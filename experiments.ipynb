{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 11:21:15.641811: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-29 11:21:15.777546: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-29 11:21:16.409786: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvrtc.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-29 11:21:16.409855: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-29 11:21:16.409862: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 1300\n",
      "src.processing - INFO - Number of testing samples is 700\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 455\n",
      "src.processing - INFO - Number of testing samples is 60\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 455\n",
      "src.processing - INFO - Number of testing samples is 60\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 455\n",
      "src.processing - INFO - Number of testing samples is 60\n",
      "src.processing - INFO - Train test split completed\n",
      "The most frequent shape is (128, 213)\n",
      "src.model - INFO - Initializing CNN\n",
      "src.model - INFO - Input shape = (128, 213, 1)\n",
      "src.model - INFO - CNN Initialized\n",
      "src.train - INFO - Number of train samples: 2665\n",
      "src.train - INFO - Number of test samples: 880\n",
      "src.processing - INFO - Start feature target split\n",
      "src.processing - INFO - Feature target split completed\n",
      "src.processing - INFO - Start feature target split\n",
      "src.processing - INFO - Feature target split completed\n",
      "src.processing - INFO - Features reshaped for CNN Input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 11:21:19.327257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22324 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:3b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.processing - INFO - Features reshaped for CNN Input\n",
      "src.processing - INFO - Target one hot encoded\n",
      "src.processing - INFO - Target one hot encoded\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 124, 209, 24)      624       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 104, 24)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " activation (Activation)     (None, 31, 104, 24)       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 27, 100, 48)       28848     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 50, 48)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 6, 50, 48)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 2, 46, 48)         57648     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 2, 46, 48)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4416)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4416)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                282688    \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 370,458\n",
      "Trainable params: 370,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "src.train - INFO - None\n",
      "src.model - INFO - Start training model\n",
      "src.model - INFO - Tensorboard Logging Started\n",
      "src.model - INFO - Use the following command in the terminal to view the logs during training: tensorboard --logdir logs/training\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 11:21:22.987827: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600\n",
      "2023-05-29 11:21:23.772421: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - ETA: 0s - loss: 2.2863 - accuracy: 0.1403 - precision: 0.0299 - recall: 0.0026 - fmeasure: 0.0046          src.model - INFO - {Epoch: 0} loss: 2.286288, accuracy: 0.140338, precision: 0.029851, recall: 0.002612, fmeasure: 0.004620, val_loss: 2.274429, val_accuracy: 0.126136, val_precision: 0.045455, val_recall: 0.003409, val_fmeasure: 0.006297\n",
      "134/134 [==============================] - 7s 17ms/step - loss: 2.2863 - accuracy: 0.1403 - precision: 0.0299 - recall: 0.0026 - fmeasure: 0.0046 - val_loss: 2.2744 - val_accuracy: 0.1261 - val_precision: 0.0455 - val_recall: 0.0034 - val_fmeasure: 0.0063\n",
      "Epoch 2/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 1.9681 - accuracy: 0.2802 - precision: 0.5098 - recall: 0.0752 - fmeasure: 0.1244src.model - INFO - {Epoch: 1} loss: 1.961934, accuracy: 0.281426, precision: 0.512212, recall: 0.077239, fmeasure: 0.127443, val_loss: 1.391136, val_accuracy: 0.552273, val_precision: 0.920509, val_recall: 0.192045, val_fmeasure: 0.309508\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 1.9619 - accuracy: 0.2814 - precision: 0.5122 - recall: 0.0772 - fmeasure: 0.1274 - val_loss: 1.3911 - val_accuracy: 0.5523 - val_precision: 0.9205 - val_recall: 0.1920 - val_fmeasure: 0.3095\n",
      "Epoch 3/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 1.0679 - accuracy: 0.6248 - precision: 0.8139 - recall: 0.4622 - fmeasure: 0.5787src.model - INFO - {Epoch: 2} loss: 1.062575, accuracy: 0.626266, precision: 0.815535, recall: 0.465672, fmeasure: 0.582013, val_loss: 0.640720, val_accuracy: 0.787500, val_precision: 0.882974, val_recall: 0.682955, val_fmeasure: 0.768444\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 1.0626 - accuracy: 0.6263 - precision: 0.8155 - recall: 0.4657 - fmeasure: 0.5820 - val_loss: 0.6407 - val_accuracy: 0.7875 - val_precision: 0.8830 - val_recall: 0.6830 - val_fmeasure: 0.7684\n",
      "Epoch 4/15\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.6024 - accuracy: 0.8096 - precision: 0.8980 - recall: 0.7154 - fmeasure: 0.7928src.model - INFO - {Epoch: 3} loss: 0.600728, accuracy: 0.810882, precision: 0.899273, recall: 0.717164, fmeasure: 0.794387, val_loss: 0.363648, val_accuracy: 0.890909, val_precision: 0.941601, val_recall: 0.832955, val_fmeasure: 0.882904\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.6007 - accuracy: 0.8109 - precision: 0.8993 - recall: 0.7172 - fmeasure: 0.7944 - val_loss: 0.3636 - val_accuracy: 0.8909 - val_precision: 0.9416 - val_recall: 0.8330 - val_fmeasure: 0.8829\n",
      "Epoch 5/15\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.3790 - accuracy: 0.8800 - precision: 0.9282 - recall: 0.8312 - fmeasure: 0.8756src.model - INFO - {Epoch: 4} loss: 0.376246, accuracy: 0.881426, precision: 0.928015, recall: 0.832463, fmeasure: 0.876234, val_loss: 0.284425, val_accuracy: 0.917045, val_precision: 0.941429, val_recall: 0.881818, val_fmeasure: 0.910068\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.3762 - accuracy: 0.8814 - precision: 0.9280 - recall: 0.8325 - fmeasure: 0.8762 - val_loss: 0.2844 - val_accuracy: 0.9170 - val_precision: 0.9414 - val_recall: 0.8818 - val_fmeasure: 0.9101\n",
      "Epoch 6/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.2977 - accuracy: 0.8981 - precision: 0.9325 - recall: 0.8668 - fmeasure: 0.8975src.model - INFO - {Epoch: 5} loss: 0.298868, accuracy: 0.897936, precision: 0.933562, recall: 0.866418, fmeasure: 0.897726, val_loss: 0.215070, val_accuracy: 0.927273, val_precision: 0.947244, val_recall: 0.914773, val_fmeasure: 0.930231\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.2989 - accuracy: 0.8979 - precision: 0.9336 - recall: 0.8664 - fmeasure: 0.8977 - val_loss: 0.2151 - val_accuracy: 0.9273 - val_precision: 0.9472 - val_recall: 0.9148 - val_fmeasure: 0.9302\n",
      "Epoch 7/15\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.2326 - accuracy: 0.9162 - precision: 0.9454 - recall: 0.8936 - fmeasure: 0.9180src.model - INFO - {Epoch: 6} loss: 0.233118, accuracy: 0.915947, precision: 0.945830, recall: 0.892910, fmeasure: 0.917798, val_loss: 0.249536, val_accuracy: 0.921591, val_precision: 0.934437, val_recall: 0.906818, val_fmeasure: 0.920215\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.2331 - accuracy: 0.9159 - precision: 0.9458 - recall: 0.8929 - fmeasure: 0.9178 - val_loss: 0.2495 - val_accuracy: 0.9216 - val_precision: 0.9344 - val_recall: 0.9068 - val_fmeasure: 0.9202\n",
      "Epoch 8/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.2343 - accuracy: 0.9206 - precision: 0.9469 - recall: 0.8954 - fmeasure: 0.9198src.model - INFO - {Epoch: 7} loss: 0.237659, accuracy: 0.919700, precision: 0.946484, recall: 0.895522, fmeasure: 0.919646, val_loss: 0.198834, val_accuracy: 0.946591, val_precision: 0.952811, val_recall: 0.934091, val_fmeasure: 0.943180\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.2377 - accuracy: 0.9197 - precision: 0.9465 - recall: 0.8955 - fmeasure: 0.9196 - val_loss: 0.1988 - val_accuracy: 0.9466 - val_precision: 0.9528 - val_recall: 0.9341 - val_fmeasure: 0.9432\n",
      "Epoch 9/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.1553 - accuracy: 0.9469 - precision: 0.9662 - recall: 0.9302 - fmeasure: 0.9473src.model - INFO - {Epoch: 8} loss: 0.154597, accuracy: 0.947467, precision: 0.966537, recall: 0.931343, fmeasure: 0.948088, val_loss: 0.173170, val_accuracy: 0.950000, val_precision: 0.961462, val_recall: 0.944318, val_fmeasure: 0.952581\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.1546 - accuracy: 0.9475 - precision: 0.9665 - recall: 0.9313 - fmeasure: 0.9481 - val_loss: 0.1732 - val_accuracy: 0.9500 - val_precision: 0.9615 - val_recall: 0.9443 - val_fmeasure: 0.9526\n",
      "Epoch 10/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.1723 - accuracy: 0.9427 - precision: 0.9580 - recall: 0.9290 - fmeasure: 0.9429src.model - INFO - {Epoch: 9} loss: 0.171927, accuracy: 0.942964, precision: 0.958231, recall: 0.928358, fmeasure: 0.942644, val_loss: 0.196770, val_accuracy: 0.938636, val_precision: 0.953323, val_recall: 0.930682, val_fmeasure: 0.941657\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.1719 - accuracy: 0.9430 - precision: 0.9582 - recall: 0.9284 - fmeasure: 0.9426 - val_loss: 0.1968 - val_accuracy: 0.9386 - val_precision: 0.9533 - val_recall: 0.9307 - val_fmeasure: 0.9417\n",
      "Epoch 11/15\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.1420 - accuracy: 0.9523 - precision: 0.9653 - recall: 0.9415 - fmeasure: 0.9530src.model - INFO - {Epoch: 10} loss: 0.141752, accuracy: 0.951970, precision: 0.965553, recall: 0.941418, fmeasure: 0.953050, val_loss: 0.171952, val_accuracy: 0.955682, val_precision: 0.960108, val_recall: 0.952273, val_fmeasure: 0.955996\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.1418 - accuracy: 0.9520 - precision: 0.9656 - recall: 0.9414 - fmeasure: 0.9530 - val_loss: 0.1720 - val_accuracy: 0.9557 - val_precision: 0.9601 - val_recall: 0.9523 - val_fmeasure: 0.9560\n",
      "Epoch 12/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.1080 - accuracy: 0.9607 - precision: 0.9715 - recall: 0.9515 - fmeasure: 0.9611src.model - INFO - {Epoch: 11} loss: 0.107226, accuracy: 0.960976, precision: 0.970690, recall: 0.951119, fmeasure: 0.960501, val_loss: 0.274898, val_accuracy: 0.939773, val_precision: 0.944777, val_recall: 0.936364, val_fmeasure: 0.940437\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.1072 - accuracy: 0.9610 - precision: 0.9707 - recall: 0.9511 - fmeasure: 0.9605 - val_loss: 0.2749 - val_accuracy: 0.9398 - val_precision: 0.9448 - val_recall: 0.9364 - val_fmeasure: 0.9404\n",
      "Epoch 13/15\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.1189 - accuracy: 0.9588 - precision: 0.9691 - recall: 0.9512 - fmeasure: 0.9598src.model - INFO - {Epoch: 12} loss: 0.117868, accuracy: 0.959099, precision: 0.969298, recall: 0.951865, fmeasure: 0.960258, val_loss: 0.179599, val_accuracy: 0.955682, val_precision: 0.960945, val_recall: 0.954546, val_fmeasure: 0.957663\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.1179 - accuracy: 0.9591 - precision: 0.9693 - recall: 0.9519 - fmeasure: 0.9603 - val_loss: 0.1796 - val_accuracy: 0.9557 - val_precision: 0.9609 - val_recall: 0.9545 - val_fmeasure: 0.9577\n",
      "Epoch 14/15\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.1227 - accuracy: 0.9609 - precision: 0.9694 - recall: 0.9541 - fmeasure: 0.9615src.model - INFO - {Epoch: 13} loss: 0.123819, accuracy: 0.960600, precision: 0.969632, recall: 0.952985, fmeasure: 0.960982, val_loss: 0.182060, val_accuracy: 0.952273, val_precision: 0.954180, val_recall: 0.948864, val_fmeasure: 0.951425\n",
      "134/134 [==============================] - 2s 15ms/step - loss: 0.1238 - accuracy: 0.9606 - precision: 0.9696 - recall: 0.9530 - fmeasure: 0.9610 - val_loss: 0.1821 - val_accuracy: 0.9523 - val_precision: 0.9542 - val_recall: 0.9489 - val_fmeasure: 0.9514\n",
      "Epoch 15/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.1413 - accuracy: 0.9527 - precision: 0.9634 - recall: 0.9416 - fmeasure: 0.9521src.model - INFO - {Epoch: 14} loss: 0.140409, accuracy: 0.952720, precision: 0.963793, recall: 0.942164, fmeasure: 0.952634, val_loss: 0.173566, val_accuracy: 0.956818, val_precision: 0.961125, val_recall: 0.954546, val_fmeasure: 0.957751\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.1404 - accuracy: 0.9527 - precision: 0.9638 - recall: 0.9422 - fmeasure: 0.9526 - val_loss: 0.1736 - val_accuracy: 0.9568 - val_precision: 0.9611 - val_recall: 0.9545 - val_fmeasure: 0.9578\n",
      "src.model - INFO - Training completed\n",
      "src.model - INFO - Evaluating model\n",
      "28/28 [==============================] - 1s 9ms/step - loss: 0.1736 - accuracy: 0.9568 - precision: 0.9618 - recall: 0.9554 - fmeasure: 0.9585\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.0244 - accuracy: 0.9936 - precision: 0.9952 - recall: 0.9907 - fmeasure: 0.9929\n",
      "src.model - INFO - Train loss: 0.024444323033094406\n",
      "src.model - INFO - Train accuracy: 0.9936209917068481\n",
      "src.model - INFO - Train precision: 0.995151698589325\n",
      "src.model - INFO - Train recall: 0.9906994104385376\n",
      "src.model - INFO - Train f1-score: 0.9928779602050781\n",
      "src.model - INFO - Test loss: 0.17356513440608978\n",
      "src.model - INFO - Test accuracy: 0.956818163394928\n",
      "src.model - INFO - Test precision: 0.9618015289306641\n",
      "src.model - INFO - Test recall: 0.9553571343421936\n",
      "src.model - INFO - Test f1-score: 0.9585281610488892\n",
      "28/28 [==============================] - 0s 5ms/step\n",
      "src.train - INFO - Confusion Matrix for classes ['a', 'am', 'bm', 'c', 'd', 'dm', 'e', 'em', 'f', 'g']:\n",
      "[[ 83   2   0   0   0   0   1   0   0   0]\n",
      " [  3  71   0   0   0   0   0   0   1   0]\n",
      " [  0   0  69   0   0   0   0   0   1   0]\n",
      " [  0   0   0 100   0   0   0   0   0   0]\n",
      " [  0   1   0   0  95   3   0   1   0   2]\n",
      " [  0   0   0   0   9  71   0   0   0   1]\n",
      " [  0   0   0   2   0   0  92   2   0   0]\n",
      " [  0   0   0   0   0   0   2  77   0   0]\n",
      " [  0   2   0   0   0   1   0   0  89   0]\n",
      " [  0   0   1   0   2   0   0   0   1  95]]\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.2121 - accuracy: 0.9471 - precision: 0.9514 - recall: 0.9460 - fmeasure: 0.9486\n",
      "Test score for instrument: Guitar\n",
      "\tTest loss: 0.21208502352237701\n",
      "\tTest accuracy: 0.9471428394317627\n",
      "\tTest precision: 0.9513776898384094\n",
      "\tTest recall: 0.9460227489471436\n",
      "\tTest f1-score: 0.948635995388031\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 9.5903e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - fmeasure: 1.0000\n",
      "Test score for instrument: Accordion\n",
      "\tTest loss: 9.590313129592687e-05\n",
      "\tTest accuracy: 1.0\n",
      "\tTest precision: 1.0\n",
      "\tTest recall: 1.0\n",
      "\tTest f1-score: 1.0\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.6305e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - fmeasure: 1.0000\n",
      "Test score for instrument: Violin\n",
      "\tTest loss: 0.0008630547090433538\n",
      "\tTest accuracy: 1.0\n",
      "\tTest precision: 1.0\n",
      "\tTest recall: 1.0\n",
      "\tTest f1-score: 1.0\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0703 - accuracy: 0.9833 - precision: 1.0000 - recall: 0.9643 - fmeasure: 0.9815\n",
      "Test score for instrument: Piano\n",
      "\tTest loss: 0.07034356147050858\n",
      "\tTest accuracy: 0.9833333492279053\n",
      "\tTest precision: 1.0\n",
      "\tTest recall: 0.9642857313156128\n",
      "\tTest f1-score: 0.9814814329147339\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os, sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from settings import *\n",
    "from my_train import *\n",
    "from src.model import CNN, CNN_nodropout\n",
    "\n",
    "datasets_raw, datasets_augmented, size = load_data(METADATA_DIR_RAW_NORMALIZED, METADATA_DIR_AUGMENTED_RAW_NORMALIZED)\n",
    "datasets_augmented = list(map(lambda df: df[~df['augmentation'].isin(['pitch_250', 'pitch_200'])].reset_index(drop=True),datasets_augmented))\n",
    "\n",
    "train_data, test_data, test_datas = train_test(datasets_raw, datasets_augmented)\n",
    "most_shape = get_most_shape(train_data)\n",
    "\n",
    "cnn = CNN(most_shape)\n",
    "my_train(cnn, train_data, test_data, size)\n",
    "\n",
    "test_by_instrument(cnn, test_datas, size)\n",
    "\n",
    "experiment1_model = cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.model - INFO - Saving model\n",
      "src.model - INFO - Saved model to /home/tzag/danigil/dl/guitarCR/models\n"
     ]
    }
   ],
   "source": [
    "experiment1_model.save_model('experiment1_model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 1300\n",
      "src.processing - INFO - Number of testing samples is 700\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 455\n",
      "src.processing - INFO - Number of testing samples is 60\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 455\n",
      "src.processing - INFO - Number of testing samples is 60\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 455\n",
      "src.processing - INFO - Number of testing samples is 60\n",
      "src.processing - INFO - Train test split completed\n",
      "The most frequent shape is (128, 107)\n",
      "src.model - INFO - Initializing CNN\n",
      "src.model - INFO - Input shape = (128, 107, 1)\n",
      "src.model - INFO - CNN Initialized\n",
      "src.train - INFO - Number of train samples: 2665\n",
      "src.train - INFO - Number of test samples: 880\n",
      "src.processing - INFO - Start feature target split\n",
      "src.processing - INFO - Feature target split completed\n",
      "src.processing - INFO - Start feature target split\n",
      "src.processing - INFO - Feature target split completed\n",
      "src.processing - INFO - Features reshaped for CNN Input\n",
      "src.processing - INFO - Features reshaped for CNN Input\n",
      "src.processing - INFO - Target one hot encoded\n",
      "src.processing - INFO - Target one hot encoded\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 124, 103, 24)      624       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 31, 51, 24)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 31, 51, 24)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 27, 47, 48)        28848     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 23, 48)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 6, 23, 48)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 2, 19, 48)         57648     \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 2, 19, 48)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1824)              0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1824)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                116800    \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 204,570\n",
      "Trainable params: 204,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "src.train - INFO - None\n",
      "src.model - INFO - Start training model\n",
      "src.model - INFO - Tensorboard Logging Started\n",
      "src.model - INFO - Use the following command in the terminal to view the logs during training: tensorboard --logdir logs/training\n",
      "Epoch 1/15\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.5632 - accuracy: 0.1235 - precision: 0.1166 - recall: 0.0101 - fmeasure: 0.0180src.model - INFO - {Epoch: 0} loss: 2.563151, accuracy: 0.123452, precision: 0.116613, recall: 0.010075, fmeasure: 0.018032, val_loss: 2.276870, val_accuracy: 0.138636, val_precision: 0.045455, val_recall: 0.002273, val_fmeasure: 0.004329\n",
      "134/134 [==============================] - 4s 16ms/step - loss: 2.5632 - accuracy: 0.1235 - precision: 0.1166 - recall: 0.0101 - fmeasure: 0.0180 - val_loss: 2.2769 - val_accuracy: 0.1386 - val_precision: 0.0455 - val_recall: 0.0023 - val_fmeasure: 0.0043\n",
      "Epoch 2/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 2.2142 - accuracy: 0.1733 - precision: 0.3658 - recall: 0.0260 - fmeasure: 0.0479src.model - INFO - {Epoch: 1} loss: 2.213107, accuracy: 0.172608, precision: 0.370647, recall: 0.026866, fmeasure: 0.049418, val_loss: 2.217110, val_accuracy: 0.178409, val_precision: 0.257576, val_recall: 0.017045, val_fmeasure: 0.031689\n",
      "134/134 [==============================] - 2s 13ms/step - loss: 2.2131 - accuracy: 0.1726 - precision: 0.3706 - recall: 0.0269 - fmeasure: 0.0494 - val_loss: 2.2171 - val_accuracy: 0.1784 - val_precision: 0.2576 - val_recall: 0.0170 - val_fmeasure: 0.0317\n",
      "Epoch 3/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 2.1309 - accuracy: 0.2126 - precision: 0.5803 - recall: 0.0622 - fmeasure: 0.1094src.model - INFO - {Epoch: 2} loss: 2.127397, accuracy: 0.213133, precision: 0.589739, recall: 0.065299, fmeasure: 0.114458, val_loss: 2.147615, val_accuracy: 0.219318, val_precision: 0.594697, val_recall: 0.043182, val_fmeasure: 0.079466\n",
      "134/134 [==============================] - 2s 13ms/step - loss: 2.1274 - accuracy: 0.2131 - precision: 0.5897 - recall: 0.0653 - fmeasure: 0.1145 - val_loss: 2.1476 - val_accuracy: 0.2193 - val_precision: 0.5947 - val_recall: 0.0432 - val_fmeasure: 0.0795\n",
      "Epoch 4/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 1.9908 - accuracy: 0.2813 - precision: 0.7477 - recall: 0.1141 - fmeasure: 0.1936src.model - INFO - {Epoch: 3} loss: 1.987523, accuracy: 0.281801, precision: 0.753358, recall: 0.116418, fmeasure: 0.196786, val_loss: 2.047260, val_accuracy: 0.257955, val_precision: 0.751894, val_recall: 0.071591, val_fmeasure: 0.128703\n",
      "134/134 [==============================] - 2s 13ms/step - loss: 1.9875 - accuracy: 0.2818 - precision: 0.7534 - recall: 0.1164 - fmeasure: 0.1968 - val_loss: 2.0473 - val_accuracy: 0.2580 - val_precision: 0.7519 - val_recall: 0.0716 - val_fmeasure: 0.1287\n",
      "Epoch 5/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 1.8954 - accuracy: 0.3176 - precision: 0.7601 - recall: 0.1611 - fmeasure: 0.2591src.model - INFO - {Epoch: 4} loss: 1.889888, accuracy: 0.320075, precision: 0.764268, recall: 0.163806, fmeasure: 0.262959, val_loss: 1.993107, val_accuracy: 0.277273, val_precision: 0.792803, val_recall: 0.087500, val_fmeasure: 0.153957\n",
      "134/134 [==============================] - 2s 13ms/step - loss: 1.8899 - accuracy: 0.3201 - precision: 0.7643 - recall: 0.1638 - fmeasure: 0.2630 - val_loss: 1.9931 - val_accuracy: 0.2773 - val_precision: 0.7928 - val_recall: 0.0875 - val_fmeasure: 0.1540\n",
      "Epoch 6/15\n",
      "130/134 [============================>.] - ETA: 0s - loss: 1.7924 - accuracy: 0.3700 - precision: 0.8156 - recall: 0.1946 - fmeasure: 0.3053src.model - INFO - {Epoch: 5} loss: 1.792926, accuracy: 0.371107, precision: 0.817403, recall: 0.194403, fmeasure: 0.305348, val_loss: 1.871656, val_accuracy: 0.319318, val_precision: 0.870455, val_recall: 0.117045, val_fmeasure: 0.199028\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 1.7929 - accuracy: 0.3711 - precision: 0.8174 - recall: 0.1944 - fmeasure: 0.3053 - val_loss: 1.8717 - val_accuracy: 0.3193 - val_precision: 0.8705 - val_recall: 0.1170 - val_fmeasure: 0.1990\n",
      "Epoch 7/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 1.6825 - accuracy: 0.4027 - precision: 0.8200 - recall: 0.2267 - fmeasure: 0.3499src.model - INFO - {Epoch: 6} loss: 1.678654, accuracy: 0.404128, precision: 0.814058, recall: 0.225746, fmeasure: 0.348169, val_loss: 1.873989, val_accuracy: 0.351136, val_precision: 0.818561, val_recall: 0.105682, val_fmeasure: 0.181231\n",
      "134/134 [==============================] - 2s 13ms/step - loss: 1.6787 - accuracy: 0.4041 - precision: 0.8141 - recall: 0.2257 - fmeasure: 0.3482 - val_loss: 1.8740 - val_accuracy: 0.3511 - val_precision: 0.8186 - val_recall: 0.1057 - val_fmeasure: 0.1812\n",
      "Epoch 8/15\n",
      "130/134 [============================>.] - ETA: 0s - loss: 1.6548 - accuracy: 0.4165 - precision: 0.8244 - recall: 0.2362 - fmeasure: 0.3585src.model - INFO - {Epoch: 7} loss: 1.654684, accuracy: 0.418011, precision: 0.822838, recall: 0.235821, fmeasure: 0.357637, val_loss: 1.783339, val_accuracy: 0.397727, val_precision: 0.767803, val_recall: 0.136364, val_fmeasure: 0.223729\n",
      "134/134 [==============================] - 2s 13ms/step - loss: 1.6547 - accuracy: 0.4180 - precision: 0.8228 - recall: 0.2358 - fmeasure: 0.3576 - val_loss: 1.7833 - val_accuracy: 0.3977 - val_precision: 0.7678 - val_recall: 0.1364 - val_fmeasure: 0.2237\n",
      "Epoch 9/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 1.5655 - accuracy: 0.4599 - precision: 0.8299 - recall: 0.2740 - fmeasure: 0.4042src.model - INFO - {Epoch: 8} loss: 1.565215, accuracy: 0.460038, precision: 0.828076, recall: 0.273134, fmeasure: 0.403042, val_loss: 1.622681, val_accuracy: 0.453409, val_precision: 0.850352, val_recall: 0.178409, val_fmeasure: 0.287104\n",
      "134/134 [==============================] - 2s 13ms/step - loss: 1.5652 - accuracy: 0.4600 - precision: 0.8281 - recall: 0.2731 - fmeasure: 0.4030 - val_loss: 1.6227 - val_accuracy: 0.4534 - val_precision: 0.8504 - val_recall: 0.1784 - val_fmeasure: 0.2871\n",
      "Epoch 10/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 1.4702 - accuracy: 0.4809 - precision: 0.8357 - recall: 0.3168 - fmeasure: 0.4510src.model - INFO - {Epoch: 9} loss: 1.463477, accuracy: 0.483302, precision: 0.837460, recall: 0.318657, fmeasure: 0.452624, val_loss: 1.478543, val_accuracy: 0.464773, val_precision: 0.820193, val_recall: 0.282955, val_fmeasure: 0.414183\n",
      "134/134 [==============================] - 2s 13ms/step - loss: 1.4635 - accuracy: 0.4833 - precision: 0.8375 - recall: 0.3187 - fmeasure: 0.4526 - val_loss: 1.4785 - val_accuracy: 0.4648 - val_precision: 0.8202 - val_recall: 0.2830 - val_fmeasure: 0.4142\n",
      "Epoch 11/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 1.3333 - accuracy: 0.5256 - precision: 0.8578 - recall: 0.3802 - fmeasure: 0.5216src.model - INFO - {Epoch: 10} loss: 1.330193, accuracy: 0.526079, precision: 0.858245, recall: 0.381343, fmeasure: 0.522826, val_loss: 1.420622, val_accuracy: 0.527273, val_precision: 0.868191, val_recall: 0.315909, val_fmeasure: 0.454537\n",
      "134/134 [==============================] - 2s 13ms/step - loss: 1.3302 - accuracy: 0.5261 - precision: 0.8582 - recall: 0.3813 - fmeasure: 0.5228 - val_loss: 1.4206 - val_accuracy: 0.5273 - val_precision: 0.8682 - val_recall: 0.3159 - val_fmeasure: 0.4545\n",
      "Epoch 12/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 1.3730 - accuracy: 0.5454 - precision: 0.8456 - recall: 0.3817 - fmeasure: 0.5186src.model - INFO - {Epoch: 11} loss: 1.371524, accuracy: 0.544465, precision: 0.845307, recall: 0.381716, fmeasure: 0.518714, val_loss: 1.346125, val_accuracy: 0.540909, val_precision: 0.891750, val_recall: 0.335227, val_fmeasure: 0.477594\n",
      "134/134 [==============================] - 2s 13ms/step - loss: 1.3715 - accuracy: 0.5445 - precision: 0.8453 - recall: 0.3817 - fmeasure: 0.5187 - val_loss: 1.3461 - val_accuracy: 0.5409 - val_precision: 0.8918 - val_recall: 0.3352 - val_fmeasure: 0.4776\n",
      "Epoch 13/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 1.2541 - accuracy: 0.5771 - precision: 0.8611 - recall: 0.4431 - fmeasure: 0.5768src.model - INFO - {Epoch: 12} loss: 1.258223, accuracy: 0.574484, precision: 0.855289, recall: 0.439552, fmeasure: 0.572431, val_loss: 1.537548, val_accuracy: 0.447727, val_precision: 0.814735, val_recall: 0.300000, val_fmeasure: 0.430190\n",
      "134/134 [==============================] - 2s 13ms/step - loss: 1.2582 - accuracy: 0.5745 - precision: 0.8553 - recall: 0.4396 - fmeasure: 0.5724 - val_loss: 1.5375 - val_accuracy: 0.4477 - val_precision: 0.8147 - val_recall: 0.3000 - val_fmeasure: 0.4302\n",
      "Epoch 14/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 1.2058 - accuracy: 0.5878 - precision: 0.8541 - recall: 0.4424 - fmeasure: 0.5770src.model - INFO - {Epoch: 13} loss: 1.204419, accuracy: 0.587242, precision: 0.851178, recall: 0.440672, fmeasure: 0.574894, val_loss: 1.246369, val_accuracy: 0.547727, val_precision: 0.893255, val_recall: 0.419318, val_fmeasure: 0.564252\n",
      "134/134 [==============================] - 2s 13ms/step - loss: 1.2044 - accuracy: 0.5872 - precision: 0.8512 - recall: 0.4407 - fmeasure: 0.5749 - val_loss: 1.2464 - val_accuracy: 0.5477 - val_precision: 0.8933 - val_recall: 0.4193 - val_fmeasure: 0.5643\n",
      "Epoch 15/15\n",
      "130/134 [============================>.] - ETA: 0s - loss: 1.0426 - accuracy: 0.6354 - precision: 0.8964 - recall: 0.5150 - fmeasure: 0.6485src.model - INFO - {Epoch: 14} loss: 1.039900, accuracy: 0.636773, precision: 0.897383, recall: 0.515298, fmeasure: 0.648331, val_loss: 1.145525, val_accuracy: 0.589773, val_precision: 0.886464, val_recall: 0.425000, val_fmeasure: 0.568426\n",
      "134/134 [==============================] - 2s 13ms/step - loss: 1.0399 - accuracy: 0.6368 - precision: 0.8974 - recall: 0.5153 - fmeasure: 0.6483 - val_loss: 1.1455 - val_accuracy: 0.5898 - val_precision: 0.8865 - val_recall: 0.4250 - val_fmeasure: 0.5684\n",
      "src.model - INFO - Training completed\n",
      "src.model - INFO - Evaluating model\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.1455 - accuracy: 0.5898 - precision: 0.8819 - recall: 0.4252 - fmeasure: 0.5689\n",
      "84/84 [==============================] - 1s 7ms/step - loss: 0.8137 - accuracy: 0.7238 - precision: 0.9611 - recall: 0.5799 - fmeasure: 0.7204\n",
      "src.model - INFO - Train loss: 0.8136547207832336\n",
      "src.model - INFO - Train accuracy: 0.7238274216651917\n",
      "src.model - INFO - Train precision: 0.9611446857452393\n",
      "src.model - INFO - Train recall: 0.5799024701118469\n",
      "src.model - INFO - Train f1-score: 0.7204312086105347\n",
      "src.model - INFO - Test loss: 1.1455254554748535\n",
      "src.model - INFO - Test accuracy: 0.5897727012634277\n",
      "src.model - INFO - Test precision: 0.8818700909614563\n",
      "src.model - INFO - Test recall: 0.4252232015132904\n",
      "src.model - INFO - Test f1-score: 0.5688608884811401\n",
      "28/28 [==============================] - 0s 5ms/step\n",
      "src.train - INFO - Confusion Matrix for classes ['a', 'am', 'bm', 'c', 'd', 'dm', 'e', 'em', 'f', 'g']:\n",
      "[[42 16  1  1  6  0  0  3 17  0]\n",
      " [ 1 45  0  0  0  0  0  0 29  0]\n",
      " [ 0  0 43  0  6  1  0  1 19  0]\n",
      " [ 1 17  0 40 11  0  1  0 22  8]\n",
      " [ 0  0  0  0 86  1  0  0 14  1]\n",
      " [ 0  0  1  0 24 29  0  0 27  0]\n",
      " [ 1  0  0  0  4  1 46  8 36  0]\n",
      " [ 1  0  0  0  1  0  1 49 26  1]\n",
      " [ 0  1  3  1  2  3  0  0 82  0]\n",
      " [ 0  0 18  2  6  0  0  9  7 57]]\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 1.3306 - accuracy: 0.5229 - precision: 0.8616 - recall: 0.3468 - fmeasure: 0.4892\n",
      "Test score for instrument: Guitar\n",
      "\tTest loss: 1.3306251764297485\n",
      "\tTest accuracy: 0.522857129573822\n",
      "\tTest precision: 0.861595869064331\n",
      "\tTest recall: 0.3467938303947449\n",
      "\tTest f1-score: 0.489177405834198\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1367 - accuracy: 0.9667 - precision: 0.9839 - recall: 0.8973 - fmeasure: 0.9377\n",
      "Test score for instrument: Accordion\n",
      "\tTest loss: 0.13670912384986877\n",
      "\tTest accuracy: 0.9666666388511658\n",
      "\tTest precision: 0.9838709831237793\n",
      "\tTest recall: 0.8973214626312256\n",
      "\tTest f1-score: 0.9377288818359375\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1207 - accuracy: 0.9833 - precision: 1.0000 - recall: 0.9531 - fmeasure: 0.9754\n",
      "Test score for instrument: Violin\n",
      "\tTest loss: 0.1206669807434082\n",
      "\tTest accuracy: 0.9833333492279053\n",
      "\tTest precision: 1.0\n",
      "\tTest recall: 0.953125\n",
      "\tTest f1-score: 0.9754098057746887\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.0197 - accuracy: 0.6000 - precision: 0.7692 - recall: 0.3348 - fmeasure: 0.4661\n",
      "Test score for instrument: Piano\n",
      "\tTest loss: 1.0196967124938965\n",
      "\tTest accuracy: 0.6000000238418579\n",
      "\tTest precision: 0.7692307829856873\n",
      "\tTest recall: 0.3348214328289032\n",
      "\tTest f1-score: 0.46612459421157837\n"
     ]
    }
   ],
   "source": [
    "datasets_raw, datasets_augmented, size = load_data(METADATA_DIR_RAW, METADATA_DIR_AUGMENTED_RAW)\n",
    "datasets_augmented = list(map(lambda df: df[~df['augmentation'].isin(['pitch_250', 'pitch_200'])].reset_index(drop=True),datasets_augmented))\n",
    "\n",
    "train_data, test_data, test_datas = train_test(datasets_raw, datasets_augmented)\n",
    "most_shape = get_most_shape(train_data)\n",
    "\n",
    "cnn = CNN(most_shape)\n",
    "my_train(cnn, train_data, test_data, size)\n",
    "\n",
    "test_by_instrument(cnn, test_datas, size)\n",
    "experiment2_model = cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.model - INFO - Saving model\n",
      "src.model - INFO - Saved model to /home/tzag/danigil/dl/guitarCR/models\n"
     ]
    }
   ],
   "source": [
    "experiment2_model.save_model('experiment2_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 1300\n",
      "src.processing - INFO - Number of testing samples is 700\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 455\n",
      "src.processing - INFO - Number of testing samples is 60\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 455\n",
      "src.processing - INFO - Number of testing samples is 60\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 455\n",
      "src.processing - INFO - Number of testing samples is 60\n",
      "src.processing - INFO - Train test split completed\n",
      "The most frequent shape is (128, 213)\n",
      "src.model - INFO - Input shape = (128, 213, 1)\n",
      "src.train - INFO - Number of train samples: 2665\n",
      "src.train - INFO - Number of test samples: 880\n",
      "src.processing - INFO - Start feature target split\n",
      "src.processing - INFO - Feature target split completed\n",
      "src.processing - INFO - Start feature target split\n",
      "src.processing - INFO - Feature target split completed\n",
      "src.processing - INFO - Features reshaped for CNN Input\n",
      "src.processing - INFO - Features reshaped for CNN Input\n",
      "src.processing - INFO - Target one hot encoded\n",
      "src.processing - INFO - Target one hot encoded\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_33 (Conv2D)          (None, 124, 209, 24)      624       \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 31, 104, 24)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " activation_55 (Activation)  (None, 31, 104, 24)       0         \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 27, 100, 48)       28848     \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 6, 50, 48)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " activation_56 (Activation)  (None, 6, 50, 48)         0         \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 2, 46, 48)         57648     \n",
      "                                                                 \n",
      " activation_57 (Activation)  (None, 2, 46, 48)         0         \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 4416)              0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 64)                282688    \n",
      "                                                                 \n",
      " activation_58 (Activation)  (None, 64)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      " activation_59 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 370,458\n",
      "Trainable params: 370,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "src.train - INFO - None\n",
      "src.model - INFO - Start training model\n",
      "src.model - INFO - Tensorboard Logging Started\n",
      "src.model - INFO - Use the following command in the terminal to view the logs during training: tensorboard --logdir logs/training\n",
      "Epoch 1/5\n",
      "131/134 [============================>.] - ETA: 0s - loss: 2.1097 - accuracy: 0.2195 - precision: 0.2683 - recall: 0.0363 - fmeasure: 0.0616src.model - INFO - {Epoch: 0} loss: 2.104899, accuracy: 0.221013, precision: 0.271020, recall: 0.036940, fmeasure: 0.062787, val_loss: 1.569881, val_accuracy: 0.455682, val_precision: 0.889610, val_recall: 0.148864, val_fmeasure: 0.245788\n",
      "134/134 [==============================] - 4s 16ms/step - loss: 2.1049 - accuracy: 0.2210 - precision: 0.2710 - recall: 0.0369 - fmeasure: 0.0628 - val_loss: 1.5699 - val_accuracy: 0.4557 - val_precision: 0.8896 - val_recall: 0.1489 - val_fmeasure: 0.2458\n",
      "Epoch 2/5\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.9853 - accuracy: 0.6553 - precision: 0.8448 - recall: 0.4809 - fmeasure: 0.5951src.model - INFO - {Epoch: 1} loss: 0.980188, accuracy: 0.656285, precision: 0.845729, recall: 0.485448, fmeasure: 0.599021, val_loss: 0.642792, val_accuracy: 0.778409, val_precision: 0.837745, val_recall: 0.713636, val_fmeasure: 0.769397\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.9802 - accuracy: 0.6563 - precision: 0.8457 - recall: 0.4854 - fmeasure: 0.5990 - val_loss: 0.6428 - val_accuracy: 0.7784 - val_precision: 0.8377 - val_recall: 0.7136 - val_fmeasure: 0.7694\n",
      "Epoch 3/5\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.3473 - accuracy: 0.8863 - precision: 0.9320 - recall: 0.8492 - fmeasure: 0.8874src.model - INFO - {Epoch: 2} loss: 0.346362, accuracy: 0.886304, precision: 0.929780, recall: 0.847761, fmeasure: 0.885588, val_loss: 0.424481, val_accuracy: 0.854545, val_precision: 0.884299, val_recall: 0.834091, val_fmeasure: 0.857970\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.3464 - accuracy: 0.8863 - precision: 0.9298 - recall: 0.8478 - fmeasure: 0.8856 - val_loss: 0.4245 - val_accuracy: 0.8545 - val_precision: 0.8843 - val_recall: 0.8341 - val_fmeasure: 0.8580\n",
      "Epoch 4/5\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.2100 - accuracy: 0.9315 - precision: 0.9557 - recall: 0.9096 - fmeasure: 0.9313src.model - INFO - {Epoch: 3} loss: 0.206867, accuracy: 0.932833, precision: 0.956663, recall: 0.911940, fmeasure: 0.932985, val_loss: 0.243676, val_accuracy: 0.915909, val_precision: 0.928947, val_recall: 0.901136, val_fmeasure: 0.914517\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.2069 - accuracy: 0.9328 - precision: 0.9567 - recall: 0.9119 - fmeasure: 0.9330 - val_loss: 0.2437 - val_accuracy: 0.9159 - val_precision: 0.9289 - val_recall: 0.9011 - val_fmeasure: 0.9145\n",
      "Epoch 5/5\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.1557 - accuracy: 0.9500 - precision: 0.9627 - recall: 0.9365 - fmeasure: 0.9491src.model - INFO - {Epoch: 4} loss: 0.153259, accuracy: 0.950844, precision: 0.963817, recall: 0.938060, fmeasure: 0.950428, val_loss: 0.242509, val_accuracy: 0.927273, val_precision: 0.936218, val_recall: 0.909091, val_fmeasure: 0.922160\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.1533 - accuracy: 0.9508 - precision: 0.9638 - recall: 0.9381 - fmeasure: 0.9504 - val_loss: 0.2425 - val_accuracy: 0.9273 - val_precision: 0.9362 - val_recall: 0.9091 - val_fmeasure: 0.9222\n",
      "src.model - INFO - Training completed\n",
      "src.model - INFO - Evaluating model\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.2425 - accuracy: 0.9273 - precision: 0.9345 - recall: 0.9074 - fmeasure: 0.9206\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.0883 - accuracy: 0.9715 - precision: 0.9803 - recall: 0.9624 - fmeasure: 0.9712\n",
      "src.model - INFO - Train loss: 0.08830930292606354\n",
      "src.model - INFO - Train accuracy: 0.9714821577072144\n",
      "src.model - INFO - Train precision: 0.9803258776664734\n",
      "src.model - INFO - Train recall: 0.9624255895614624\n",
      "src.model - INFO - Train f1-score: 0.9711676239967346\n",
      "src.model - INFO - Test loss: 0.2425106018781662\n",
      "src.model - INFO - Test accuracy: 0.9272727370262146\n",
      "src.model - INFO - Test precision: 0.9345404505729675\n",
      "src.model - INFO - Test recall: 0.9073660969734192\n",
      "src.model - INFO - Test f1-score: 0.9205840826034546\n",
      "28/28 [==============================] - 0s 5ms/step\n",
      "src.train - INFO - Confusion Matrix for classes ['a', 'am', 'bm', 'c', 'd', 'dm', 'e', 'em', 'f', 'g']:\n",
      "[[77  6  0  0  0  0  0  3  0  0]\n",
      " [ 2 71  0  0  0  0  0  0  2  0]\n",
      " [ 0  0 68  0  1  0  1  0  0  0]\n",
      " [ 0  1  0 97  0  0  0  1  1  0]\n",
      " [ 0  1  0  2 88 11  0  0  0  0]\n",
      " [ 0  0  0  0  3 76  0  2  0  0]\n",
      " [ 0  1  0  0  0  0 87  8  0  0]\n",
      " [ 0  0  0  0  0  0  1 77  0  1]\n",
      " [ 0  4  0  1  0  1  0  0 86  0]\n",
      " [ 0  0  0  3  0  2  3  2  0 89]]\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.2836 - accuracy: 0.9114 - precision: 0.9210 - recall: 0.8973 - fmeasure: 0.9086\n",
      "Test score for instrument: Guitar\n",
      "\tTest loss: 0.28361475467681885\n",
      "\tTest accuracy: 0.9114285707473755\n",
      "\tTest precision: 0.9209892153739929\n",
      "\tTest recall: 0.8973214626312256\n",
      "\tTest f1-score: 0.908647358417511\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0113 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - fmeasure: 1.0000\n",
      "Test score for instrument: Accordion\n",
      "\tTest loss: 0.011325622908771038\n",
      "\tTest accuracy: 1.0\n",
      "\tTest precision: 1.0\n",
      "\tTest recall: 1.0\n",
      "\tTest f1-score: 1.0\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0028 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - fmeasure: 1.0000\n",
      "Test score for instrument: Violin\n",
      "\tTest loss: 0.0027600442990660667\n",
      "\tTest accuracy: 1.0\n",
      "\tTest precision: 1.0\n",
      "\tTest recall: 1.0\n",
      "\tTest f1-score: 1.0\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2339 - accuracy: 0.9667 - precision: 0.9792 - recall: 0.8638 - fmeasure: 0.9177\n",
      "Test score for instrument: Piano\n",
      "\tTest loss: 0.23387837409973145\n",
      "\tTest accuracy: 0.9666666388511658\n",
      "\tTest precision: 0.9791666269302368\n",
      "\tTest recall: 0.8638392686843872\n",
      "\tTest f1-score: 0.917717456817627\n"
     ]
    }
   ],
   "source": [
    "from src.model import CNN, CNN_nodropout\n",
    "\n",
    "datasets_raw, datasets_augmented, size = load_data(METADATA_DIR_RAW_NORMALIZED, METADATA_DIR_AUGMENTED_RAW_NORMALIZED)\n",
    "datasets_augmented = list(map(lambda df: df[~df['augmentation'].isin(['pitch_250', 'pitch_200'])].reset_index(drop=True),datasets_augmented))\n",
    "\n",
    "train_data, test_data, test_datas = train_test(datasets_raw, datasets_augmented)\n",
    "most_shape = get_most_shape(train_data)\n",
    "\n",
    "cnn = CNN_nodropout(most_shape)\n",
    "my_train(cnn, train_data, test_data, size, epochs=5)\n",
    "\n",
    "test_by_instrument(cnn, test_datas, size)\n",
    "\n",
    "experiment3_model = cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.model - INFO - Saving model\n",
      "src.model - INFO - Saved model to /home/tzag/danigil/dl/guitarCR/models\n"
     ]
    }
   ],
   "source": [
    "experiment3_model.save_model('experiment3_model_5epochs_better')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOD test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ood(clf, instruments=['guitar', 'piano'], size=213):\n",
    "    for instrument in instruments:\n",
    "        dataset = pd.read_pickle(os.path.join(METADATA_DIR_RAW_NORMALIZED_OOD, f'data_{instrument}.pkl'))\n",
    "        dataset['spectrogram'] = dataset['spectrogram'].apply(lambda x: np.pad(x, ((0, 0), (0, size-x.shape[1])), 'constant'))\n",
    "\n",
    "        test_data = dataset\n",
    "\n",
    "        X_test = test_data['spectrogram']\n",
    "        X_test = np.array([np.pad(x, ((0, 0), (0, size-x.shape[1])), 'constant') for x in dataset['spectrogram']])\n",
    "        y_test = test_data['class_ID']\n",
    "\n",
    "        X_test = np.array([x.reshape( (128, size, 1) ) for x in X_test])\n",
    "        y_test = np.array(keras.utils.to_categorical(y_test, 10))\n",
    "\n",
    "        \n",
    "        score = clf.model.evaluate(\n",
    "            x=X_test,\n",
    "            y=y_test)\n",
    "        \n",
    "        print(f'OOD performance for instrument: {instrument}')\n",
    "        print('Test accuracy:', score[1])\n",
    "        print('Test recall:', score[2])\n",
    "        print('Test percision:', score[3])\n",
    "        print('Test f1-score:', score[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 1.2957 - accuracy: 0.7833 - precision: 0.7924 - recall: 0.7924 - fmeasure: 0.7924\n",
      "OOD performance for instrument: guitar\n",
      "Test accuracy: 0.7833333611488342\n",
      "Test recall: 0.7924107313156128\n",
      "Test percision: 0.7924107313156128\n",
      "Test f1-score: 0.7924106121063232\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3410 - accuracy: 0.7500 - precision: 0.7656 - recall: 0.7422 - fmeasure: 0.7531\n",
      "OOD performance for instrument: piano\n",
      "Test accuracy: 0.75\n",
      "Test recall: 0.765625\n",
      "Test percision: 0.7421875\n",
      "Test f1-score: 0.7531249523162842\n"
     ]
    }
   ],
   "source": [
    "test_ood(experiment1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3729 - accuracy: 0.8833 - precision: 0.9015 - recall: 0.8884 - fmeasure: 0.8948\n",
      "OOD performance for instrument: guitar\n",
      "Test accuracy: 0.8833333253860474\n",
      "Test recall: 0.9014977216720581\n",
      "Test percision: 0.8883928656578064\n",
      "Test f1-score: 0.894841194152832\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.4991 - accuracy: 0.8100 - precision: 0.8629 - recall: 0.8438 - fmeasure: 0.8532\n",
      "OOD performance for instrument: piano\n",
      "Test accuracy: 0.8100000023841858\n",
      "Test recall: 0.8629032373428345\n",
      "Test percision: 0.84375\n",
      "Test f1-score: 0.85317462682724\n"
     ]
    }
   ],
   "source": [
    "test_ood(experiment3_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "danigil-steganalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
