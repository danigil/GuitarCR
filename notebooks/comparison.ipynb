{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent shape is (128, 107)\n",
      "src.model - INFO - Initializing CNN\n",
      "src.model - INFO - Input shape = (128, 107, 1)\n",
      "src.model - INFO - CNN Initialized\n",
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 05:45:25.667841: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600\n",
      "2023-05-22 05:45:26.566045: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 11s 13ms/step - loss: 2.2164 - accuracy: 0.1643 - precision: 0.2441 - recall: 0.0186 - fmeasure: 0.0341 - val_loss: 2.0004 - val_accuracy: 0.2988 - val_precision: 0.4285 - val_recall: 0.0575 - val_fmeasure: 0.0986\n",
      "Epoch 2/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 1.9687 - accuracy: 0.2874 - precision: 0.6346 - recall: 0.0967 - fmeasure: 0.1627 - val_loss: 1.6630 - val_accuracy: 0.3862 - val_precision: 0.6977 - val_recall: 0.2042 - val_fmeasure: 0.3040\n",
      "Epoch 3/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 1.7113 - accuracy: 0.3948 - precision: 0.7915 - recall: 0.2221 - fmeasure: 0.3377 - val_loss: 1.5544 - val_accuracy: 0.4650 - val_precision: 0.8126 - val_recall: 0.2867 - val_fmeasure: 0.4097\n",
      "Epoch 4/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 1.4857 - accuracy: 0.4866 - precision: 0.8320 - recall: 0.3099 - fmeasure: 0.4444 - val_loss: 1.2192 - val_accuracy: 0.5721 - val_precision: 0.9032 - val_recall: 0.3746 - val_fmeasure: 0.5175\n",
      "Epoch 5/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 1.1879 - accuracy: 0.5765 - precision: 0.8710 - recall: 0.4022 - fmeasure: 0.5425 - val_loss: 0.8791 - val_accuracy: 0.7117 - val_precision: 0.9300 - val_recall: 0.4717 - val_fmeasure: 0.6167\n",
      "Epoch 6/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 1.0269 - accuracy: 0.6375 - precision: 0.8560 - recall: 0.4696 - fmeasure: 0.6003 - val_loss: 0.7741 - val_accuracy: 0.7300 - val_precision: 0.9005 - val_recall: 0.5842 - val_fmeasure: 0.6980\n",
      "Epoch 7/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.8908 - accuracy: 0.6851 - precision: 0.8539 - recall: 0.5328 - fmeasure: 0.6509 - val_loss: 0.6945 - val_accuracy: 0.7625 - val_precision: 0.8706 - val_recall: 0.6071 - val_fmeasure: 0.7030\n",
      "Epoch 8/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.7707 - accuracy: 0.7266 - precision: 0.8607 - recall: 0.5984 - fmeasure: 0.7022 - val_loss: 0.6350 - val_accuracy: 0.7887 - val_precision: 0.8908 - val_recall: 0.6550 - val_fmeasure: 0.7428\n",
      "Epoch 9/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.6722 - accuracy: 0.7597 - precision: 0.8598 - recall: 0.6555 - fmeasure: 0.7410 - val_loss: 0.6004 - val_accuracy: 0.8062 - val_precision: 0.8782 - val_recall: 0.7296 - val_fmeasure: 0.7910\n",
      "Epoch 10/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.6538 - accuracy: 0.7704 - precision: 0.8637 - recall: 0.6797 - fmeasure: 0.7580 - val_loss: 0.5812 - val_accuracy: 0.8196 - val_precision: 0.8681 - val_recall: 0.7658 - val_fmeasure: 0.8089\n",
      "Epoch 11/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.6778 - accuracy: 0.7702 - precision: 0.8577 - recall: 0.6865 - fmeasure: 0.7599 - val_loss: 0.4876 - val_accuracy: 0.8292 - val_precision: 0.8669 - val_recall: 0.7788 - val_fmeasure: 0.8164\n",
      "Epoch 12/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.5642 - accuracy: 0.7983 - precision: 0.8635 - recall: 0.7288 - fmeasure: 0.7883 - val_loss: 0.5204 - val_accuracy: 0.8096 - val_precision: 0.8516 - val_recall: 0.7721 - val_fmeasure: 0.8068\n",
      "Epoch 13/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.5471 - accuracy: 0.8114 - precision: 0.8717 - recall: 0.7454 - fmeasure: 0.8018 - val_loss: 0.4613 - val_accuracy: 0.8396 - val_precision: 0.8677 - val_recall: 0.8096 - val_fmeasure: 0.8360\n",
      "Epoch 14/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.4719 - accuracy: 0.8271 - precision: 0.8774 - recall: 0.7762 - fmeasure: 0.8221 - val_loss: 0.3322 - val_accuracy: 0.8829 - val_precision: 0.9063 - val_recall: 0.8354 - val_fmeasure: 0.8673\n",
      "Epoch 15/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.4387 - accuracy: 0.8470 - precision: 0.8914 - recall: 0.8015 - fmeasure: 0.8428 - val_loss: 0.3942 - val_accuracy: 0.8900 - val_precision: 0.9111 - val_recall: 0.8567 - val_fmeasure: 0.8815\n",
      "Epoch 16/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.4823 - accuracy: 0.8380 - precision: 0.8805 - recall: 0.7985 - fmeasure: 0.8362 - val_loss: 0.3186 - val_accuracy: 0.8996 - val_precision: 0.9196 - val_recall: 0.8704 - val_fmeasure: 0.8931\n",
      "Epoch 17/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.4390 - accuracy: 0.8545 - precision: 0.8906 - recall: 0.8141 - fmeasure: 0.8495 - val_loss: 0.3674 - val_accuracy: 0.8788 - val_precision: 0.8996 - val_recall: 0.8600 - val_fmeasure: 0.8784\n",
      "Epoch 18/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.5175 - accuracy: 0.8452 - precision: 0.8857 - recall: 0.7995 - fmeasure: 0.8390 - val_loss: 0.4158 - val_accuracy: 0.8771 - val_precision: 0.8948 - val_recall: 0.8521 - val_fmeasure: 0.8719\n",
      "Epoch 19/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.4753 - accuracy: 0.8505 - precision: 0.8893 - recall: 0.8133 - fmeasure: 0.8486 - val_loss: 0.3211 - val_accuracy: 0.9038 - val_precision: 0.9174 - val_recall: 0.8842 - val_fmeasure: 0.8998\n",
      "Epoch 20/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.3230 - accuracy: 0.8868 - precision: 0.9119 - recall: 0.8587 - fmeasure: 0.8838 - val_loss: 0.2869 - val_accuracy: 0.9129 - val_precision: 0.9280 - val_recall: 0.8971 - val_fmeasure: 0.9115\n",
      "Epoch 21/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.3805 - accuracy: 0.8803 - precision: 0.9058 - recall: 0.8536 - fmeasure: 0.8782 - val_loss: 0.4989 - val_accuracy: 0.9042 - val_precision: 0.9263 - val_recall: 0.8813 - val_fmeasure: 0.9019\n",
      "Epoch 22/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.4019 - accuracy: 0.8771 - precision: 0.9074 - recall: 0.8470 - fmeasure: 0.8753 - val_loss: 0.2756 - val_accuracy: 0.9087 - val_precision: 0.9232 - val_recall: 0.8988 - val_fmeasure: 0.9103\n",
      "Epoch 23/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.3106 - accuracy: 0.8941 - precision: 0.9196 - recall: 0.8728 - fmeasure: 0.8950 - val_loss: 0.3563 - val_accuracy: 0.9087 - val_precision: 0.9234 - val_recall: 0.8954 - val_fmeasure: 0.9086\n",
      "Epoch 24/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.3317 - accuracy: 0.8973 - precision: 0.9216 - recall: 0.8758 - fmeasure: 0.8975 - val_loss: 0.2470 - val_accuracy: 0.9254 - val_precision: 0.9359 - val_recall: 0.9079 - val_fmeasure: 0.9211\n",
      "Epoch 25/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.2755 - accuracy: 0.9066 - precision: 0.9284 - recall: 0.8875 - fmeasure: 0.9070 - val_loss: 0.1720 - val_accuracy: 0.9450 - val_precision: 0.9520 - val_recall: 0.9375 - val_fmeasure: 0.9444\n",
      "Epoch 26/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.3472 - accuracy: 0.8993 - precision: 0.9193 - recall: 0.8771 - fmeasure: 0.8971 - val_loss: 0.2174 - val_accuracy: 0.9346 - val_precision: 0.9436 - val_recall: 0.9229 - val_fmeasure: 0.9327\n",
      "Epoch 27/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.3925 - accuracy: 0.8883 - precision: 0.9131 - recall: 0.8648 - fmeasure: 0.8876 - val_loss: 0.2493 - val_accuracy: 0.9204 - val_precision: 0.9362 - val_recall: 0.9025 - val_fmeasure: 0.9185\n",
      "Epoch 28/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.3088 - accuracy: 0.9020 - precision: 0.9240 - recall: 0.8821 - fmeasure: 0.9020 - val_loss: 0.2025 - val_accuracy: 0.9383 - val_precision: 0.9453 - val_recall: 0.9271 - val_fmeasure: 0.9358\n",
      "Epoch 29/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.2742 - accuracy: 0.9165 - precision: 0.9334 - recall: 0.8999 - fmeasure: 0.9159 - val_loss: 0.2075 - val_accuracy: 0.9337 - val_precision: 0.9425 - val_recall: 0.9229 - val_fmeasure: 0.9322\n",
      "Epoch 30/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.2997 - accuracy: 0.9101 - precision: 0.9318 - recall: 0.8915 - fmeasure: 0.9107 - val_loss: 0.2157 - val_accuracy: 0.9371 - val_precision: 0.9439 - val_recall: 0.9242 - val_fmeasure: 0.9335\n",
      "Epoch 31/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.3006 - accuracy: 0.9111 - precision: 0.9288 - recall: 0.8953 - fmeasure: 0.9113 - val_loss: 0.2479 - val_accuracy: 0.9321 - val_precision: 0.9431 - val_recall: 0.9217 - val_fmeasure: 0.9318\n",
      "Epoch 32/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.3771 - accuracy: 0.9005 - precision: 0.9259 - recall: 0.8744 - fmeasure: 0.8986 - val_loss: 0.2130 - val_accuracy: 0.9371 - val_precision: 0.9461 - val_recall: 0.9271 - val_fmeasure: 0.9362\n",
      "Epoch 33/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.2306 - accuracy: 0.9274 - precision: 0.9428 - recall: 0.9106 - fmeasure: 0.9260 - val_loss: 0.1637 - val_accuracy: 0.9467 - val_precision: 0.9552 - val_recall: 0.9367 - val_fmeasure: 0.9455\n",
      "Epoch 34/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.2243 - accuracy: 0.9284 - precision: 0.9423 - recall: 0.9141 - fmeasure: 0.9276 - val_loss: 0.1646 - val_accuracy: 0.9483 - val_precision: 0.9551 - val_recall: 0.9450 - val_fmeasure: 0.9499\n",
      "Epoch 35/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.2498 - accuracy: 0.9300 - precision: 0.9440 - recall: 0.9167 - fmeasure: 0.9298 - val_loss: 0.2576 - val_accuracy: 0.9367 - val_precision: 0.9485 - val_recall: 0.9221 - val_fmeasure: 0.9343\n",
      "Epoch 36/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.3075 - accuracy: 0.9206 - precision: 0.9367 - recall: 0.9043 - fmeasure: 0.9198 - val_loss: 0.1926 - val_accuracy: 0.9421 - val_precision: 0.9488 - val_recall: 0.9346 - val_fmeasure: 0.9413\n",
      "Epoch 37/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.2130 - accuracy: 0.9302 - precision: 0.9437 - recall: 0.9180 - fmeasure: 0.9303 - val_loss: 0.1703 - val_accuracy: 0.9508 - val_precision: 0.9565 - val_recall: 0.9396 - val_fmeasure: 0.9477\n",
      "Epoch 38/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.2000 - accuracy: 0.9409 - precision: 0.9537 - recall: 0.9293 - fmeasure: 0.9410 - val_loss: 0.2091 - val_accuracy: 0.9533 - val_precision: 0.9579 - val_recall: 0.9487 - val_fmeasure: 0.9532\n",
      "Epoch 39/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.2119 - accuracy: 0.9407 - precision: 0.9520 - recall: 0.9305 - fmeasure: 0.9409 - val_loss: 0.2892 - val_accuracy: 0.9458 - val_precision: 0.9547 - val_recall: 0.9392 - val_fmeasure: 0.9466\n",
      "Epoch 40/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.2600 - accuracy: 0.9307 - precision: 0.9445 - recall: 0.9191 - fmeasure: 0.9313 - val_loss: 0.2343 - val_accuracy: 0.9529 - val_precision: 0.9594 - val_recall: 0.9437 - val_fmeasure: 0.9513\n",
      "Epoch 41/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.2218 - accuracy: 0.9333 - precision: 0.9491 - recall: 0.9202 - fmeasure: 0.9341 - val_loss: 0.1641 - val_accuracy: 0.9588 - val_precision: 0.9634 - val_recall: 0.9512 - val_fmeasure: 0.9571\n",
      "Epoch 42/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.1894 - accuracy: 0.9466 - precision: 0.9565 - recall: 0.9352 - fmeasure: 0.9455 - val_loss: 0.1639 - val_accuracy: 0.9504 - val_precision: 0.9586 - val_recall: 0.9442 - val_fmeasure: 0.9510\n",
      "Epoch 43/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.2426 - accuracy: 0.9333 - precision: 0.9479 - recall: 0.9216 - fmeasure: 0.9342 - val_loss: 0.1767 - val_accuracy: 0.9521 - val_precision: 0.9630 - val_recall: 0.9387 - val_fmeasure: 0.9502\n",
      "Epoch 44/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.2951 - accuracy: 0.9294 - precision: 0.9438 - recall: 0.9144 - fmeasure: 0.9284 - val_loss: 0.1750 - val_accuracy: 0.9563 - val_precision: 0.9646 - val_recall: 0.9487 - val_fmeasure: 0.9564\n",
      "Epoch 45/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.2322 - accuracy: 0.9404 - precision: 0.9541 - recall: 0.9304 - fmeasure: 0.9418 - val_loss: 0.1985 - val_accuracy: 0.9654 - val_precision: 0.9701 - val_recall: 0.9583 - val_fmeasure: 0.9639\n",
      "Epoch 46/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.2312 - accuracy: 0.9419 - precision: 0.9537 - recall: 0.9326 - fmeasure: 0.9427 - val_loss: 0.1964 - val_accuracy: 0.9546 - val_precision: 0.9615 - val_recall: 0.9496 - val_fmeasure: 0.9553\n",
      "Epoch 47/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.1624 - accuracy: 0.9504 - precision: 0.9606 - recall: 0.9424 - fmeasure: 0.9512 - val_loss: 0.2067 - val_accuracy: 0.9629 - val_precision: 0.9673 - val_recall: 0.9596 - val_fmeasure: 0.9633\n",
      "Epoch 48/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.1671 - accuracy: 0.9491 - precision: 0.9573 - recall: 0.9390 - fmeasure: 0.9478 - val_loss: 0.1903 - val_accuracy: 0.9492 - val_precision: 0.9558 - val_recall: 0.9442 - val_fmeasure: 0.9497\n",
      "Epoch 49/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.2951 - accuracy: 0.9340 - precision: 0.9470 - recall: 0.9219 - fmeasure: 0.9339 - val_loss: 0.2263 - val_accuracy: 0.9358 - val_precision: 0.9483 - val_recall: 0.9175 - val_fmeasure: 0.9319\n",
      "Epoch 50/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.2348 - accuracy: 0.9395 - precision: 0.9517 - recall: 0.9309 - fmeasure: 0.9409 - val_loss: 0.1771 - val_accuracy: 0.9533 - val_precision: 0.9633 - val_recall: 0.9437 - val_fmeasure: 0.9530\n",
      "Epoch 51/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.1595 - accuracy: 0.9520 - precision: 0.9626 - recall: 0.9436 - fmeasure: 0.9528 - val_loss: 0.1449 - val_accuracy: 0.9554 - val_precision: 0.9614 - val_recall: 0.9513 - val_fmeasure: 0.9561\n",
      "Epoch 52/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.1993 - accuracy: 0.9489 - precision: 0.9594 - recall: 0.9403 - fmeasure: 0.9495 - val_loss: 0.2486 - val_accuracy: 0.9375 - val_precision: 0.9467 - val_recall: 0.9321 - val_fmeasure: 0.9391\n",
      "Epoch 53/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.2035 - accuracy: 0.9463 - precision: 0.9563 - recall: 0.9368 - fmeasure: 0.9462 - val_loss: 0.1928 - val_accuracy: 0.9558 - val_precision: 0.9608 - val_recall: 0.9492 - val_fmeasure: 0.9548\n",
      "Epoch 54/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.2477 - accuracy: 0.9429 - precision: 0.9547 - recall: 0.9338 - fmeasure: 0.9438 - val_loss: 0.2003 - val_accuracy: 0.9488 - val_precision: 0.9550 - val_recall: 0.9429 - val_fmeasure: 0.9487\n",
      "Epoch 55/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.2047 - accuracy: 0.9472 - precision: 0.9572 - recall: 0.9374 - fmeasure: 0.9469 - val_loss: 0.1980 - val_accuracy: 0.9521 - val_precision: 0.9571 - val_recall: 0.9454 - val_fmeasure: 0.9510\n",
      "Epoch 56/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.1613 - accuracy: 0.9561 - precision: 0.9642 - recall: 0.9491 - fmeasure: 0.9564 - val_loss: 0.2546 - val_accuracy: 0.9529 - val_precision: 0.9570 - val_recall: 0.9487 - val_fmeasure: 0.9527\n",
      "Epoch 57/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.1459 - accuracy: 0.9588 - precision: 0.9668 - recall: 0.9517 - fmeasure: 0.9589 - val_loss: 0.1279 - val_accuracy: 0.9650 - val_precision: 0.9692 - val_recall: 0.9637 - val_fmeasure: 0.9664\n",
      "Epoch 58/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.1465 - accuracy: 0.9574 - precision: 0.9661 - recall: 0.9504 - fmeasure: 0.9580 - val_loss: 0.1531 - val_accuracy: 0.9638 - val_precision: 0.9677 - val_recall: 0.9600 - val_fmeasure: 0.9637\n",
      "Epoch 59/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.2978 - accuracy: 0.9345 - precision: 0.9486 - recall: 0.9218 - fmeasure: 0.9346 - val_loss: 0.2856 - val_accuracy: 0.9317 - val_precision: 0.9497 - val_recall: 0.9196 - val_fmeasure: 0.9338\n",
      "Epoch 60/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.1890 - accuracy: 0.9461 - precision: 0.9572 - recall: 0.9357 - fmeasure: 0.9461 - val_loss: 0.2633 - val_accuracy: 0.9517 - val_precision: 0.9582 - val_recall: 0.9412 - val_fmeasure: 0.9493\n",
      "Epoch 61/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.1419 - accuracy: 0.9620 - precision: 0.9699 - recall: 0.9551 - fmeasure: 0.9623 - val_loss: 0.1505 - val_accuracy: 0.9692 - val_precision: 0.9739 - val_recall: 0.9658 - val_fmeasure: 0.9697\n",
      "Epoch 62/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.1069 - accuracy: 0.9647 - precision: 0.9719 - recall: 0.9590 - fmeasure: 0.9652 - val_loss: 0.1957 - val_accuracy: 0.9629 - val_precision: 0.9686 - val_recall: 0.9604 - val_fmeasure: 0.9644\n",
      "Epoch 63/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.1272 - accuracy: 0.9627 - precision: 0.9704 - recall: 0.9566 - fmeasure: 0.9632 - val_loss: 0.1972 - val_accuracy: 0.9675 - val_precision: 0.9682 - val_recall: 0.9654 - val_fmeasure: 0.9668\n",
      "Epoch 64/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.2996 - accuracy: 0.9352 - precision: 0.9474 - recall: 0.9260 - fmeasure: 0.9363 - val_loss: 0.3093 - val_accuracy: 0.9575 - val_precision: 0.9634 - val_recall: 0.9529 - val_fmeasure: 0.9580\n",
      "Epoch 65/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.1909 - accuracy: 0.9501 - precision: 0.9610 - recall: 0.9424 - fmeasure: 0.9514 - val_loss: 0.1735 - val_accuracy: 0.9613 - val_precision: 0.9679 - val_recall: 0.9596 - val_fmeasure: 0.9636\n",
      "Epoch 66/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.2148 - accuracy: 0.9536 - precision: 0.9627 - recall: 0.9445 - fmeasure: 0.9533 - val_loss: 0.1583 - val_accuracy: 0.9550 - val_precision: 0.9617 - val_recall: 0.9479 - val_fmeasure: 0.9545\n",
      "Epoch 67/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.2286 - accuracy: 0.9461 - precision: 0.9581 - recall: 0.9350 - fmeasure: 0.9461 - val_loss: 0.2345 - val_accuracy: 0.9558 - val_precision: 0.9614 - val_recall: 0.9437 - val_fmeasure: 0.9522\n",
      "Epoch 68/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.1462 - accuracy: 0.9591 - precision: 0.9677 - recall: 0.9517 - fmeasure: 0.9594 - val_loss: 0.3613 - val_accuracy: 0.9646 - val_precision: 0.9696 - val_recall: 0.9600 - val_fmeasure: 0.9646\n",
      "Epoch 69/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.2814 - accuracy: 0.9431 - precision: 0.9532 - recall: 0.9340 - fmeasure: 0.9432 - val_loss: 0.3606 - val_accuracy: 0.9483 - val_precision: 0.9569 - val_recall: 0.9446 - val_fmeasure: 0.9506\n",
      "Epoch 70/70\n",
      "480/480 [==============================] - 6s 12ms/step - loss: 0.3096 - accuracy: 0.9396 - precision: 0.9505 - recall: 0.9286 - fmeasure: 0.9391 - val_loss: 0.3413 - val_accuracy: 0.9279 - val_precision: 0.9437 - val_recall: 0.9100 - val_fmeasure: 0.9258\n",
      "75/75 [==============================] - 1s 7ms/step - loss: 0.3413 - accuracy: 0.9279 - precision: 0.9437 - recall: 0.9100 - fmeasure: 0.9259\n",
      "Test loss: 0.3412608802318573\n",
      "Test accuracy: 0.9279166460037231\n",
      "Test precision: 0.9437494874000549\n",
      "Test recall: 0.9100000262260437\n",
      "Test f1-score: 0.9258784055709839\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os, sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from settings import *\n",
    "from my_train import *\n",
    "from src.model import CNN\n",
    "\n",
    "_, datasets_augmented, size = load_data(None, METADATA_DIR_AUGMENTED_RAW, instruments=[], instruments_aug=['Guitar'])\n",
    "datasets_augmented = list(map(lambda df: df[~df['augmentation'].isin(['GN_10db', 'GN_20db', 'GN_30db'])].reset_index(drop=True),datasets_augmented))\n",
    "\n",
    "dataset_raw = datasets_augmented[0]\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "def over_sample(df):\n",
    "    def get_class(class_ID):\n",
    "        return list(CLASSES_MAP.keys())[list(CLASSES_MAP.values()).index(class_ID)]\n",
    "    oversample = RandomOverSampler(sampling_strategy='auto')\n",
    "    X, y = df[['spectrogram', 'augmentation']].values, df['class_ID'].values\n",
    "#     X = X.reshape(-1, 1)\n",
    "    X, y = oversample.fit_resample(X, y)\n",
    "    df = pd.DataFrame()\n",
    "    df['spectrogram'] = pd.Series([np.array(x[0]) for x in X])\n",
    "    df['augmentation'] = pd.Series([np.array(x[1]) for x in X])\n",
    "    df['augmentation'] = df['augmentation'].map(lambda x: str(x))\n",
    "    df['class_ID'] = pd.Series(y)\n",
    "    df['class_name'] = df['class_ID'].map(lambda x: get_class(x))\n",
    "    return df\n",
    "\n",
    "def clean_shape(df):\n",
    "    max_shape = df['spectrogram'].map(lambda x: x.shape).value_counts().index[0]\n",
    "    print(f\"The most frequent shape is {max_shape}\")\n",
    "    df['shape'] = df['spectrogram'].map(lambda x: x.shape)\n",
    "    df = df[df['shape']==max_shape]\n",
    "    df.drop(columns='shape', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "def process_augmented(df):\n",
    "    df = (df.pipe(clean_shape)\n",
    "            .pipe(over_sample)\n",
    "    )\n",
    "    df = df[['spectrogram','class_ID', 'class_name', 'augmentation']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "dataset = process_augmented(dataset_raw)\n",
    "\n",
    "np.random.seed(42)\n",
    "sample = np.random.choice(dataset.index, size=int(len(dataset)*0.8), replace=False)\n",
    "train_data, test_data = dataset.iloc[sample], dataset.drop(sample)\n",
    "\n",
    "X_train = train_data['spectrogram']\n",
    "y_train = train_data['class_ID']\n",
    "X_test = test_data['spectrogram']\n",
    "y_test = test_data['class_ID']\n",
    "\n",
    "X_train = np.array([x.reshape( (128, 107, 1) ) for x in X_train])\n",
    "X_test = np.array([x.reshape( (128, 107, 1) ) for x in X_test])\n",
    "\n",
    "y_train = np.array(keras.utils.to_categorical(y_train, 10))\n",
    "y_test_values=y_test\n",
    "y_test = np.array(keras.utils.to_categorical(y_test, 10))\n",
    "\n",
    "cnn = CNN((128, 107))\n",
    "model = cnn.model\n",
    "\n",
    "model.compile(\n",
    "\toptimizer=\"Adam\",\n",
    "\tloss=\"categorical_crossentropy\",\n",
    "\tmetrics=['accuracy', precision, recall,fmeasure])\n",
    "\n",
    "model.fit(\n",
    "\tx=X_train, \n",
    "\ty=y_train,\n",
    "    epochs=70,\n",
    "    batch_size=20,\n",
    "    validation_data= (X_test, y_test))\n",
    "\n",
    "score = model.evaluate(\n",
    "\tx=X_test,\n",
    "\ty=y_test)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test precision:', score[2])\n",
    "print('Test recall:', score[3])\n",
    "print('Test f1-score:', score[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.model - INFO - Saving model\n",
      "src.model - INFO - Saved model to /home/tzag/danigil/dl/guitarCR/models\n"
     ]
    }
   ],
   "source": [
    "cnn.save_model(\"baseline_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_raw, _, size = load_data(METADATA_DIR_RAW, None, instruments=['Piano', 'Accordion', 'Violin'], instruments_aug=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "cannot convert float infinity to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m y_test_values\u001b[39m=\u001b[39my_test\n\u001b[1;32m     20\u001b[0m y_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(keras\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mto_categorical(y_test, \u001b[39m10\u001b[39m))\n\u001b[0;32m---> 22\u001b[0m score \u001b[39m=\u001b[39m cnn\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mevaluate(X_test,y_test)\n\u001b[1;32m     23\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTest score for instrument: \u001b[39m\u001b[39m{\u001b[39;00minstrument\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mTest loss:\u001b[39m\u001b[39m'\u001b[39m, score[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/danigil-steganalysis/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/danigil-steganalysis/lib/python3.8/site-packages/keras/utils/generic_utils.py:239\u001b[0m, in \u001b[0;36mProgbar.update\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    236\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    238\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 239\u001b[0m     numdigits \u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m(np\u001b[39m.\u001b[39;49mlog10(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget)) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    240\u001b[0m     bar \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(numdigits) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39md/\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m [\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m%\u001b[39m (current, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget)\n\u001b[1;32m    241\u001b[0m     prog \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(current) \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget\n",
      "\u001b[0;31mOverflowError\u001b[0m: cannot convert float infinity to integer"
     ]
    }
   ],
   "source": [
    "test_instruments = ['Piano', 'Accordion', 'Violin']\n",
    "for test_data, instrument in zip(datasets_raw, test_instruments):\n",
    "    X_test = test_data['spectrogram']\n",
    "    reshaped = [0] * len(X_test)\n",
    "    for i, x in enumerate(X_test):\n",
    "        try:\n",
    "            reshapen = x.reshape((128, 107, 1))\n",
    "            reshaped[i] = reshapen\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    idxs = [i for i in range(len(reshaped)) if reshaped[i]==0]\n",
    "    \n",
    "    X_test = np.array(list(filter(lambda x: x!=0, reshaped)))\n",
    "    #X_test = np.array([x.reshape( (128, 107, 1) ) for x in X_test])\n",
    "    y_test = test_data['class_ID']\n",
    "    y_test.drop(index=idxs, inplace=True)\n",
    "\n",
    "    y_test_values=y_test\n",
    "    y_test = np.array(keras.utils.to_categorical(y_test, 10))\n",
    "\n",
    "    score = cnn.model.evaluate(X_test,y_test)\n",
    "    print(f'Test score for instrument: {instrument}')\n",
    "    print('\\tTest loss:', score[0])\n",
    "    print('\\tTest accuracy:', score[1])\n",
    "    print('\\tTest precision:', score[2])\n",
    "    print('\\tTest recall:', score[3])\n",
    "    print('\\tTest f1-score:', score[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "danigil-steganalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
