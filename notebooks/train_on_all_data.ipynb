{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 13:43:20.537442: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-19 13:43:20.673879: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-19 13:43:21.280696: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvrtc.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-19 13:43:21.280795: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-19 13:43:21.280805: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import pandas as pd\n",
    "from src.metrics import *\n",
    "from settings import *\n",
    "from src.data import generate\n",
    "\n",
    "instruments = ['Guitar', 'Accordion', 'Violin']\n",
    "\n",
    "# from setup_logging import setup_logging\n",
    "# setup_logging()\n",
    "\n",
    "#generate.my_run(instruments)\n",
    "datasets = [pd.read_pickle(os.path.join(METADATA_DIR_PROCESSED_NORMALIZED, f'data_{instrument.lower()}.pkl')) for instrument in instruments]\n",
    "datasets_augmented = [pd.read_pickle(os.path.join(METADATA_DIR_PROCESSED_NORMALIZED, f'data_{instrument.lower()}.pkl')) for instrument in instruments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(128, 87), (128, 87), (128, 87)]\n"
     ]
    }
   ],
   "source": [
    "print([dataset['spectrogram'][1].shape for dataset in datasets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.processing - INFO - Start train test split with split ratio: 0.8\n",
      "src.processing - INFO - Number of training samples is 1600\n",
      "src.processing - INFO - Number of testing samples is 400\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.8\n",
      "src.processing - INFO - Number of training samples is 80\n",
      "src.processing - INFO - Number of testing samples is 20\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.8\n",
      "src.processing - INFO - Number of training samples is 80\n",
      "src.processing - INFO - Number of testing samples is 20\n",
      "src.processing - INFO - Train test split completed\n",
      "The most frequent shape is (128, 87)\n",
      "src.train - INFO - Number of train samples: 1760\n",
      "src.train - INFO - Number of test samples: 440\n",
      "src.processing - INFO - Start feature target split\n",
      "src.processing - INFO - Feature target split completed\n",
      "src.processing - INFO - Start feature target split\n",
      "src.processing - INFO - Feature target split completed\n",
      "src.processing - INFO - Features reshaped for CNN Input\n",
      "src.processing - INFO - Features reshaped for CNN Input\n",
      "src.processing - INFO - Target one hot encoded\n",
      "src.processing - INFO - Target one hot encoded\n",
      "src.model - INFO - Initializing CNN\n",
      "src.model - INFO - Input shape = (128, 87, 1)\n",
      "src.model - INFO - CNN Initialized\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 124, 83, 24)       624       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 41, 24)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " activation (Activation)     (None, 31, 41, 24)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 27, 37, 48)        28848     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 18, 48)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 6, 18, 48)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 2, 14, 48)         57648     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 2, 14, 48)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1344)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1344)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                86080     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 173,850\n",
      "Trainable params: 173,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "src.train - INFO - None\n",
      "src.model - INFO - Start training model\n",
      "src.model - INFO - Tensorboard Logging Started\n",
      "src.model - INFO - Use the following command in the terminal to view the logs during training: tensorboard --logdir logs/training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 13:43:39.165944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22324 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:3b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 13:43:42.239176: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600\n",
      "2023-05-19 13:43:43.012887: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - ETA: 0s - loss: 2.8050 - accuracy: 0.1068 - precision: 0.0667 - recall: 0.0063 - fmeasure: 0.0110src.model - INFO - {Epoch: 0} loss: 2.804950, accuracy: 0.106818, precision: 0.066667, recall: 0.006250, fmeasure: 0.011024, val_loss: 2.290059, val_accuracy: 0.109091, val_precision: 0.000000, val_recall: 0.000000, val_fmeasure: 0.000000\n",
      "88/88 [==============================] - 6s 15ms/step - loss: 2.8050 - accuracy: 0.1068 - precision: 0.0667 - recall: 0.0063 - fmeasure: 0.0110 - val_loss: 2.2901 - val_accuracy: 0.1091 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fmeasure: 0.0000e+00\n",
      "Epoch 2/67\n",
      "84/88 [===========================>..] - ETA: 0s - loss: 2.2778 - accuracy: 0.1482 - precision: 0.1012 - recall: 0.0060 - fmeasure: 0.0112src.model - INFO - {Epoch: 1} loss: 2.275299, accuracy: 0.150000, precision: 0.107955, recall: 0.006250, fmeasure: 0.011757, val_loss: 2.232690, val_accuracy: 0.156818, val_precision: 0.045455, val_recall: 0.004545, val_fmeasure: 0.008264\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 2.2753 - accuracy: 0.1500 - precision: 0.1080 - recall: 0.0063 - fmeasure: 0.0118 - val_loss: 2.2327 - val_accuracy: 0.1568 - val_precision: 0.0455 - val_recall: 0.0045 - val_fmeasure: 0.0083\n",
      "Epoch 3/67\n",
      "84/88 [===========================>..] - ETA: 0s - loss: 2.2572 - accuracy: 0.1708 - precision: 0.2123 - recall: 0.0173 - fmeasure: 0.0314src.model - INFO - {Epoch: 2} loss: 2.255720, accuracy: 0.167614, precision: 0.225379, recall: 0.017614, fmeasure: 0.032166, val_loss: 2.224113, val_accuracy: 0.184091, val_precision: 0.045455, val_recall: 0.002273, val_fmeasure: 0.004329\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 2.2557 - accuracy: 0.1676 - precision: 0.2254 - recall: 0.0176 - fmeasure: 0.0322 - val_loss: 2.2241 - val_accuracy: 0.1841 - val_precision: 0.0455 - val_recall: 0.0023 - val_fmeasure: 0.0043\n",
      "Epoch 4/67\n",
      "88/88 [==============================] - ETA: 0s - loss: 2.2103 - accuracy: 0.1937 - precision: 0.1875 - recall: 0.0131 - fmeasure: 0.0242src.model - INFO - {Epoch: 3} loss: 2.210302, accuracy: 0.193750, precision: 0.187500, recall: 0.013068, fmeasure: 0.024167, val_loss: 2.107339, val_accuracy: 0.227273, val_precision: 0.186147, val_recall: 0.020455, val_fmeasure: 0.034929\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 2.2103 - accuracy: 0.1937 - precision: 0.1875 - recall: 0.0131 - fmeasure: 0.0242 - val_loss: 2.1073 - val_accuracy: 0.2273 - val_precision: 0.1861 - val_recall: 0.0205 - val_fmeasure: 0.0349\n",
      "Epoch 5/67\n",
      "86/88 [============================>.] - ETA: 0s - loss: 2.1292 - accuracy: 0.2215 - precision: 0.3884 - recall: 0.0337 - fmeasure: 0.0605src.model - INFO - {Epoch: 4} loss: 2.132070, accuracy: 0.221023, precision: 0.385227, recall: 0.033523, fmeasure: 0.060171, val_loss: 2.063922, val_accuracy: 0.236364, val_precision: 0.242424, val_recall: 0.047727, val_fmeasure: 0.078387\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 2.1321 - accuracy: 0.2210 - precision: 0.3852 - recall: 0.0335 - fmeasure: 0.0602 - val_loss: 2.0639 - val_accuracy: 0.2364 - val_precision: 0.2424 - val_recall: 0.0477 - val_fmeasure: 0.0784\n",
      "Epoch 6/67\n",
      "86/88 [============================>.] - ETA: 0s - loss: 2.1110 - accuracy: 0.2413 - precision: 0.5225 - recall: 0.0593 - fmeasure: 0.1030src.model - INFO - {Epoch: 5} loss: 2.110724, accuracy: 0.243182, precision: 0.521970, recall: 0.058523, fmeasure: 0.101728, val_loss: 2.085310, val_accuracy: 0.263636, val_precision: 0.265152, val_recall: 0.027273, val_fmeasure: 0.048723\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 2.1107 - accuracy: 0.2432 - precision: 0.5220 - recall: 0.0585 - fmeasure: 0.1017 - val_loss: 2.0853 - val_accuracy: 0.2636 - val_precision: 0.2652 - val_recall: 0.0273 - val_fmeasure: 0.0487\n",
      "Epoch 7/67\n",
      "88/88 [==============================] - ETA: 0s - loss: 2.0307 - accuracy: 0.2705 - precision: 0.6047 - recall: 0.0761 - fmeasure: 0.1321src.model - INFO - {Epoch: 6} loss: 2.030667, accuracy: 0.270455, precision: 0.604708, recall: 0.076136, fmeasure: 0.132110, val_loss: 1.868575, val_accuracy: 0.327273, val_precision: 0.539394, val_recall: 0.106818, val_fmeasure: 0.170139\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 2.0307 - accuracy: 0.2705 - precision: 0.6047 - recall: 0.0761 - fmeasure: 0.1321 - val_loss: 1.8686 - val_accuracy: 0.3273 - val_precision: 0.5394 - val_recall: 0.1068 - val_fmeasure: 0.1701\n",
      "Epoch 8/67\n",
      "86/88 [============================>.] - ETA: 0s - loss: 1.9176 - accuracy: 0.3017 - precision: 0.6857 - recall: 0.1064 - fmeasure: 0.1793src.model - INFO - {Epoch: 7} loss: 1.915734, accuracy: 0.303977, precision: 0.687121, recall: 0.107386, fmeasure: 0.180936, val_loss: 1.763432, val_accuracy: 0.440909, val_precision: 0.710227, val_recall: 0.129545, val_fmeasure: 0.210200\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 1.9157 - accuracy: 0.3040 - precision: 0.6871 - recall: 0.1074 - fmeasure: 0.1809 - val_loss: 1.7634 - val_accuracy: 0.4409 - val_precision: 0.7102 - val_recall: 0.1295 - val_fmeasure: 0.2102\n",
      "Epoch 9/67\n",
      "84/88 [===========================>..] - ETA: 0s - loss: 1.8810 - accuracy: 0.3304 - precision: 0.7122 - recall: 0.1268 - fmeasure: 0.2104src.model - INFO - {Epoch: 8} loss: 1.879939, accuracy: 0.328977, precision: 0.706547, recall: 0.125568, fmeasure: 0.208513, val_loss: 1.817892, val_accuracy: 0.375000, val_precision: 0.581818, val_recall: 0.113636, val_fmeasure: 0.181777\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 1.8799 - accuracy: 0.3290 - precision: 0.7065 - recall: 0.1256 - fmeasure: 0.2085 - val_loss: 1.8179 - val_accuracy: 0.3750 - val_precision: 0.5818 - val_recall: 0.1136 - val_fmeasure: 0.1818\n",
      "Epoch 10/67\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 1.7889 - accuracy: 0.3659 - precision: 0.7324 - recall: 0.1700 - fmeasure: 0.2703src.model - INFO - {Epoch: 9} loss: 1.782998, accuracy: 0.369318, precision: 0.733559, recall: 0.171591, fmeasure: 0.272418, val_loss: 1.795273, val_accuracy: 0.384091, val_precision: 0.531313, val_recall: 0.140909, val_fmeasure: 0.213421\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 1.7830 - accuracy: 0.3693 - precision: 0.7336 - recall: 0.1716 - fmeasure: 0.2724 - val_loss: 1.7953 - val_accuracy: 0.3841 - val_precision: 0.5313 - val_recall: 0.1409 - val_fmeasure: 0.2134\n",
      "Epoch 11/67\n",
      "84/88 [===========================>..] - ETA: 0s - loss: 1.8365 - accuracy: 0.3435 - precision: 0.7779 - recall: 0.1631 - fmeasure: 0.2607src.model - INFO - {Epoch: 10} loss: 1.827600, accuracy: 0.350568, precision: 0.778119, recall: 0.165341, fmeasure: 0.263926, val_loss: 1.658048, val_accuracy: 0.443182, val_precision: 0.761111, val_recall: 0.197727, val_fmeasure: 0.301862\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 1.8276 - accuracy: 0.3506 - precision: 0.7781 - recall: 0.1653 - fmeasure: 0.2639 - val_loss: 1.6580 - val_accuracy: 0.4432 - val_precision: 0.7611 - val_recall: 0.1977 - val_fmeasure: 0.3019\n",
      "Epoch 12/67\n",
      "84/88 [===========================>..] - ETA: 0s - loss: 1.6390 - accuracy: 0.3923 - precision: 0.7860 - recall: 0.2244 - fmeasure: 0.3433src.model - INFO - {Epoch: 11} loss: 1.628264, accuracy: 0.394886, precision: 0.789786, recall: 0.228409, fmeasure: 0.348500, val_loss: 1.510931, val_accuracy: 0.486364, val_precision: 0.796501, val_recall: 0.270455, val_fmeasure: 0.393050\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 1.6283 - accuracy: 0.3949 - precision: 0.7898 - recall: 0.2284 - fmeasure: 0.3485 - val_loss: 1.5109 - val_accuracy: 0.4864 - val_precision: 0.7965 - val_recall: 0.2705 - val_fmeasure: 0.3930\n",
      "Epoch 13/67\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 1.6226 - accuracy: 0.4271 - precision: 0.7915 - recall: 0.2465 - fmeasure: 0.3673src.model - INFO - {Epoch: 12} loss: 1.631279, accuracy: 0.423864, precision: 0.787750, recall: 0.245455, fmeasure: 0.366015, val_loss: 1.418551, val_accuracy: 0.495455, val_precision: 0.810119, val_recall: 0.290909, val_fmeasure: 0.418192\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 1.6313 - accuracy: 0.4239 - precision: 0.7877 - recall: 0.2455 - fmeasure: 0.3660 - val_loss: 1.4186 - val_accuracy: 0.4955 - val_precision: 0.8101 - val_recall: 0.2909 - val_fmeasure: 0.4182\n",
      "Epoch 14/67\n",
      "86/88 [============================>.] - ETA: 0s - loss: 1.5538 - accuracy: 0.4506 - precision: 0.8433 - recall: 0.2808 - fmeasure: 0.4104src.model - INFO - {Epoch: 13} loss: 1.553992, accuracy: 0.450000, precision: 0.845456, recall: 0.280682, fmeasure: 0.410510, val_loss: 1.507818, val_accuracy: 0.504545, val_precision: 0.818884, val_recall: 0.279545, val_fmeasure: 0.402177\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 1.5540 - accuracy: 0.4500 - precision: 0.8455 - recall: 0.2807 - fmeasure: 0.4105 - val_loss: 1.5078 - val_accuracy: 0.5045 - val_precision: 0.8189 - val_recall: 0.2795 - val_fmeasure: 0.4022\n",
      "Epoch 15/67\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 1.5194 - accuracy: 0.4453 - precision: 0.8111 - recall: 0.2812 - fmeasure: 0.4100src.model - INFO - {Epoch: 14} loss: 1.517670, accuracy: 0.449432, precision: 0.816112, recall: 0.281818, fmeasure: 0.411531, val_loss: 1.307594, val_accuracy: 0.550000, val_precision: 0.843802, val_recall: 0.313636, val_fmeasure: 0.438918\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 1.5177 - accuracy: 0.4494 - precision: 0.8161 - recall: 0.2818 - fmeasure: 0.4115 - val_loss: 1.3076 - val_accuracy: 0.5500 - val_precision: 0.8438 - val_recall: 0.3136 - val_fmeasure: 0.4389\n",
      "Epoch 16/67\n",
      "83/88 [===========================>..] - ETA: 0s - loss: 1.3819 - accuracy: 0.5096 - precision: 0.8434 - recall: 0.3307 - fmeasure: 0.4673src.model - INFO - {Epoch: 15} loss: 1.382871, accuracy: 0.508523, precision: 0.843232, recall: 0.332955, fmeasure: 0.469285, val_loss: 1.628415, val_accuracy: 0.534091, val_precision: 0.812598, val_recall: 0.350000, val_fmeasure: 0.480984\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 1.3829 - accuracy: 0.5085 - precision: 0.8432 - recall: 0.3330 - fmeasure: 0.4693 - val_loss: 1.6284 - val_accuracy: 0.5341 - val_precision: 0.8126 - val_recall: 0.3500 - val_fmeasure: 0.4810\n",
      "Epoch 17/67\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 1.4088 - accuracy: 0.5082 - precision: 0.8318 - recall: 0.3365 - fmeasure: 0.4716src.model - INFO - {Epoch: 16} loss: 1.407565, accuracy: 0.508523, precision: 0.830360, recall: 0.333523, fmeasure: 0.467930, val_loss: 1.189835, val_accuracy: 0.604545, val_precision: 0.908976, val_recall: 0.381818, val_fmeasure: 0.531587\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 1.4076 - accuracy: 0.5085 - precision: 0.8304 - recall: 0.3335 - fmeasure: 0.4679 - val_loss: 1.1898 - val_accuracy: 0.6045 - val_precision: 0.9090 - val_recall: 0.3818 - val_fmeasure: 0.5316\n",
      "Epoch 18/67\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.2933 - accuracy: 0.5375 - precision: 0.8645 - recall: 0.3705 - fmeasure: 0.5132src.model - INFO - {Epoch: 17} loss: 1.293316, accuracy: 0.537500, precision: 0.864450, recall: 0.370455, fmeasure: 0.513158, val_loss: 1.179703, val_accuracy: 0.579545, val_precision: 0.910422, val_recall: 0.393182, val_fmeasure: 0.543107\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 1.2933 - accuracy: 0.5375 - precision: 0.8645 - recall: 0.3705 - fmeasure: 0.5132 - val_loss: 1.1797 - val_accuracy: 0.5795 - val_precision: 0.9104 - val_recall: 0.3932 - val_fmeasure: 0.5431\n",
      "Epoch 19/67\n",
      "84/88 [===========================>..] - ETA: 0s - loss: 1.2504 - accuracy: 0.5524 - precision: 0.8336 - recall: 0.3821 - fmeasure: 0.5159src.model - INFO - {Epoch: 18} loss: 1.258720, accuracy: 0.551136, precision: 0.833126, recall: 0.380114, fmeasure: 0.514141, val_loss: 1.134527, val_accuracy: 0.606818, val_precision: 0.915683, val_recall: 0.418182, val_fmeasure: 0.570176\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 1.2587 - accuracy: 0.5511 - precision: 0.8331 - recall: 0.3801 - fmeasure: 0.5141 - val_loss: 1.1345 - val_accuracy: 0.6068 - val_precision: 0.9157 - val_recall: 0.4182 - val_fmeasure: 0.5702\n",
      "Epoch 20/67\n",
      "84/88 [===========================>..] - ETA: 0s - loss: 1.1240 - accuracy: 0.5905 - precision: 0.8813 - recall: 0.4095 - fmeasure: 0.5521src.model - INFO - {Epoch: 19} loss: 1.113638, accuracy: 0.593750, precision: 0.880075, recall: 0.414773, fmeasure: 0.556497, val_loss: 0.977715, val_accuracy: 0.643182, val_precision: 0.907804, val_recall: 0.454545, val_fmeasure: 0.599017\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 1.1136 - accuracy: 0.5938 - precision: 0.8801 - recall: 0.4148 - fmeasure: 0.5565 - val_loss: 0.9777 - val_accuracy: 0.6432 - val_precision: 0.9078 - val_recall: 0.4545 - val_fmeasure: 0.5990\n",
      "Epoch 21/67\n",
      "83/88 [===========================>..] - ETA: 0s - loss: 1.0361 - accuracy: 0.6175 - precision: 0.8836 - recall: 0.4512 - fmeasure: 0.5916src.model - INFO - {Epoch: 20} loss: 1.023865, accuracy: 0.620455, precision: 0.885074, recall: 0.457386, fmeasure: 0.597159, val_loss: 0.894807, val_accuracy: 0.645455, val_precision: 0.937872, val_recall: 0.470455, val_fmeasure: 0.620541\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 1.0239 - accuracy: 0.6205 - precision: 0.8851 - recall: 0.4574 - fmeasure: 0.5972 - val_loss: 0.8948 - val_accuracy: 0.6455 - val_precision: 0.9379 - val_recall: 0.4705 - val_fmeasure: 0.6205\n",
      "Epoch 22/67\n",
      "84/88 [===========================>..] - ETA: 0s - loss: 1.0655 - accuracy: 0.6280 - precision: 0.8697 - recall: 0.4518 - fmeasure: 0.5899src.model - INFO - {Epoch: 21} loss: 1.064570, accuracy: 0.628977, precision: 0.867151, recall: 0.450000, fmeasure: 0.587941, val_loss: 0.971305, val_accuracy: 0.654545, val_precision: 0.890516, val_recall: 0.459091, val_fmeasure: 0.598512\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 1.0646 - accuracy: 0.6290 - precision: 0.8672 - recall: 0.4500 - fmeasure: 0.5879 - val_loss: 0.9713 - val_accuracy: 0.6545 - val_precision: 0.8905 - val_recall: 0.4591 - val_fmeasure: 0.5985\n",
      "Epoch 23/67\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 0.9851 - accuracy: 0.6488 - precision: 0.8442 - recall: 0.4600 - fmeasure: 0.5867src.model - INFO - {Epoch: 22} loss: 0.986022, accuracy: 0.646591, precision: 0.843661, recall: 0.460795, fmeasure: 0.586971, val_loss: 0.925354, val_accuracy: 0.627273, val_precision: 0.887298, val_recall: 0.463636, val_fmeasure: 0.605763\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.9860 - accuracy: 0.6466 - precision: 0.8437 - recall: 0.4608 - fmeasure: 0.5870 - val_loss: 0.9254 - val_accuracy: 0.6273 - val_precision: 0.8873 - val_recall: 0.4636 - val_fmeasure: 0.6058\n",
      "Epoch 24/67\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.9227 - accuracy: 0.6642 - precision: 0.8579 - recall: 0.5000 - fmeasure: 0.6274src.model - INFO - {Epoch: 23} loss: 0.922676, accuracy: 0.664205, precision: 0.857866, recall: 0.500000, fmeasure: 0.627367, val_loss: 1.041237, val_accuracy: 0.690909, val_precision: 0.870600, val_recall: 0.456818, val_fmeasure: 0.592770\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.9227 - accuracy: 0.6642 - precision: 0.8579 - recall: 0.5000 - fmeasure: 0.6274 - val_loss: 1.0412 - val_accuracy: 0.6909 - val_precision: 0.8706 - val_recall: 0.4568 - val_fmeasure: 0.5928\n",
      "Epoch 25/67\n",
      "84/88 [===========================>..] - ETA: 0s - loss: 1.0469 - accuracy: 0.6512 - precision: 0.8350 - recall: 0.4940 - fmeasure: 0.6161src.model - INFO - {Epoch: 24} loss: 1.043915, accuracy: 0.648864, precision: 0.830195, recall: 0.491477, fmeasure: 0.612970, val_loss: 1.265059, val_accuracy: 0.654545, val_precision: 0.836372, val_recall: 0.450000, val_fmeasure: 0.580435\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 1.0439 - accuracy: 0.6489 - precision: 0.8302 - recall: 0.4915 - fmeasure: 0.6130 - val_loss: 1.2651 - val_accuracy: 0.6545 - val_precision: 0.8364 - val_recall: 0.4500 - val_fmeasure: 0.5804\n",
      "Epoch 26/67\n",
      "84/88 [===========================>..] - ETA: 0s - loss: 0.9902 - accuracy: 0.6673 - precision: 0.8269 - recall: 0.5054 - fmeasure: 0.6236src.model - INFO - {Epoch: 25} loss: 0.982959, accuracy: 0.667614, precision: 0.826662, recall: 0.503977, fmeasure: 0.622430, val_loss: 1.570078, val_accuracy: 0.645455, val_precision: 0.819588, val_recall: 0.425000, val_fmeasure: 0.550710\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.9830 - accuracy: 0.6676 - precision: 0.8267 - recall: 0.5040 - fmeasure: 0.6224 - val_loss: 1.5701 - val_accuracy: 0.6455 - val_precision: 0.8196 - val_recall: 0.4250 - val_fmeasure: 0.5507\n",
      "Epoch 27/67\n",
      "86/88 [============================>.] - ETA: 0s - loss: 1.5483 - accuracy: 0.5808 - precision: 0.7501 - recall: 0.3953 - fmeasure: 0.5127src.model - INFO - {Epoch: 26} loss: 1.532116, accuracy: 0.582386, precision: 0.749923, recall: 0.398295, fmeasure: 0.515004, val_loss: 1.044139, val_accuracy: 0.661364, val_precision: 0.795031, val_recall: 0.475000, val_fmeasure: 0.589871\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 1.5321 - accuracy: 0.5824 - precision: 0.7499 - recall: 0.3983 - fmeasure: 0.5150 - val_loss: 1.0441 - val_accuracy: 0.6614 - val_precision: 0.7950 - val_recall: 0.4750 - val_fmeasure: 0.5899\n",
      "Epoch 28/67\n",
      "84/88 [===========================>..] - ETA: 0s - loss: 1.1915 - accuracy: 0.6667 - precision: 0.8126 - recall: 0.4899 - fmeasure: 0.6069src.model - INFO - {Epoch: 27} loss: 1.176471, accuracy: 0.667045, precision: 0.815696, recall: 0.492045, fmeasure: 0.609602, val_loss: 0.901253, val_accuracy: 0.718182, val_precision: 0.887304, val_recall: 0.500000, val_fmeasure: 0.633132\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 1.1765 - accuracy: 0.6670 - precision: 0.8157 - recall: 0.4920 - fmeasure: 0.6096 - val_loss: 0.9013 - val_accuracy: 0.7182 - val_precision: 0.8873 - val_recall: 0.5000 - val_fmeasure: 0.6331\n",
      "Epoch 29/67\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 0.9847 - accuracy: 0.6894 - precision: 0.8374 - recall: 0.5394 - fmeasure: 0.6516src.model - INFO - {Epoch: 28} loss: 0.976988, accuracy: 0.690341, precision: 0.838522, recall: 0.540341, fmeasure: 0.652678, val_loss: 0.809556, val_accuracy: 0.693182, val_precision: 0.827439, val_recall: 0.525000, val_fmeasure: 0.635788\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.9770 - accuracy: 0.6903 - precision: 0.8385 - recall: 0.5403 - fmeasure: 0.6527 - val_loss: 0.8096 - val_accuracy: 0.6932 - val_precision: 0.8274 - val_recall: 0.5250 - val_fmeasure: 0.6358\n",
      "Epoch 30/67\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 0.9310 - accuracy: 0.6994 - precision: 0.8291 - recall: 0.5359 - fmeasure: 0.6456src.model - INFO - {Epoch: 29} loss: 0.922655, accuracy: 0.700568, precision: 0.830454, recall: 0.535795, fmeasure: 0.645799, val_loss: 0.718904, val_accuracy: 0.752273, val_precision: 0.890243, val_recall: 0.552273, val_fmeasure: 0.674930\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.9227 - accuracy: 0.7006 - precision: 0.8305 - recall: 0.5358 - fmeasure: 0.6458 - val_loss: 0.7189 - val_accuracy: 0.7523 - val_precision: 0.8902 - val_recall: 0.5523 - val_fmeasure: 0.6749\n",
      "Epoch 31/67\n",
      "87/88 [============================>.] - ETA: 0s - loss: 0.8048 - accuracy: 0.7218 - precision: 0.8474 - recall: 0.5764 - fmeasure: 0.6821src.model - INFO - {Epoch: 30} loss: 0.805341, accuracy: 0.722159, precision: 0.845678, recall: 0.575000, fmeasure: 0.680505, val_loss: 0.738751, val_accuracy: 0.756818, val_precision: 0.880498, val_recall: 0.579545, val_fmeasure: 0.692593\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.8053 - accuracy: 0.7222 - precision: 0.8457 - recall: 0.5750 - fmeasure: 0.6805 - val_loss: 0.7388 - val_accuracy: 0.7568 - val_precision: 0.8805 - val_recall: 0.5795 - val_fmeasure: 0.6926\n",
      "Epoch 32/67\n",
      "87/88 [============================>.] - ETA: 0s - loss: 0.6647 - accuracy: 0.7454 - precision: 0.8499 - recall: 0.5943 - fmeasure: 0.6963src.model - INFO - {Epoch: 31} loss: 0.664128, accuracy: 0.745455, precision: 0.848775, recall: 0.594318, fmeasure: 0.695919, val_loss: 0.677563, val_accuracy: 0.761364, val_precision: 0.846610, val_recall: 0.645454, val_fmeasure: 0.728153\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.6641 - accuracy: 0.7455 - precision: 0.8488 - recall: 0.5943 - fmeasure: 0.6959 - val_loss: 0.6776 - val_accuracy: 0.7614 - val_precision: 0.8466 - val_recall: 0.6455 - val_fmeasure: 0.7282\n",
      "Epoch 33/67\n",
      "83/88 [===========================>..] - ETA: 0s - loss: 0.6619 - accuracy: 0.7458 - precision: 0.8494 - recall: 0.6355 - fmeasure: 0.7240src.model - INFO - {Epoch: 32} loss: 0.657852, accuracy: 0.750000, precision: 0.848828, recall: 0.638068, fmeasure: 0.725553, val_loss: 0.603191, val_accuracy: 0.765909, val_precision: 0.871799, val_recall: 0.690909, val_fmeasure: 0.767698\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.6579 - accuracy: 0.7500 - precision: 0.8488 - recall: 0.6381 - fmeasure: 0.7256 - val_loss: 0.6032 - val_accuracy: 0.7659 - val_precision: 0.8718 - val_recall: 0.6909 - val_fmeasure: 0.7677\n",
      "Epoch 34/67\n",
      "86/88 [============================>.] - ETA: 0s - loss: 0.6218 - accuracy: 0.7552 - precision: 0.8559 - recall: 0.6552 - fmeasure: 0.7391src.model - INFO - {Epoch: 33} loss: 0.624279, accuracy: 0.754545, precision: 0.854186, recall: 0.652841, fmeasure: 0.736867, val_loss: 0.832700, val_accuracy: 0.770455, val_precision: 0.870237, val_recall: 0.656818, val_fmeasure: 0.745027\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.6243 - accuracy: 0.7545 - precision: 0.8542 - recall: 0.6528 - fmeasure: 0.7369 - val_loss: 0.8327 - val_accuracy: 0.7705 - val_precision: 0.8702 - val_recall: 0.6568 - val_fmeasure: 0.7450\n",
      "Epoch 35/67\n",
      "84/88 [===========================>..] - ETA: 0s - loss: 0.7320 - accuracy: 0.7601 - precision: 0.8431 - recall: 0.6524 - fmeasure: 0.7323src.model - INFO - {Epoch: 34} loss: 0.723880, accuracy: 0.760795, precision: 0.842196, recall: 0.655682, fmeasure: 0.733954, val_loss: 0.780193, val_accuracy: 0.756818, val_precision: 0.804846, val_recall: 0.647727, val_fmeasure: 0.713380\n",
      "88/88 [==============================] - 1s 11ms/step - loss: 0.7239 - accuracy: 0.7608 - precision: 0.8422 - recall: 0.6557 - fmeasure: 0.7340 - val_loss: 0.7802 - val_accuracy: 0.7568 - val_precision: 0.8048 - val_recall: 0.6477 - val_fmeasure: 0.7134\n",
      "Epoch 36/67\n",
      "83/88 [===========================>..] - ETA: 0s - loss: 0.7901 - accuracy: 0.7663 - precision: 0.8439 - recall: 0.6657 - fmeasure: 0.7412src.model - INFO - {Epoch: 35} loss: 0.799653, accuracy: 0.764205, precision: 0.843229, recall: 0.660795, fmeasure: 0.737902, val_loss: 1.110357, val_accuracy: 0.695455, val_precision: 0.788338, val_recall: 0.515909, val_fmeasure: 0.618231\n",
      "88/88 [==============================] - 1s 11ms/step - loss: 0.7997 - accuracy: 0.7642 - precision: 0.8432 - recall: 0.6608 - fmeasure: 0.7379 - val_loss: 1.1104 - val_accuracy: 0.6955 - val_precision: 0.7883 - val_recall: 0.5159 - val_fmeasure: 0.6182\n",
      "Epoch 37/67\n",
      "83/88 [===========================>..] - ETA: 0s - loss: 0.7618 - accuracy: 0.7169 - precision: 0.8064 - recall: 0.6187 - fmeasure: 0.6978src.model - INFO - {Epoch: 36} loss: 0.756162, accuracy: 0.718750, precision: 0.807593, recall: 0.621591, fmeasure: 0.700197, val_loss: 0.571346, val_accuracy: 0.809091, val_precision: 0.891833, val_recall: 0.715909, val_fmeasure: 0.791459\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.7562 - accuracy: 0.7188 - precision: 0.8076 - recall: 0.6216 - fmeasure: 0.7002 - val_loss: 0.5713 - val_accuracy: 0.8091 - val_precision: 0.8918 - val_recall: 0.7159 - val_fmeasure: 0.7915\n",
      "Epoch 38/67\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.6568 - accuracy: 0.7625 - precision: 0.8438 - recall: 0.6761 - fmeasure: 0.7480src.model - INFO - {Epoch: 37} loss: 0.656750, accuracy: 0.762500, precision: 0.843799, recall: 0.676136, fmeasure: 0.747980, val_loss: 0.626420, val_accuracy: 0.797727, val_precision: 0.872199, val_recall: 0.697727, val_fmeasure: 0.771212\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.6568 - accuracy: 0.7625 - precision: 0.8438 - recall: 0.6761 - fmeasure: 0.7480 - val_loss: 0.6264 - val_accuracy: 0.7977 - val_precision: 0.8722 - val_recall: 0.6977 - val_fmeasure: 0.7712\n",
      "Epoch 39/67\n",
      "86/88 [============================>.] - ETA: 0s - loss: 0.6481 - accuracy: 0.7733 - precision: 0.8483 - recall: 0.6826 - fmeasure: 0.7544src.model - INFO - {Epoch: 38} loss: 0.647799, accuracy: 0.770455, precision: 0.846418, recall: 0.681250, fmeasure: 0.752900, val_loss: 0.509717, val_accuracy: 0.806818, val_precision: 0.873753, val_recall: 0.725000, val_fmeasure: 0.789968\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.6478 - accuracy: 0.7705 - precision: 0.8464 - recall: 0.6813 - fmeasure: 0.7529 - val_loss: 0.5097 - val_accuracy: 0.8068 - val_precision: 0.8738 - val_recall: 0.7250 - val_fmeasure: 0.7900\n",
      "Epoch 40/67\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 0.5156 - accuracy: 0.8029 - precision: 0.8658 - recall: 0.7341 - fmeasure: 0.7929src.model - INFO - {Epoch: 39} loss: 0.510458, accuracy: 0.806250, precision: 0.866722, recall: 0.736363, fmeasure: 0.794573, val_loss: 0.643849, val_accuracy: 0.822727, val_precision: 0.864081, val_recall: 0.745455, val_fmeasure: 0.798930\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.5105 - accuracy: 0.8062 - precision: 0.8667 - recall: 0.7364 - fmeasure: 0.7946 - val_loss: 0.6438 - val_accuracy: 0.8227 - val_precision: 0.8641 - val_recall: 0.7455 - val_fmeasure: 0.7989\n",
      "Epoch 41/67\n",
      "86/88 [============================>.] - ETA: 0s - loss: 0.4979 - accuracy: 0.8140 - precision: 0.8639 - recall: 0.7390 - fmeasure: 0.7946src.model - INFO - {Epoch: 40} loss: 0.499338, accuracy: 0.814205, precision: 0.864423, recall: 0.738636, fmeasure: 0.794606, val_loss: 0.486603, val_accuracy: 0.827273, val_precision: 0.875802, val_recall: 0.784091, val_fmeasure: 0.824972\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.4993 - accuracy: 0.8142 - precision: 0.8644 - recall: 0.7386 - fmeasure: 0.7946 - val_loss: 0.4866 - val_accuracy: 0.8273 - val_precision: 0.8758 - val_recall: 0.7841 - val_fmeasure: 0.8250\n",
      "Epoch 42/67\n",
      "87/88 [============================>.] - ETA: 0s - loss: 0.5126 - accuracy: 0.8264 - precision: 0.8816 - recall: 0.7638 - fmeasure: 0.8168src.model - INFO - {Epoch: 41} loss: 0.511547, accuracy: 0.825568, precision: 0.880104, recall: 0.763636, fmeasure: 0.816026, val_loss: 0.486034, val_accuracy: 0.825000, val_precision: 0.882675, val_recall: 0.759091, val_fmeasure: 0.813657\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.5115 - accuracy: 0.8256 - precision: 0.8801 - recall: 0.7636 - fmeasure: 0.8160 - val_loss: 0.4860 - val_accuracy: 0.8250 - val_precision: 0.8827 - val_recall: 0.7591 - val_fmeasure: 0.8137\n",
      "Epoch 43/67\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 0.6048 - accuracy: 0.8112 - precision: 0.8669 - recall: 0.7471 - fmeasure: 0.8005src.model - INFO - {Epoch: 42} loss: 0.600626, accuracy: 0.811932, precision: 0.869952, recall: 0.747159, fmeasure: 0.801888, val_loss: 0.552682, val_accuracy: 0.825000, val_precision: 0.860999, val_recall: 0.768182, val_fmeasure: 0.810490\n",
      "88/88 [==============================] - 1s 13ms/step - loss: 0.6006 - accuracy: 0.8119 - precision: 0.8700 - recall: 0.7472 - fmeasure: 0.8019 - val_loss: 0.5527 - val_accuracy: 0.8250 - val_precision: 0.8610 - val_recall: 0.7682 - val_fmeasure: 0.8105\n",
      "Epoch 44/67\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 0.5658 - accuracy: 0.8171 - precision: 0.8758 - recall: 0.7576 - fmeasure: 0.8112src.model - INFO - {Epoch: 43} loss: 0.560316, accuracy: 0.818750, precision: 0.877037, recall: 0.759091, fmeasure: 0.812502, val_loss: 0.518904, val_accuracy: 0.856818, val_precision: 0.899719, val_recall: 0.813636, val_fmeasure: 0.853180\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.5603 - accuracy: 0.8188 - precision: 0.8770 - recall: 0.7591 - fmeasure: 0.8125 - val_loss: 0.5189 - val_accuracy: 0.8568 - val_precision: 0.8997 - val_recall: 0.8136 - val_fmeasure: 0.8532\n",
      "Epoch 45/67\n",
      "87/88 [============================>.] - ETA: 0s - loss: 0.5228 - accuracy: 0.8161 - precision: 0.8572 - recall: 0.7529 - fmeasure: 0.8004src.model - INFO - {Epoch: 44} loss: 0.519290, accuracy: 0.817045, precision: 0.857629, recall: 0.753977, fmeasure: 0.801201, val_loss: 0.531849, val_accuracy: 0.834091, val_precision: 0.866920, val_recall: 0.761364, val_fmeasure: 0.808528\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.5193 - accuracy: 0.8170 - precision: 0.8576 - recall: 0.7540 - fmeasure: 0.8012 - val_loss: 0.5318 - val_accuracy: 0.8341 - val_precision: 0.8669 - val_recall: 0.7614 - val_fmeasure: 0.8085\n",
      "Epoch 46/67\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.4966 - accuracy: 0.8119 - precision: 0.8648 - recall: 0.7551 - fmeasure: 0.8043src.model - INFO - {Epoch: 45} loss: 0.496648, accuracy: 0.811932, precision: 0.864823, recall: 0.755114, fmeasure: 0.804305, val_loss: 0.651219, val_accuracy: 0.861364, val_precision: 0.892134, val_recall: 0.825000, val_fmeasure: 0.856535\n",
      "88/88 [==============================] - 1s 13ms/step - loss: 0.4966 - accuracy: 0.8119 - precision: 0.8648 - recall: 0.7551 - fmeasure: 0.8043 - val_loss: 0.6512 - val_accuracy: 0.8614 - val_precision: 0.8921 - val_recall: 0.8250 - val_fmeasure: 0.8565\n",
      "Epoch 47/67\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 0.5704 - accuracy: 0.8118 - precision: 0.8550 - recall: 0.7488 - fmeasure: 0.7972src.model - INFO - {Epoch: 46} loss: 0.572398, accuracy: 0.810227, precision: 0.853034, recall: 0.748295, fmeasure: 0.795999, val_loss: 0.538175, val_accuracy: 0.850000, val_precision: 0.883689, val_recall: 0.781818, val_fmeasure: 0.827127\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.5724 - accuracy: 0.8102 - precision: 0.8530 - recall: 0.7483 - fmeasure: 0.7960 - val_loss: 0.5382 - val_accuracy: 0.8500 - val_precision: 0.8837 - val_recall: 0.7818 - val_fmeasure: 0.8271\n",
      "Epoch 48/67\n",
      "87/88 [============================>.] - ETA: 0s - loss: 0.4402 - accuracy: 0.8305 - precision: 0.8726 - recall: 0.7782 - fmeasure: 0.8217src.model - INFO - {Epoch: 47} loss: 0.441082, accuracy: 0.830114, precision: 0.871889, recall: 0.776704, fmeasure: 0.820578, val_loss: 0.430797, val_accuracy: 0.847727, val_precision: 0.889475, val_recall: 0.788636, val_fmeasure: 0.833592\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.4411 - accuracy: 0.8301 - precision: 0.8719 - recall: 0.7767 - fmeasure: 0.8206 - val_loss: 0.4308 - val_accuracy: 0.8477 - val_precision: 0.8895 - val_recall: 0.7886 - val_fmeasure: 0.8336\n",
      "Epoch 49/67\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 0.3864 - accuracy: 0.8512 - precision: 0.8912 - recall: 0.8076 - fmeasure: 0.8461src.model - INFO - {Epoch: 48} loss: 0.387945, accuracy: 0.848864, precision: 0.888095, recall: 0.805682, fmeasure: 0.843583, val_loss: 0.444390, val_accuracy: 0.822727, val_precision: 0.858688, val_recall: 0.786364, val_fmeasure: 0.819937\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.3879 - accuracy: 0.8489 - precision: 0.8881 - recall: 0.8057 - fmeasure: 0.8436 - val_loss: 0.4444 - val_accuracy: 0.8227 - val_precision: 0.8587 - val_recall: 0.7864 - val_fmeasure: 0.8199\n",
      "Epoch 50/67\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 0.4254 - accuracy: 0.8418 - precision: 0.8797 - recall: 0.7935 - fmeasure: 0.8331src.model - INFO - {Epoch: 49} loss: 0.423919, accuracy: 0.844318, precision: 0.881974, recall: 0.797159, fmeasure: 0.836175, val_loss: 0.398255, val_accuracy: 0.872727, val_precision: 0.897704, val_recall: 0.834091, val_fmeasure: 0.864120\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.4239 - accuracy: 0.8443 - precision: 0.8820 - recall: 0.7972 - fmeasure: 0.8362 - val_loss: 0.3983 - val_accuracy: 0.8727 - val_precision: 0.8977 - val_recall: 0.8341 - val_fmeasure: 0.8641\n",
      "Epoch 51/67\n",
      "87/88 [============================>.] - ETA: 0s - loss: 0.4128 - accuracy: 0.8552 - precision: 0.8893 - recall: 0.8069 - fmeasure: 0.8450src.model - INFO - {Epoch: 50} loss: 0.411540, accuracy: 0.855682, precision: 0.889369, recall: 0.807386, fmeasure: 0.845339, val_loss: 0.428083, val_accuracy: 0.852273, val_precision: 0.868518, val_recall: 0.822727, val_fmeasure: 0.844389\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.4115 - accuracy: 0.8557 - precision: 0.8894 - recall: 0.8074 - fmeasure: 0.8453 - val_loss: 0.4281 - val_accuracy: 0.8523 - val_precision: 0.8685 - val_recall: 0.8227 - val_fmeasure: 0.8444\n",
      "Epoch 52/67\n",
      "87/88 [============================>.] - ETA: 0s - loss: 0.5447 - accuracy: 0.8270 - precision: 0.8718 - recall: 0.7839 - fmeasure: 0.8241src.model - INFO - {Epoch: 51} loss: 0.540387, accuracy: 0.828409, precision: 0.872673, recall: 0.785795, fmeasure: 0.825488, val_loss: 0.844545, val_accuracy: 0.845455, val_precision: 0.876452, val_recall: 0.815909, val_fmeasure: 0.843911\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.5404 - accuracy: 0.8284 - precision: 0.8727 - recall: 0.7858 - fmeasure: 0.8255 - val_loss: 0.8445 - val_accuracy: 0.8455 - val_precision: 0.8765 - val_recall: 0.8159 - val_fmeasure: 0.8439\n",
      "Epoch 53/67\n",
      "87/88 [============================>.] - ETA: 0s - loss: 0.3782 - accuracy: 0.8540 - precision: 0.8805 - recall: 0.8161 - fmeasure: 0.8463src.model - INFO - {Epoch: 52} loss: 0.381013, accuracy: 0.852841, precision: 0.879803, recall: 0.814773, fmeasure: 0.845312, val_loss: 0.417981, val_accuracy: 0.886364, val_precision: 0.910593, val_recall: 0.863636, val_fmeasure: 0.886061\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.3810 - accuracy: 0.8528 - precision: 0.8798 - recall: 0.8148 - fmeasure: 0.8453 - val_loss: 0.4180 - val_accuracy: 0.8864 - val_precision: 0.9106 - val_recall: 0.8636 - val_fmeasure: 0.8861\n",
      "Epoch 54/67\n",
      "87/88 [============================>.] - ETA: 0s - loss: 0.3697 - accuracy: 0.8580 - precision: 0.8837 - recall: 0.8161 - fmeasure: 0.8477src.model - INFO - {Epoch: 53} loss: 0.369194, accuracy: 0.857955, precision: 0.884273, recall: 0.815341, fmeasure: 0.847557, val_loss: 0.384801, val_accuracy: 0.881818, val_precision: 0.911887, val_recall: 0.856818, val_fmeasure: 0.882498\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.3692 - accuracy: 0.8580 - precision: 0.8843 - recall: 0.8153 - fmeasure: 0.8476 - val_loss: 0.3848 - val_accuracy: 0.8818 - val_precision: 0.9119 - val_recall: 0.8568 - val_fmeasure: 0.8825\n",
      "Epoch 55/67\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 0.3314 - accuracy: 0.8765 - precision: 0.9066 - recall: 0.8471 - fmeasure: 0.8751src.model - INFO - {Epoch: 54} loss: 0.338930, accuracy: 0.873864, precision: 0.904366, recall: 0.845455, fmeasure: 0.873255, val_loss: 0.386855, val_accuracy: 0.890909, val_precision: 0.913415, val_recall: 0.868182, val_fmeasure: 0.889425\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.3389 - accuracy: 0.8739 - precision: 0.9044 - recall: 0.8455 - fmeasure: 0.8733 - val_loss: 0.3869 - val_accuracy: 0.8909 - val_precision: 0.9134 - val_recall: 0.8682 - val_fmeasure: 0.8894\n",
      "Epoch 56/67\n",
      "83/88 [===========================>..] - ETA: 0s - loss: 0.5315 - accuracy: 0.8470 - precision: 0.8785 - recall: 0.8187 - fmeasure: 0.8468src.model - INFO - {Epoch: 55} loss: 0.529326, accuracy: 0.847727, precision: 0.880884, recall: 0.818750, fmeasure: 0.847889, val_loss: 0.621216, val_accuracy: 0.813636, val_precision: 0.853235, val_recall: 0.786364, val_fmeasure: 0.817077\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.5293 - accuracy: 0.8477 - precision: 0.8809 - recall: 0.8188 - fmeasure: 0.8479 - val_loss: 0.6212 - val_accuracy: 0.8136 - val_precision: 0.8532 - val_recall: 0.7864 - val_fmeasure: 0.8171\n",
      "Epoch 57/67\n",
      "86/88 [============================>.] - ETA: 0s - loss: 0.5511 - accuracy: 0.8169 - precision: 0.8543 - recall: 0.7727 - fmeasure: 0.8105src.model - INFO - {Epoch: 56} loss: 0.551133, accuracy: 0.817045, precision: 0.855021, recall: 0.772727, fmeasure: 0.810867, val_loss: 0.808799, val_accuracy: 0.872727, val_precision: 0.901281, val_recall: 0.827273, val_fmeasure: 0.860357\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.5511 - accuracy: 0.8170 - precision: 0.8550 - recall: 0.7727 - fmeasure: 0.8109 - val_loss: 0.8088 - val_accuracy: 0.8727 - val_precision: 0.9013 - val_recall: 0.8273 - val_fmeasure: 0.8604\n",
      "Epoch 58/67\n",
      "84/88 [===========================>..] - ETA: 0s - loss: 0.9615 - accuracy: 0.7667 - precision: 0.8136 - recall: 0.7036 - fmeasure: 0.7524src.model - INFO - {Epoch: 57} loss: 0.943628, accuracy: 0.766477, precision: 0.814989, recall: 0.705114, fmeasure: 0.753976, val_loss: 0.834230, val_accuracy: 0.809091, val_precision: 0.842491, val_recall: 0.772727, val_fmeasure: 0.804783\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.9436 - accuracy: 0.7665 - precision: 0.8150 - recall: 0.7051 - fmeasure: 0.7540 - val_loss: 0.8342 - val_accuracy: 0.8091 - val_precision: 0.8425 - val_recall: 0.7727 - val_fmeasure: 0.8048\n",
      "Epoch 59/67\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 0.5680 - accuracy: 0.8224 - precision: 0.8711 - recall: 0.7794 - fmeasure: 0.8212src.model - INFO - {Epoch: 58} loss: 0.564900, accuracy: 0.821591, precision: 0.869235, recall: 0.777841, fmeasure: 0.819499, val_loss: 0.454545, val_accuracy: 0.852273, val_precision: 0.896206, val_recall: 0.820455, val_fmeasure: 0.854446\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.5649 - accuracy: 0.8216 - precision: 0.8692 - recall: 0.7778 - fmeasure: 0.8195 - val_loss: 0.4545 - val_accuracy: 0.8523 - val_precision: 0.8962 - val_recall: 0.8205 - val_fmeasure: 0.8544\n",
      "Epoch 60/67\n",
      "86/88 [============================>.] - ETA: 0s - loss: 0.3813 - accuracy: 0.8587 - precision: 0.8953 - recall: 0.8163 - fmeasure: 0.8528src.model - INFO - {Epoch: 59} loss: 0.381249, accuracy: 0.859091, precision: 0.895217, recall: 0.817045, fmeasure: 0.853143, val_loss: 0.381807, val_accuracy: 0.868182, val_precision: 0.890366, val_recall: 0.850000, val_fmeasure: 0.868769\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.3812 - accuracy: 0.8591 - precision: 0.8952 - recall: 0.8170 - fmeasure: 0.8531 - val_loss: 0.3818 - val_accuracy: 0.8682 - val_precision: 0.8904 - val_recall: 0.8500 - val_fmeasure: 0.8688\n",
      "Epoch 61/67\n",
      "83/88 [===========================>..] - ETA: 0s - loss: 0.4031 - accuracy: 0.8747 - precision: 0.9027 - recall: 0.8464 - fmeasure: 0.8729src.model - INFO - {Epoch: 60} loss: 0.397921, accuracy: 0.875568, precision: 0.902258, recall: 0.846591, fmeasure: 0.872774, val_loss: 0.355560, val_accuracy: 0.861364, val_precision: 0.891893, val_recall: 0.847727, val_fmeasure: 0.868342\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.3979 - accuracy: 0.8756 - precision: 0.9023 - recall: 0.8466 - fmeasure: 0.8728 - val_loss: 0.3556 - val_accuracy: 0.8614 - val_precision: 0.8919 - val_recall: 0.8477 - val_fmeasure: 0.8683\n",
      "Epoch 62/67\n",
      "87/88 [============================>.] - ETA: 0s - loss: 0.3533 - accuracy: 0.8609 - precision: 0.8988 - recall: 0.8345 - fmeasure: 0.8646src.model - INFO - {Epoch: 61} loss: 0.354652, accuracy: 0.860227, precision: 0.898087, recall: 0.833523, fmeasure: 0.863734, val_loss: 0.324786, val_accuracy: 0.909091, val_precision: 0.927007, val_recall: 0.888636, val_fmeasure: 0.906647\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.3547 - accuracy: 0.8602 - precision: 0.8981 - recall: 0.8335 - fmeasure: 0.8637 - val_loss: 0.3248 - val_accuracy: 0.9091 - val_precision: 0.9270 - val_recall: 0.8886 - val_fmeasure: 0.9066\n",
      "Epoch 63/67\n",
      "85/88 [===========================>..] - ETA: 0s - loss: 0.3217 - accuracy: 0.8841 - precision: 0.9092 - recall: 0.8535 - fmeasure: 0.8799src.model - INFO - {Epoch: 62} loss: 0.321026, accuracy: 0.884091, precision: 0.908729, recall: 0.853409, fmeasure: 0.879624, val_loss: 0.333647, val_accuracy: 0.900000, val_precision: 0.914866, val_recall: 0.870454, val_fmeasure: 0.890563\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.3210 - accuracy: 0.8841 - precision: 0.9087 - recall: 0.8534 - fmeasure: 0.8796 - val_loss: 0.3336 - val_accuracy: 0.9000 - val_precision: 0.9149 - val_recall: 0.8705 - val_fmeasure: 0.8906\n",
      "Epoch 64/67\n",
      "83/88 [===========================>..] - ETA: 0s - loss: 0.2959 - accuracy: 0.8940 - precision: 0.9201 - recall: 0.8681 - fmeasure: 0.8927src.model - INFO - {Epoch: 63} loss: 0.302820, accuracy: 0.890341, precision: 0.917202, recall: 0.864204, fmeasure: 0.889270, val_loss: 0.352385, val_accuracy: 0.893182, val_precision: 0.913671, val_recall: 0.872727, val_fmeasure: 0.892000\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.3028 - accuracy: 0.8903 - precision: 0.9172 - recall: 0.8642 - fmeasure: 0.8893 - val_loss: 0.3524 - val_accuracy: 0.8932 - val_precision: 0.9137 - val_recall: 0.8727 - val_fmeasure: 0.8920\n",
      "Epoch 65/67\n",
      "84/88 [===========================>..] - ETA: 0s - loss: 0.2763 - accuracy: 0.8970 - precision: 0.9176 - recall: 0.8714 - fmeasure: 0.8933src.model - INFO - {Epoch: 64} loss: 0.277170, accuracy: 0.896023, precision: 0.917574, recall: 0.870455, fmeasure: 0.892779, val_loss: 0.312125, val_accuracy: 0.897727, val_precision: 0.910071, val_recall: 0.875000, val_fmeasure: 0.891603\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.2772 - accuracy: 0.8960 - precision: 0.9176 - recall: 0.8705 - fmeasure: 0.8928 - val_loss: 0.3121 - val_accuracy: 0.8977 - val_precision: 0.9101 - val_recall: 0.8750 - val_fmeasure: 0.8916\n",
      "Epoch 66/67\n",
      "83/88 [===========================>..] - ETA: 0s - loss: 0.3816 - accuracy: 0.8813 - precision: 0.9036 - recall: 0.8578 - fmeasure: 0.8797src.model - INFO - {Epoch: 65} loss: 0.378524, accuracy: 0.881250, precision: 0.903644, recall: 0.857955, fmeasure: 0.879796, val_loss: 0.322458, val_accuracy: 0.884091, val_precision: 0.898565, val_recall: 0.877273, val_fmeasure: 0.887113\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.3785 - accuracy: 0.8813 - precision: 0.9036 - recall: 0.8580 - fmeasure: 0.8798 - val_loss: 0.3225 - val_accuracy: 0.8841 - val_precision: 0.8986 - val_recall: 0.8773 - val_fmeasure: 0.8871\n",
      "Epoch 67/67\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.3673 - accuracy: 0.8693 - precision: 0.8950 - recall: 0.8489 - fmeasure: 0.8707src.model - INFO - {Epoch: 66} loss: 0.367287, accuracy: 0.869318, precision: 0.895039, recall: 0.848864, fmeasure: 0.870737, val_loss: 0.388366, val_accuracy: 0.900000, val_precision: 0.918740, val_recall: 0.875000, val_fmeasure: 0.895446\n",
      "88/88 [==============================] - 1s 12ms/step - loss: 0.3673 - accuracy: 0.8693 - precision: 0.8950 - recall: 0.8489 - fmeasure: 0.8707 - val_loss: 0.3884 - val_accuracy: 0.9000 - val_precision: 0.9187 - val_recall: 0.8750 - val_fmeasure: 0.8954\n",
      "src.model - INFO - Training completed\n",
      "src.model - INFO - Evaluating model\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.3884 - accuracy: 0.8977 - precision: 0.9178 - recall: 0.8735 - fmeasure: 0.8946\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.1621 - accuracy: 0.9483 - precision: 0.9558 - recall: 0.9358 - fmeasure: 0.9455\n",
      "src.model - INFO - Train loss: 0.16207431256771088\n",
      "src.model - INFO - Train precision: 0.9557662010192871\n",
      "src.model - INFO - Train recall: 0.9357954263687134\n",
      "src.model - INFO - Train f1-score: 0.9454578161239624\n",
      "src.model - INFO - Test loss: 0.3883664906024933\n",
      "src.model - INFO - Test precision: 0.9177500009536743\n",
      "src.model - INFO - Test recall: 0.8735119104385376\n",
      "src.model - INFO - Test f1-score: 0.8945932388305664\n",
      "14/14 [==============================] - 0s 4ms/step\n",
      "src.train - INFO - Confusion Matrix for classes ['a', 'am', 'bm', 'c', 'd', 'dm', 'e', 'em', 'f', 'g']:\n",
      "[[33  0  0  0  0  0  1  0  0  0]\n",
      " [ 6 44  0  0  0  1  0  0  0  0]\n",
      " [ 0  0 37  2  0  0  0  0  0  0]\n",
      " [ 0  0  0 45  0  0  0  0  0  1]\n",
      " [ 0  0  0  0 39  3  0  0  0  2]\n",
      " [ 0  1  0  0  5 36  0  0  0  0]\n",
      " [ 0  0  1  0  2  0 47  4  0  2]\n",
      " [ 0  0  1  0  0  0  4 33  0  0]\n",
      " [ 0  1  1  0  1  0  0  1 39  0]\n",
      " [ 0  0  0  0  2  0  0  3  0 42]]\n",
      "src.model - INFO - Saving model\n",
      "src.model - INFO - Saved model to /home/tzag/danigil/dl/guitarCR/models\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import keras\n",
    "import os, glob\n",
    "import logging\n",
    "import librosa, librosa.display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, \\\n",
    "                         Flatten, MaxPooling2D\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras import backend as K\n",
    "\n",
    "from src.metrics import *\n",
    "from settings import *\n",
    "from src.data import generate\n",
    "from src.processing import *\n",
    "from src.model import CNN\n",
    "from src.data.preprocessing import get_most_shape\n",
    "from setup_logging import setup_logging\n",
    "\n",
    "setup_logging()\n",
    "logger = logging.getLogger('src.train')\n",
    "\n",
    "augmented = False\n",
    "\n",
    "train_datas = []\n",
    "test_datas = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    train_data, test_data = train_test_split(dataset, augmented=augmented, split_ratio=0.8)\n",
    "    train_datas.append(train_data)\n",
    "    test_datas.append(test_data)\n",
    "\n",
    "train_data = pd.concat(train_datas)\n",
    "test_data = pd.concat(test_datas)\n",
    "\n",
    "most_shape = get_most_shape(train_data)\n",
    "\n",
    "logger.info(f\"Number of train samples: {len(train_data)}\")\n",
    "logger.info(f\"Number of test samples: {len(test_data)}\")\n",
    "# most_shape = get_most_shape(dataset)\n",
    "#train_data, test_data = train_test_split(dataset, augmented=augmented, split_ratio=0.65)\n",
    "\n",
    "X_train, y_train = features_target_split(train_data)\n",
    "X_test, y_test = features_target_split(test_data)\n",
    "\n",
    "# Reshape for CNN input\n",
    "X_train, X_test = reshape_feature_CNN(X_train), reshape_feature_CNN(X_test)\n",
    "\n",
    "# Preserve y_test values\n",
    "y_test_values = y_test.copy()\n",
    "\n",
    "# One-Hot encoding for classes\n",
    "y_train, y_test = one_hot_encode(y_train), one_hot_encode(y_test)\n",
    "\n",
    "# Instance of CNN model\n",
    "cnn = CNN(most_shape)\n",
    "logger.info(str(cnn))\n",
    "\n",
    "cnn.train(X_train, y_train, X_test, y_test)\n",
    "cnn.evaluate(X_train, y_train, X_test, y_test)\n",
    "\n",
    "if tf.__version__ != '1.8.0':\n",
    "    predict_x=cnn.model.predict(X_test)\n",
    "    predictions = np.argmax(predict_x,axis=1)\n",
    "else:    \n",
    "    predictions = cnn.model.predict_classes(X_test)\n",
    "conf_matrix=confusion_matrix(y_test_values, predictions, labels=range(10))\n",
    "logger.info('Confusion Matrix for classes {}:\\n{}'.format(CLASSES, conf_matrix))\n",
    "cnn.save_model(name=\"model_nopiano_noaugment_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3280 - accuracy: 0.9400 - precision: 0.9531 - recall: 0.9531 - fmeasure: 0.9531\n",
      "Test loss: 0.32797059416770935\n",
      "Test accuracy: 0.9399999976158142\n",
      "Test precision: 0.953125\n",
      "Test recall: 0.953125\n",
      "Test f1-score: 0.9531249403953552\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dataset_piano = pd.read_pickle(os.path.join(METADATA_DIR_PROCESSED_NORMALIZED, 'data_piano.pkl'))\n",
    "\n",
    "test_data = dataset_piano\n",
    "\n",
    "X_test = test_data['spectrogram']\n",
    "X_test = np.array([np.pad(x, ((0, 0), (0, 87-x.shape[1])), 'constant') for x in dataset['spectrogram']])\n",
    "y_test = test_data['class_ID']\n",
    "\n",
    "X_test = np.array([x.reshape( (128, 87, 1) ) for x in X_test])\n",
    "\n",
    "y_test_values=y_test\n",
    "y_test = np.array(keras.utils.to_categorical(y_test, 10))\n",
    "\n",
    "score = cnn.model.evaluate(X_test,y_test)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test precision:', score[2])\n",
    "print('Test recall:', score[3])\n",
    "print('Test f1-score:', score[4])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline performance on piano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step - loss: 255.6006 - accuracy: 0.2900 - precision: 0.4453 - recall: 0.4453 - fmeasure: 0.4453\n",
      "Test loss: 255.60064697265625\n",
      "Test accuracy: 0.28999999165534973\n",
      "Test precision: 0.4453125\n",
      "Test recall: 0.4453125\n",
      "Test f1-score: 0.4453124403953552\n"
     ]
    }
   ],
   "source": [
    "with open(MODEL_1_JSON, \"r\") as json_file:\n",
    "\tloaded_model_json = json_file.read()\n",
    "\n",
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights(MODEL_1_H5)\n",
    "\n",
    "model.compile(\n",
    "            optimizer=\"Adam\",\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics=['accuracy', precision, recall, fmeasure])\n",
    "\n",
    "score = model.evaluate(\n",
    "\tx=X_test,\n",
    "\ty=y_test)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test precision:', score[2])\n",
    "print('Test recall:', score[3])\n",
    "print('Test f1-score:', score[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "danigil-steganalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
