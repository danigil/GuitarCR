{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 08:37:57.562213: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-22 08:37:57.687644: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-22 08:37:58.290220: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvrtc.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-22 08:37:58.290293: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-22 08:37:58.290299: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 1300\n",
      "src.processing - INFO - Number of testing samples is 700\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 455\n",
      "src.processing - INFO - Number of testing samples is 60\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 455\n",
      "src.processing - INFO - Number of testing samples is 60\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 455\n",
      "src.processing - INFO - Number of testing samples is 60\n",
      "src.processing - INFO - Train test split completed\n",
      "The most frequent shape is (128, 213)\n",
      "src.model - INFO - Initializing CNN\n",
      "src.model - INFO - Input shape = (128, 213, 1)\n",
      "src.model - INFO - CNN Initialized\n",
      "src.train - INFO - Number of train samples: 2665\n",
      "src.train - INFO - Number of test samples: 880\n",
      "src.processing - INFO - Start feature target split\n",
      "src.processing - INFO - Feature target split completed\n",
      "src.processing - INFO - Start feature target split\n",
      "src.processing - INFO - Feature target split completed\n",
      "src.processing - INFO - Features reshaped for CNN Input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 08:38:01.145188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22324 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:3b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.processing - INFO - Features reshaped for CNN Input\n",
      "src.processing - INFO - Target one hot encoded\n",
      "src.processing - INFO - Target one hot encoded\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 124, 209, 24)      624       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 104, 24)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " activation (Activation)     (None, 31, 104, 24)       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 27, 100, 48)       28848     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 50, 48)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 6, 50, 48)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 2, 46, 48)         57648     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 2, 46, 48)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4416)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4416)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                282688    \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 370,458\n",
      "Trainable params: 370,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "src.train - INFO - None\n",
      "src.model - INFO - Start training model\n",
      "src.model - INFO - Tensorboard Logging Started\n",
      "src.model - INFO - Use the following command in the terminal to view the logs during training: tensorboard --logdir logs/training\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 08:38:05.312273: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600\n",
      "2023-05-22 08:38:06.241451: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - ETA: 0s - loss: 2.2939 - accuracy: 0.1268 - precision: 0.0000e+00 - recall: 0.0000e+00 - fmeasure: 0.0000e+00src.model - INFO - {Epoch: 0} loss: 2.293925, accuracy: 0.126829, precision: 0.000000, recall: 0.000000, fmeasure: 0.000000, val_loss: 2.249043, val_accuracy: 0.151136, val_precision: 0.000000, val_recall: 0.000000, val_fmeasure: 0.000000\n",
      "134/134 [==============================] - 8s 18ms/step - loss: 2.2939 - accuracy: 0.1268 - precision: 0.0000e+00 - recall: 0.0000e+00 - fmeasure: 0.0000e+00 - val_loss: 2.2490 - val_accuracy: 0.1511 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fmeasure: 0.0000e+00\n",
      "Epoch 2/15\n",
      "132/134 [============================>.] - ETA: 0s - loss: 2.1668 - accuracy: 0.2076 - precision: 0.1591 - recall: 0.0114 - fmeasure: 0.0209src.model - INFO - {Epoch: 1} loss: 2.164833, accuracy: 0.208255, precision: 0.171642, recall: 0.013806, fmeasure: 0.025038, val_loss: 1.826783, val_accuracy: 0.319318, val_precision: 0.803030, val_recall: 0.075000, val_fmeasure: 0.135247\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 2.1648 - accuracy: 0.2083 - precision: 0.1716 - recall: 0.0138 - fmeasure: 0.0250 - val_loss: 1.8268 - val_accuracy: 0.3193 - val_precision: 0.8030 - val_recall: 0.0750 - val_fmeasure: 0.1352\n",
      "Epoch 3/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 1.5452 - accuracy: 0.4397 - precision: 0.7334 - recall: 0.2130 - fmeasure: 0.3162src.model - INFO - {Epoch: 2} loss: 1.536370, accuracy: 0.442026, precision: 0.736635, recall: 0.217910, fmeasure: 0.322017, val_loss: 1.027998, val_accuracy: 0.668182, val_precision: 0.871445, val_recall: 0.369318, val_fmeasure: 0.511923\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 1.5364 - accuracy: 0.4420 - precision: 0.7366 - recall: 0.2179 - fmeasure: 0.3220 - val_loss: 1.0280 - val_accuracy: 0.6682 - val_precision: 0.8714 - val_recall: 0.3693 - val_fmeasure: 0.5119\n",
      "Epoch 4/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.9197 - accuracy: 0.6828 - precision: 0.8292 - recall: 0.5420 - fmeasure: 0.6476src.model - INFO - {Epoch: 3} loss: 0.918566, accuracy: 0.683302, precision: 0.829983, recall: 0.541418, fmeasure: 0.647304, val_loss: 0.549858, val_accuracy: 0.821591, val_precision: 0.884794, val_recall: 0.742045, val_fmeasure: 0.805589\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.9186 - accuracy: 0.6833 - precision: 0.8300 - recall: 0.5414 - fmeasure: 0.6473 - val_loss: 0.5499 - val_accuracy: 0.8216 - val_precision: 0.8848 - val_recall: 0.7420 - val_fmeasure: 0.8056\n",
      "Epoch 5/15\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.5529 - accuracy: 0.8142 - precision: 0.8826 - recall: 0.7481 - fmeasure: 0.8080src.model - INFO - {Epoch: 4} loss: 0.549797, accuracy: 0.815385, precision: 0.883926, recall: 0.751119, fmeasure: 0.810312, val_loss: 0.304691, val_accuracy: 0.910227, val_precision: 0.934594, val_recall: 0.873864, val_fmeasure: 0.902533\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.5498 - accuracy: 0.8154 - precision: 0.8839 - recall: 0.7511 - fmeasure: 0.8103 - val_loss: 0.3047 - val_accuracy: 0.9102 - val_precision: 0.9346 - val_recall: 0.8739 - val_fmeasure: 0.9025\n",
      "Epoch 6/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.3909 - accuracy: 0.8668 - precision: 0.9156 - recall: 0.8267 - fmeasure: 0.8677src.model - INFO - {Epoch: 5} loss: 0.394432, accuracy: 0.864540, precision: 0.913492, recall: 0.821269, fmeasure: 0.863502, val_loss: 0.275375, val_accuracy: 0.914773, val_precision: 0.939299, val_recall: 0.889773, val_fmeasure: 0.913055\n",
      "134/134 [==============================] - 2s 13ms/step - loss: 0.3944 - accuracy: 0.8645 - precision: 0.9135 - recall: 0.8213 - fmeasure: 0.8635 - val_loss: 0.2754 - val_accuracy: 0.9148 - val_precision: 0.9393 - val_recall: 0.8898 - val_fmeasure: 0.9131\n",
      "Epoch 7/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.3410 - accuracy: 0.8878 - precision: 0.9240 - recall: 0.8534 - fmeasure: 0.8865src.model - INFO - {Epoch: 6} loss: 0.337804, accuracy: 0.888555, precision: 0.924958, recall: 0.855597, fmeasure: 0.888122, val_loss: 0.257670, val_accuracy: 0.914773, val_precision: 0.932742, val_recall: 0.904546, val_fmeasure: 0.917943\n",
      "134/134 [==============================] - 2s 13ms/step - loss: 0.3378 - accuracy: 0.8886 - precision: 0.9250 - recall: 0.8556 - fmeasure: 0.8881 - val_loss: 0.2577 - val_accuracy: 0.9148 - val_precision: 0.9327 - val_recall: 0.9045 - val_fmeasure: 0.9179\n",
      "Epoch 8/15\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.2567 - accuracy: 0.9169 - precision: 0.9413 - recall: 0.8915 - fmeasure: 0.9152src.model - INFO - {Epoch: 7} loss: 0.256825, accuracy: 0.917073, precision: 0.941153, recall: 0.890298, fmeasure: 0.914386, val_loss: 0.216973, val_accuracy: 0.919318, val_precision: 0.938497, val_recall: 0.910227, val_fmeasure: 0.923851\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.2568 - accuracy: 0.9171 - precision: 0.9412 - recall: 0.8903 - fmeasure: 0.9144 - val_loss: 0.2170 - val_accuracy: 0.9193 - val_precision: 0.9385 - val_recall: 0.9102 - val_fmeasure: 0.9239\n",
      "Epoch 9/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.2334 - accuracy: 0.9252 - precision: 0.9481 - recall: 0.9023 - fmeasure: 0.9240src.model - INFO - {Epoch: 8} loss: 0.232516, accuracy: 0.925704, precision: 0.947408, recall: 0.900373, fmeasure: 0.922586, val_loss: 0.213703, val_accuracy: 0.938636, val_precision: 0.953157, val_recall: 0.923864, val_fmeasure: 0.938046\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.2325 - accuracy: 0.9257 - precision: 0.9474 - recall: 0.9004 - fmeasure: 0.9226 - val_loss: 0.2137 - val_accuracy: 0.9386 - val_precision: 0.9532 - val_recall: 0.9239 - val_fmeasure: 0.9380\n",
      "Epoch 10/15\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.1687 - accuracy: 0.9500 - precision: 0.9644 - recall: 0.9314 - fmeasure: 0.9473src.model - INFO - {Epoch: 9} loss: 0.169055, accuracy: 0.949719, precision: 0.963031, recall: 0.930597, fmeasure: 0.946183, val_loss: 0.174752, val_accuracy: 0.947727, val_precision: 0.950658, val_recall: 0.945455, val_fmeasure: 0.947990\n",
      "134/134 [==============================] - 2s 13ms/step - loss: 0.1691 - accuracy: 0.9497 - precision: 0.9630 - recall: 0.9306 - fmeasure: 0.9462 - val_loss: 0.1748 - val_accuracy: 0.9477 - val_precision: 0.9507 - val_recall: 0.9455 - val_fmeasure: 0.9480\n",
      "Epoch 11/15\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.2393 - accuracy: 0.9258 - precision: 0.9450 - recall: 0.9081 - fmeasure: 0.9257src.model - INFO - {Epoch: 10} loss: 0.237065, accuracy: 0.926829, precision: 0.946647, recall: 0.909701, fmeasure: 0.927332, val_loss: 0.177655, val_accuracy: 0.946591, val_precision: 0.954778, val_recall: 0.936364, val_fmeasure: 0.945275\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.2371 - accuracy: 0.9268 - precision: 0.9466 - recall: 0.9097 - fmeasure: 0.9273 - val_loss: 0.1777 - val_accuracy: 0.9466 - val_precision: 0.9548 - val_recall: 0.9364 - val_fmeasure: 0.9453\n",
      "Epoch 12/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.1415 - accuracy: 0.9519 - precision: 0.9609 - recall: 0.9397 - fmeasure: 0.9499src.model - INFO - {Epoch: 11} loss: 0.141750, accuracy: 0.951595, precision: 0.961002, recall: 0.939925, fmeasure: 0.950043, val_loss: 0.194665, val_accuracy: 0.944318, val_precision: 0.948266, val_recall: 0.939773, val_fmeasure: 0.943910\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.1418 - accuracy: 0.9516 - precision: 0.9610 - recall: 0.9399 - fmeasure: 0.9500 - val_loss: 0.1947 - val_accuracy: 0.9443 - val_precision: 0.9483 - val_recall: 0.9398 - val_fmeasure: 0.9439\n",
      "Epoch 13/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.1282 - accuracy: 0.9599 - precision: 0.9709 - recall: 0.9500 - fmeasure: 0.9601src.model - INFO - {Epoch: 12} loss: 0.129897, accuracy: 0.959475, precision: 0.970415, recall: 0.950000, fmeasure: 0.959857, val_loss: 0.181858, val_accuracy: 0.954545, val_precision: 0.957536, val_recall: 0.945455, val_fmeasure: 0.951310\n",
      "134/134 [==============================] - 2s 13ms/step - loss: 0.1299 - accuracy: 0.9595 - precision: 0.9704 - recall: 0.9500 - fmeasure: 0.9599 - val_loss: 0.1819 - val_accuracy: 0.9545 - val_precision: 0.9575 - val_recall: 0.9455 - val_fmeasure: 0.9513\n",
      "Epoch 14/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.1219 - accuracy: 0.9603 - precision: 0.9700 - recall: 0.9500 - fmeasure: 0.9596src.model - INFO - {Epoch: 13} loss: 0.122119, accuracy: 0.959850, precision: 0.968390, recall: 0.948880, fmeasure: 0.958307, val_loss: 0.193529, val_accuracy: 0.946591, val_precision: 0.953874, val_recall: 0.935227, val_fmeasure: 0.944254\n",
      "134/134 [==============================] - 2s 13ms/step - loss: 0.1221 - accuracy: 0.9598 - precision: 0.9684 - recall: 0.9489 - fmeasure: 0.9583 - val_loss: 0.1935 - val_accuracy: 0.9466 - val_precision: 0.9539 - val_recall: 0.9352 - val_fmeasure: 0.9443\n",
      "Epoch 15/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.1332 - accuracy: 0.9573 - precision: 0.9667 - recall: 0.9515 - fmeasure: 0.9589src.model - INFO - {Epoch: 14} loss: 0.131820, accuracy: 0.957974, precision: 0.967428, recall: 0.952612, fmeasure: 0.959772, val_loss: 0.197948, val_accuracy: 0.945455, val_precision: 0.948252, val_recall: 0.937500, val_fmeasure: 0.942681\n",
      "134/134 [==============================] - 2s 13ms/step - loss: 0.1318 - accuracy: 0.9580 - precision: 0.9674 - recall: 0.9526 - fmeasure: 0.9598 - val_loss: 0.1979 - val_accuracy: 0.9455 - val_precision: 0.9483 - val_recall: 0.9375 - val_fmeasure: 0.9427\n",
      "src.model - INFO - Training completed\n",
      "src.model - INFO - Evaluating model\n",
      "28/28 [==============================] - 1s 9ms/step - loss: 0.1980 - accuracy: 0.9455 - precision: 0.9491 - recall: 0.9386 - fmeasure: 0.9438\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.0346 - accuracy: 0.9887 - precision: 0.9918 - recall: 0.9859 - fmeasure: 0.9888\n",
      "src.model - INFO - Train loss: 0.034642335027456284\n",
      "src.model - INFO - Train precision: 0.9917914867401123\n",
      "src.model - INFO - Train recall: 0.9858630895614624\n",
      "src.model - INFO - Train f1-score: 0.9887800812721252\n",
      "src.model - INFO - Test loss: 0.19797371327877045\n",
      "src.model - INFO - Test precision: 0.9491191506385803\n",
      "src.model - INFO - Test recall: 0.9386160969734192\n",
      "src.model - INFO - Test f1-score: 0.9437500834465027\n",
      "28/28 [==============================] - 0s 7ms/step\n",
      "src.train - INFO - Confusion Matrix for classes ['a', 'am', 'bm', 'c', 'd', 'dm', 'e', 'em', 'f', 'g']:\n",
      "[[ 84   0   0   1   0   0   0   1   0   0]\n",
      " [  4  67   0   2   0   0   1   0   1   0]\n",
      " [  0   0  70   0   0   0   0   0   0   0]\n",
      " [  0   0   0 100   0   0   0   0   0   0]\n",
      " [  0   2   0   0  86  12   0   0   1   1]\n",
      " [  1   0   0   0   4  76   0   0   0   0]\n",
      " [  0   1   0   0   0   0  88   7   0   0]\n",
      " [  0   0   0   0   0   0   1  77   0   1]\n",
      " [  0   1   0   1   0   0   0   0  90   0]\n",
      " [  0   0   1   0   0   1   0   3   0  94]]\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.2424 - accuracy: 0.9343 - precision: 0.9365 - recall: 0.9259 - fmeasure: 0.9311\n",
      "Test score for instrument: Guitar\n",
      "\tTest loss: 0.24236929416656494\n",
      "\tTest accuracy: 0.9342857003211975\n",
      "\tTest precision: 0.9364827871322632\n",
      "\tTest recall: 0.9259334206581116\n",
      "\tTest f1-score: 0.9310781955718994\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.9228e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - fmeasure: 1.0000\n",
      "Test score for instrument: Accordion\n",
      "\tTest loss: 0.0008922809502109885\n",
      "\tTest accuracy: 1.0\n",
      "\tTest precision: 1.0\n",
      "\tTest recall: 1.0\n",
      "\tTest f1-score: 1.0\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - fmeasure: 1.0000\n",
      "Test score for instrument: Violin\n",
      "\tTest loss: 0.0017422736855223775\n",
      "\tTest accuracy: 1.0\n",
      "\tTest precision: 1.0\n",
      "\tTest recall: 1.0\n",
      "\tTest f1-score: 1.0\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0733 - accuracy: 0.9667 - precision: 0.9808 - recall: 0.9464 - fmeasure: 0.9630\n",
      "Test score for instrument: Piano\n",
      "\tTest loss: 0.07334032654762268\n",
      "\tTest accuracy: 0.9666666388511658\n",
      "\tTest precision: 0.9807692170143127\n",
      "\tTest recall: 0.9464285373687744\n",
      "\tTest f1-score: 0.9629629254341125\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os, sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from settings import *\n",
    "from my_train import *\n",
    "from src.model import CNN\n",
    "\n",
    "datasets_raw, datasets_augmented, size = load_data(METADATA_DIR_RAW_NORMALIZED, METADATA_DIR_AUGMENTED_RAW_NORMALIZED)\n",
    "datasets_augmented = list(map(lambda df: df[~df['augmentation'].isin(['pitch_250', 'pitch_200'])].reset_index(drop=True),datasets_augmented))\n",
    "\n",
    "train_data, test_data, test_datas = train_test(datasets_raw, datasets_augmented)\n",
    "most_shape = get_most_shape(train_data)\n",
    "\n",
    "cnn = CNN(most_shape)\n",
    "my_train(cnn, train_data, test_data, size)\n",
    "\n",
    "test_by_instrument(cnn, test_datas, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.model - INFO - Saving model\n",
      "src.model - INFO - Saved model to /home/tzag/danigil/dl/guitarCR/models\n"
     ]
    }
   ],
   "source": [
    "cnn.save_model(\"myresults_dropout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 1300\n",
      "src.processing - INFO - Number of testing samples is 700\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 585\n",
      "src.processing - INFO - Number of testing samples is 62\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 585\n",
      "src.processing - INFO - Number of testing samples is 62\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 585\n",
      "src.processing - INFO - Number of testing samples is 62\n",
      "src.processing - INFO - Train test split completed\n",
      "The most frequent shape is (128, 213)\n",
      "src.model - INFO - Initializing CNN\n",
      "src.model - INFO - Input shape = (128, 213, 1)\n",
      "src.model - INFO - CNN Initialized\n",
      "src.train - INFO - Number of train samples: 3055\n",
      "src.train - INFO - Number of test samples: 886\n",
      "src.processing - INFO - Start feature target split\n",
      "src.processing - INFO - Feature target split completed\n",
      "src.processing - INFO - Start feature target split\n",
      "src.processing - INFO - Feature target split completed\n",
      "src.processing - INFO - Features reshaped for CNN Input\n",
      "src.processing - INFO - Features reshaped for CNN Input\n",
      "src.processing - INFO - Target one hot encoded\n",
      "src.processing - INFO - Target one hot encoded\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 124, 209, 24)      624       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 31, 104, 24)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 31, 104, 24)       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 27, 100, 48)       28848     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 50, 48)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 6, 50, 48)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 2, 46, 48)         57648     \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 2, 46, 48)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 4416)              0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4416)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                282688    \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 370,458\n",
      "Trainable params: 370,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "src.train - INFO - None\n",
      "src.model - INFO - Start training model\n",
      "src.model - INFO - Tensorboard Logging Started\n",
      "src.model - INFO - Use the following command in the terminal to view the logs during training: tensorboard --logdir logs/training\n",
      "Epoch 1/15\n",
      "153/153 [==============================] - ETA: 0s - loss: 2.3013 - accuracy: 0.1185 - precision: 0.0000e+00 - recall: 0.0000e+00 - fmeasure: 0.0000e+00src.model - INFO - {Epoch: 0} loss: 2.301270, accuracy: 0.118494, precision: 0.000000, recall: 0.000000, fmeasure: 0.000000, val_loss: 2.276483, val_accuracy: 0.146727, val_precision: 0.000000, val_recall: 0.000000, val_fmeasure: 0.000000\n",
      "153/153 [==============================] - 4s 17ms/step - loss: 2.3013 - accuracy: 0.1185 - precision: 0.0000e+00 - recall: 0.0000e+00 - fmeasure: 0.0000e+00 - val_loss: 2.2765 - val_accuracy: 0.1467 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fmeasure: 0.0000e+00\n",
      "Epoch 2/15\n",
      "150/153 [============================>.] - ETA: 0s - loss: 2.1697 - accuracy: 0.2023 - precision: 0.1432 - recall: 0.0130 - fmeasure: 0.0234src.model - INFO - {Epoch: 1} loss: 2.163873, accuracy: 0.204910, precision: 0.160022, recall: 0.015359, fmeasure: 0.027462, val_loss: 1.909088, val_accuracy: 0.378104, val_precision: 0.400000, val_recall: 0.024444, val_fmeasure: 0.045624\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 2.1639 - accuracy: 0.2049 - precision: 0.1600 - recall: 0.0154 - fmeasure: 0.0275 - val_loss: 1.9091 - val_accuracy: 0.3781 - val_precision: 0.4000 - val_recall: 0.0244 - val_fmeasure: 0.0456\n",
      "Epoch 3/15\n",
      "150/153 [============================>.] - ETA: 0s - loss: 1.6604 - accuracy: 0.3923 - precision: 0.6242 - recall: 0.1630 - fmeasure: 0.2467src.model - INFO - {Epoch: 2} loss: 1.656278, accuracy: 0.394108, precision: 0.624583, recall: 0.165359, fmeasure: 0.249433, val_loss: 1.192129, val_accuracy: 0.616253, val_precision: 0.875131, val_recall: 0.279259, val_fmeasure: 0.416306\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 1.6563 - accuracy: 0.3941 - precision: 0.6246 - recall: 0.1654 - fmeasure: 0.2494 - val_loss: 1.1921 - val_accuracy: 0.6163 - val_precision: 0.8751 - val_recall: 0.2793 - val_fmeasure: 0.4163\n",
      "Epoch 4/15\n",
      "150/153 [============================>.] - ETA: 0s - loss: 1.1768 - accuracy: 0.5797 - precision: 0.7699 - recall: 0.3997 - fmeasure: 0.5205src.model - INFO - {Epoch: 3} loss: 1.176999, accuracy: 0.578396, precision: 0.767666, recall: 0.400327, fmeasure: 0.520524, val_loss: 0.793543, val_accuracy: 0.726862, val_precision: 0.852548, val_recall: 0.563333, val_fmeasure: 0.673912\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 1.1770 - accuracy: 0.5784 - precision: 0.7677 - recall: 0.4003 - fmeasure: 0.5205 - val_loss: 0.7935 - val_accuracy: 0.7269 - val_precision: 0.8525 - val_recall: 0.5633 - val_fmeasure: 0.6739\n",
      "Epoch 5/15\n",
      "150/153 [============================>.] - ETA: 0s - loss: 0.9317 - accuracy: 0.6813 - precision: 0.8175 - recall: 0.5413 - fmeasure: 0.6476src.model - INFO - {Epoch: 4} loss: 0.929918, accuracy: 0.681833, precision: 0.816818, recall: 0.542048, fmeasure: 0.647821, val_loss: 0.603704, val_accuracy: 0.809255, val_precision: 0.899705, val_recall: 0.704444, val_fmeasure: 0.787316\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.9299 - accuracy: 0.6818 - precision: 0.8168 - recall: 0.5420 - fmeasure: 0.6478 - val_loss: 0.6037 - val_accuracy: 0.8093 - val_precision: 0.8997 - val_recall: 0.7044 - val_fmeasure: 0.7873\n",
      "Epoch 6/15\n",
      "150/153 [============================>.] - ETA: 0s - loss: 0.7229 - accuracy: 0.7573 - precision: 0.8589 - recall: 0.6640 - fmeasure: 0.7458src.model - INFO - {Epoch: 5} loss: 0.722082, accuracy: 0.758101, precision: 0.859434, recall: 0.664706, fmeasure: 0.746478, val_loss: 0.442199, val_accuracy: 0.867946, val_precision: 0.920253, val_recall: 0.793704, val_fmeasure: 0.850730\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.7221 - accuracy: 0.7581 - precision: 0.8594 - recall: 0.6647 - fmeasure: 0.7465 - val_loss: 0.4422 - val_accuracy: 0.8679 - val_precision: 0.9203 - val_recall: 0.7937 - val_fmeasure: 0.8507\n",
      "Epoch 7/15\n",
      "149/153 [============================>.] - ETA: 0s - loss: 0.6267 - accuracy: 0.7933 - precision: 0.8783 - recall: 0.7158 - fmeasure: 0.7861src.model - INFO - {Epoch: 6} loss: 0.632397, accuracy: 0.792471, precision: 0.876849, recall: 0.715250, fmeasure: 0.785150, val_loss: 0.343238, val_accuracy: 0.893905, val_precision: 0.940861, val_recall: 0.838889, val_fmeasure: 0.885751\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.6324 - accuracy: 0.7925 - precision: 0.8768 - recall: 0.7153 - fmeasure: 0.7851 - val_loss: 0.3432 - val_accuracy: 0.8939 - val_precision: 0.9409 - val_recall: 0.8389 - val_fmeasure: 0.8858\n",
      "Epoch 8/15\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.5773 - accuracy: 0.8159 - precision: 0.8902 - recall: 0.7411 - fmeasure: 0.8069src.model - INFO - {Epoch: 7} loss: 0.577627, accuracy: 0.816039, precision: 0.889196, recall: 0.741285, fmeasure: 0.806576, val_loss: 0.380213, val_accuracy: 0.887133, val_precision: 0.936866, val_recall: 0.830000, val_fmeasure: 0.878712\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.5776 - accuracy: 0.8160 - precision: 0.8892 - recall: 0.7413 - fmeasure: 0.8066 - val_loss: 0.3802 - val_accuracy: 0.8871 - val_precision: 0.9369 - val_recall: 0.8300 - val_fmeasure: 0.8787\n",
      "Epoch 9/15\n",
      "150/153 [============================>.] - ETA: 0s - loss: 0.5122 - accuracy: 0.8310 - precision: 0.8970 - recall: 0.7697 - fmeasure: 0.8268src.model - INFO - {Epoch: 8} loss: 0.510376, accuracy: 0.832733, precision: 0.898992, recall: 0.772113, fmeasure: 0.829146, val_loss: 0.311494, val_accuracy: 0.901806, val_precision: 0.938560, val_recall: 0.866667, val_fmeasure: 0.900169\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.5104 - accuracy: 0.8327 - precision: 0.8990 - recall: 0.7721 - fmeasure: 0.8291 - val_loss: 0.3115 - val_accuracy: 0.9018 - val_precision: 0.9386 - val_recall: 0.8667 - val_fmeasure: 0.9002\n",
      "Epoch 10/15\n",
      "150/153 [============================>.] - ETA: 0s - loss: 0.4287 - accuracy: 0.8660 - precision: 0.9198 - recall: 0.8180 - fmeasure: 0.8645src.model - INFO - {Epoch: 9} loss: 0.426968, accuracy: 0.867103, precision: 0.920182, recall: 0.818083, fmeasure: 0.864669, val_loss: 0.358072, val_accuracy: 0.888262, val_precision: 0.914635, val_recall: 0.864445, val_fmeasure: 0.888298\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.4270 - accuracy: 0.8671 - precision: 0.9202 - recall: 0.8181 - fmeasure: 0.8647 - val_loss: 0.3581 - val_accuracy: 0.8883 - val_precision: 0.9146 - val_recall: 0.8644 - val_fmeasure: 0.8883\n",
      "Epoch 11/15\n",
      "149/153 [============================>.] - ETA: 0s - loss: 0.3915 - accuracy: 0.8664 - precision: 0.9160 - recall: 0.8265 - fmeasure: 0.8679src.model - INFO - {Epoch: 10} loss: 0.391960, accuracy: 0.865794, precision: 0.915299, recall: 0.824619, fmeasure: 0.866462, val_loss: 0.288334, val_accuracy: 0.918736, val_precision: 0.941433, val_recall: 0.894074, val_fmeasure: 0.916436\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.3920 - accuracy: 0.8658 - precision: 0.9153 - recall: 0.8246 - fmeasure: 0.8665 - val_loss: 0.2883 - val_accuracy: 0.9187 - val_precision: 0.9414 - val_recall: 0.8941 - val_fmeasure: 0.9164\n",
      "Epoch 12/15\n",
      "149/153 [============================>.] - ETA: 0s - loss: 0.3426 - accuracy: 0.8869 - precision: 0.9302 - recall: 0.8490 - fmeasure: 0.8868src.model - INFO - {Epoch: 11} loss: 0.343638, accuracy: 0.887398, precision: 0.930589, recall: 0.850218, fmeasure: 0.887642, val_loss: 0.300879, val_accuracy: 0.922122, val_precision: 0.934886, val_recall: 0.904074, val_fmeasure: 0.918821\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.3436 - accuracy: 0.8874 - precision: 0.9306 - recall: 0.8502 - fmeasure: 0.8876 - val_loss: 0.3009 - val_accuracy: 0.9221 - val_precision: 0.9349 - val_recall: 0.9041 - val_fmeasure: 0.9188\n",
      "Epoch 13/15\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.3661 - accuracy: 0.8773 - precision: 0.9219 - recall: 0.8439 - fmeasure: 0.8801src.model - INFO - {Epoch: 12} loss: 0.366093, accuracy: 0.877250, precision: 0.921890, recall: 0.843900, fmeasure: 0.880087, val_loss: 0.245581, val_accuracy: 0.927765, val_precision: 0.953355, val_recall: 0.899630, val_fmeasure: 0.924873\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.3661 - accuracy: 0.8773 - precision: 0.9219 - recall: 0.8439 - fmeasure: 0.8801 - val_loss: 0.2456 - val_accuracy: 0.9278 - val_precision: 0.9534 - val_recall: 0.8996 - val_fmeasure: 0.9249\n",
      "Epoch 14/15\n",
      "150/153 [============================>.] - ETA: 0s - loss: 0.3078 - accuracy: 0.8947 - precision: 0.9298 - recall: 0.8657 - fmeasure: 0.8959src.model - INFO - {Epoch: 13} loss: 0.306848, accuracy: 0.894272, precision: 0.930439, recall: 0.866013, fmeasure: 0.896330, val_loss: 0.289087, val_accuracy: 0.918736, val_precision: 0.937473, val_recall: 0.907408, val_fmeasure: 0.921847\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.3068 - accuracy: 0.8943 - precision: 0.9304 - recall: 0.8660 - fmeasure: 0.8963 - val_loss: 0.2891 - val_accuracy: 0.9187 - val_precision: 0.9375 - val_recall: 0.9074 - val_fmeasure: 0.9218\n",
      "Epoch 15/15\n",
      "149/153 [============================>.] - ETA: 0s - loss: 0.3235 - accuracy: 0.8946 - precision: 0.9252 - recall: 0.8617 - fmeasure: 0.8912src.model - INFO - {Epoch: 14} loss: 0.322110, accuracy: 0.894599, precision: 0.924864, recall: 0.862745, fmeasure: 0.891548, val_loss: 0.273768, val_accuracy: 0.923251, val_precision: 0.942294, val_recall: 0.907778, val_fmeasure: 0.924455\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.3221 - accuracy: 0.8946 - precision: 0.9249 - recall: 0.8627 - fmeasure: 0.8915 - val_loss: 0.2738 - val_accuracy: 0.9233 - val_precision: 0.9423 - val_recall: 0.9078 - val_fmeasure: 0.9245\n",
      "src.model - INFO - Training completed\n",
      "src.model - INFO - Evaluating model\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.2738 - accuracy: 0.9233 - precision: 0.9418 - recall: 0.9064 - fmeasure: 0.9235\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.1538 - accuracy: 0.9499 - precision: 0.9703 - recall: 0.9263 - fmeasure: 0.9474\n",
      "src.model - INFO - Train loss: 0.1538384109735489\n",
      "src.model - INFO - Train precision: 0.9703040719032288\n",
      "src.model - INFO - Train recall: 0.9263455271720886\n",
      "src.model - INFO - Train f1-score: 0.947441041469574\n",
      "src.model - INFO - Test loss: 0.2737541198730469\n",
      "src.model - INFO - Test precision: 0.9418171644210815\n",
      "src.model - INFO - Test recall: 0.9063514471054077\n",
      "src.model - INFO - Test f1-score: 0.9235188364982605\n",
      "28/28 [==============================] - 0s 5ms/step\n",
      "src.train - INFO - Confusion Matrix for classes ['a', 'am', 'bm', 'c', 'd', 'dm', 'e', 'em', 'f', 'g']:\n",
      "[[79  1  1  1  0  0  0  4  0  0]\n",
      " [ 5 65  0  1  0  0  0  2  1  1]\n",
      " [ 0  0 72  0  0  0  0  0  0  1]\n",
      " [ 1  2  0 86  1  0  1  1  0  2]\n",
      " [ 0  0  0  0 87  9  2  0  1  0]\n",
      " [ 0  0  0  0  3 77  0  4  0  0]\n",
      " [ 0  0  0  0  2  0 90  4  0  0]\n",
      " [ 0  1  0  0  0  0  3 80  0  1]\n",
      " [ 0  2  0  0  0  2  0  0 85  0]\n",
      " [ 2  0  0  1  1  0  1  2  1 97]]\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3177 - accuracy: 0.9114 - precision: 0.9297 - recall: 0.8953 - fmeasure: 0.9118\n",
      "Test score for instrument: Guitar\n",
      "\tTest loss: 0.3177022635936737\n",
      "\tTest accuracy: 0.9114285707473755\n",
      "\tTest precision: 0.9296866059303284\n",
      "\tTest recall: 0.8952922224998474\n",
      "\tTest f1-score: 0.9118311405181885\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.0174 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - fmeasure: 1.0000\n",
      "Test score for instrument: Accordion\n",
      "\tTest loss: 0.01743292063474655\n",
      "\tTest accuracy: 1.0\n",
      "\tTest precision: 1.0\n",
      "\tTest recall: 1.0\n",
      "\tTest f1-score: 1.0\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0044 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - fmeasure: 1.0000\n",
      "Test score for instrument: Violin\n",
      "\tTest loss: 0.004415764473378658\n",
      "\tTest accuracy: 1.0\n",
      "\tTest precision: 1.0\n",
      "\tTest recall: 1.0\n",
      "\tTest f1-score: 1.0\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3032 - accuracy: 0.9032 - precision: 0.9463 - recall: 0.8385 - fmeasure: 0.8891\n",
      "Test score for instrument: Piano\n",
      "\tTest loss: 0.30322471261024475\n",
      "\tTest accuracy: 0.9032257795333862\n",
      "\tTest precision: 0.9462864398956299\n",
      "\tTest recall: 0.8385416269302368\n",
      "\tTest f1-score: 0.8890514373779297\n"
     ]
    }
   ],
   "source": [
    "datasets_raw, datasets_augmented, size = load_data(METADATA_DIR_RAW_NORMALIZED, METADATA_DIR_AUGMENTED_RAW_NORMALIZED)\n",
    "\n",
    "train_data, test_data, test_datas = train_test(datasets_raw, datasets_augmented)\n",
    "most_shape = get_most_shape(train_data)\n",
    "\n",
    "cnn = CNN(most_shape)\n",
    "my_train(cnn, train_data, test_data, size)\n",
    "\n",
    "test_by_instrument(cnn, test_datas, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 06:46:51.747358: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-22 06:46:51.871833: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-22 06:46:52.532092: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvrtc.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-22 06:46:52.532187: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-22 06:46:52.532194: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 1300\n",
      "src.processing - INFO - Number of testing samples is 700\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 455\n",
      "src.processing - INFO - Number of testing samples is 60\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 455\n",
      "src.processing - INFO - Number of testing samples is 60\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 455\n",
      "src.processing - INFO - Number of testing samples is 60\n",
      "src.processing - INFO - Train test split completed\n",
      "The most frequent shape is (128, 213)\n",
      "src.model - INFO - Input shape = (128, 213, 1)\n",
      "src.train - INFO - Number of train samples: 2665\n",
      "src.train - INFO - Number of test samples: 880\n",
      "src.processing - INFO - Start feature target split\n",
      "src.processing - INFO - Feature target split completed\n",
      "src.processing - INFO - Start feature target split\n",
      "src.processing - INFO - Feature target split completed\n",
      "src.processing - INFO - Features reshaped for CNN Input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 06:46:55.451799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22324 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:3b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.processing - INFO - Features reshaped for CNN Input\n",
      "src.processing - INFO - Target one hot encoded\n",
      "src.processing - INFO - Target one hot encoded\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 124, 209, 24)      624       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 104, 24)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " activation (Activation)     (None, 31, 104, 24)       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 27, 100, 48)       28848     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 50, 48)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 6, 50, 48)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 2, 46, 48)         57648     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 2, 46, 48)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4416)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                282688    \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 370,458\n",
      "Trainable params: 370,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "src.train - INFO - None\n",
      "src.model - INFO - Start training model\n",
      "src.model - INFO - Tensorboard Logging Started\n",
      "src.model - INFO - Use the following command in the terminal to view the logs during training: tensorboard --logdir logs/training\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 06:46:58.999901: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600\n",
      "2023-05-22 06:46:59.776527: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - ETA: 0s - loss: 2.1592 - accuracy: 0.2173 - precision: 0.1981 - recall: 0.0276 - fmeasure: 0.0465src.model - INFO - {Epoch: 0} loss: 2.159171, accuracy: 0.217261, precision: 0.198134, recall: 0.027612, fmeasure: 0.046486, val_loss: 1.684798, val_accuracy: 0.382955, val_precision: 0.832332, val_recall: 0.157955, val_fmeasure: 0.258780\n",
      "134/134 [==============================] - 7s 17ms/step - loss: 2.1592 - accuracy: 0.2173 - precision: 0.1981 - recall: 0.0276 - fmeasure: 0.0465 - val_loss: 1.6848 - val_accuracy: 0.3830 - val_precision: 0.8323 - val_recall: 0.1580 - val_fmeasure: 0.2588\n",
      "Epoch 2/8\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.9187 - accuracy: 0.6767 - precision: 0.8645 - recall: 0.5286 - fmeasure: 0.6401src.model - INFO - {Epoch: 1} loss: 0.911663, accuracy: 0.679174, precision: 0.866230, recall: 0.535448, fmeasure: 0.645459, val_loss: 0.507260, val_accuracy: 0.842045, val_precision: 0.910714, val_recall: 0.771591, val_fmeasure: 0.833168\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.9117 - accuracy: 0.6792 - precision: 0.8662 - recall: 0.5354 - fmeasure: 0.6455 - val_loss: 0.5073 - val_accuracy: 0.8420 - val_precision: 0.9107 - val_recall: 0.7716 - val_fmeasure: 0.8332\n",
      "Epoch 3/8\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3200 - accuracy: 0.8987 - precision: 0.9491 - recall: 0.8608 - fmeasure: 0.9012src.model - INFO - {Epoch: 2} loss: 0.320031, accuracy: 0.898687, precision: 0.949094, recall: 0.860821, fmeasure: 0.901217, val_loss: 0.327514, val_accuracy: 0.909091, val_precision: 0.934323, val_recall: 0.880682, val_fmeasure: 0.906012\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.3200 - accuracy: 0.8987 - precision: 0.9491 - recall: 0.8608 - fmeasure: 0.9012 - val_loss: 0.3275 - val_accuracy: 0.9091 - val_precision: 0.9343 - val_recall: 0.8807 - val_fmeasure: 0.9060\n",
      "Epoch 4/8\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.2075 - accuracy: 0.9397 - precision: 0.9667 - recall: 0.9172 - fmeasure: 0.9406src.model - INFO - {Epoch: 3} loss: 0.210099, accuracy: 0.938462, precision: 0.967037, recall: 0.916418, fmeasure: 0.940289, val_loss: 0.239633, val_accuracy: 0.930682, val_precision: 0.948397, val_recall: 0.914773, val_fmeasure: 0.930888\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.2101 - accuracy: 0.9385 - precision: 0.9670 - recall: 0.9164 - fmeasure: 0.9403 - val_loss: 0.2396 - val_accuracy: 0.9307 - val_precision: 0.9484 - val_recall: 0.9148 - val_fmeasure: 0.9309\n",
      "Epoch 5/8\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.1238 - accuracy: 0.9676 - precision: 0.9785 - recall: 0.9561 - fmeasure: 0.9669src.model - INFO - {Epoch: 4} loss: 0.122550, accuracy: 0.967355, precision: 0.977134, recall: 0.955223, fmeasure: 0.965747, val_loss: 0.239370, val_accuracy: 0.937500, val_precision: 0.943866, val_recall: 0.921591, val_fmeasure: 0.932329\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.1225 - accuracy: 0.9674 - precision: 0.9771 - recall: 0.9552 - fmeasure: 0.9657 - val_loss: 0.2394 - val_accuracy: 0.9375 - val_precision: 0.9439 - val_recall: 0.9216 - val_fmeasure: 0.9323\n",
      "Epoch 6/8\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.0913 - accuracy: 0.9761 - precision: 0.9818 - recall: 0.9648 - fmeasure: 0.9730src.model - INFO - {Epoch: 5} loss: 0.091229, accuracy: 0.975985, precision: 0.982107, recall: 0.963433, fmeasure: 0.972417, val_loss: 0.305563, val_accuracy: 0.902273, val_precision: 0.912852, val_recall: 0.901136, val_fmeasure: 0.906815\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.0912 - accuracy: 0.9760 - precision: 0.9821 - recall: 0.9634 - fmeasure: 0.9724 - val_loss: 0.3056 - val_accuracy: 0.9023 - val_precision: 0.9129 - val_recall: 0.9011 - val_fmeasure: 0.9068\n",
      "Epoch 7/8\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.1092 - accuracy: 0.9664 - precision: 0.9750 - recall: 0.9588 - fmeasure: 0.9667src.model - INFO - {Epoch: 6} loss: 0.107471, accuracy: 0.966979, precision: 0.975604, recall: 0.959701, fmeasure: 0.967400, val_loss: 0.190682, val_accuracy: 0.953409, val_precision: 0.957775, val_recall: 0.952273, val_fmeasure: 0.954953\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.1075 - accuracy: 0.9670 - precision: 0.9756 - recall: 0.9597 - fmeasure: 0.9674 - val_loss: 0.1907 - val_accuracy: 0.9534 - val_precision: 0.9578 - val_recall: 0.9523 - val_fmeasure: 0.9550\n",
      "Epoch 8/8\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 0.9914 - precision: 0.9925 - recall: 0.9892 - fmeasure: 0.9908src.model - INFO - {Epoch: 7} loss: 0.032302, accuracy: 0.991370, precision: 0.992518, recall: 0.989179, fmeasure: 0.990805, val_loss: 0.188742, val_accuracy: 0.943182, val_precision: 0.944318, val_recall: 0.940909, val_fmeasure: 0.942570\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.0323 - accuracy: 0.9914 - precision: 0.9925 - recall: 0.9892 - fmeasure: 0.9908 - val_loss: 0.1887 - val_accuracy: 0.9432 - val_precision: 0.9443 - val_recall: 0.9409 - val_fmeasure: 0.9426\n",
      "src.model - INFO - Training completed\n",
      "src.model - INFO - Evaluating model\n",
      "28/28 [==============================] - 1s 9ms/step - loss: 0.1887 - accuracy: 0.9432 - precision: 0.9452 - recall: 0.9420 - fmeasure: 0.9436\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.0211 - accuracy: 0.9940 - precision: 0.9952 - recall: 0.9940 - fmeasure: 0.9946\n",
      "src.model - INFO - Train loss: 0.021084867417812347\n",
      "src.model - INFO - Train precision: 0.995151698589325\n",
      "src.model - INFO - Train recall: 0.9940476417541504\n",
      "src.model - INFO - Train f1-score: 0.9945909380912781\n",
      "src.model - INFO - Test loss: 0.18874193727970123\n",
      "src.model - INFO - Test precision: 0.9452044367790222\n",
      "src.model - INFO - Test recall: 0.9419642686843872\n",
      "src.model - INFO - Test f1-score: 0.9435586333274841\n",
      "28/28 [==============================] - 0s 5ms/step\n",
      "src.train - INFO - Confusion Matrix for classes ['a', 'am', 'bm', 'c', 'd', 'dm', 'e', 'em', 'f', 'g']:\n",
      "[[84  1  0  1  0  0  0  0  0  0]\n",
      " [ 5 66  0  0  1  0  0  0  2  1]\n",
      " [ 0  0 70  0  0  0  0  0  0  0]\n",
      " [ 1  0  0 97  1  0  0  1  0  0]\n",
      " [ 0  0  0  0 96  6  0  0  0  0]\n",
      " [ 0  0  0  0  6 75  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 88  8  0  0]\n",
      " [ 0  0  0  1  0  0  2 74  0  2]\n",
      " [ 0  2  0  0  0  1  0  0 89  0]\n",
      " [ 0  0  0  0  0  3  1  4  0 91]]\n",
      "src.model - INFO - Saving model\n",
      "src.model - INFO - Saved model to /home/tzag/danigil/dl/guitarCR/models\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from settings import *\n",
    "from my_train import *\n",
    "from src.model import CNN, CNN_nodropout\n",
    "\n",
    "datasets_raw, datasets_augmented, size = load_data(METADATA_DIR_RAW_NORMALIZED, METADATA_DIR_AUGMENTED_RAW_NORMALIZED)\n",
    "datasets_augmented = list(map(lambda df: df[~df['augmentation'].isin(['pitch_250', 'pitch_200'])].reset_index(drop=True),datasets_augmented))\n",
    "\n",
    "train_data, test_data, test_datas = train_test(datasets_raw, datasets_augmented)\n",
    "most_shape = get_most_shape(train_data)\n",
    "\n",
    "cnn = CNN_nodropout(most_shape)\n",
    "my_train(cnn, train_data, test_data, size, epochs=8)\n",
    "cnn.save_model(\"mymodel\")\n",
    "\n",
    "#test_by_instrument(cnn, test_datas, size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "danigil-steganalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
