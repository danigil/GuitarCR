{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 08:51:26.459457: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-16 08:51:26.568407: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-16 08:51:27.164305: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvrtc.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-16 08:51:27.164397: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-16 08:51:27.164403: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import pandas as pd\n",
    "from src.metrics import *\n",
    "from settings import *\n",
    "from src.data import generate\n",
    "\n",
    "instruments = ['Guitar', 'Accordion', 'Violin', 'Piano']\n",
    "\n",
    "datasets = [(pd.read_pickle(os.path.join(METADATA_DIR_PROCESSED, f'data_{instrument.lower()}.pkl')), instrument) for instrument in instruments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.processing - INFO - Start train test split with split ratio: 0.8\n",
      "src.processing - INFO - Number of training samples is 1600\n",
      "src.processing - INFO - Number of testing samples is 400\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.8\n",
      "src.processing - INFO - Number of training samples is 80\n",
      "src.processing - INFO - Number of testing samples is 20\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.8\n",
      "src.processing - INFO - Number of training samples is 80\n",
      "src.processing - INFO - Number of testing samples is 20\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.8\n",
      "src.processing - INFO - Number of training samples is 80\n",
      "src.processing - INFO - Number of testing samples is 20\n",
      "src.processing - INFO - Train test split completed\n",
      "The most frequent shape is (128, 87)\n",
      "src.train - INFO - Number of train samples: 1840\n",
      "src.train - INFO - Number of test samples: 460\n",
      "src.processing - INFO - Start feature target split\n",
      "src.processing - INFO - Feature target split completed\n",
      "src.processing - INFO - Start feature target split\n",
      "src.processing - INFO - Feature target split completed\n",
      "src.processing - INFO - Features reshaped for CNN Input\n",
      "src.processing - INFO - Features reshaped for CNN Input\n",
      "src.processing - INFO - Target one hot encoded\n",
      "src.processing - INFO - Target one hot encoded\n",
      "src.model - INFO - Initializing CNN\n",
      "src.model - INFO - Input shape = (128, 87, 1)\n",
      "src.model - INFO - CNN Initialized\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 124, 83, 24)       624       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 41, 24)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " activation (Activation)     (None, 31, 41, 24)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 27, 37, 48)        28848     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 18, 48)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 6, 18, 48)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 2, 14, 48)         57648     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 2, 14, 48)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1344)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1344)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                86080     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 173,850\n",
      "Trainable params: 173,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "src.train - INFO - None\n",
      "src.model - INFO - Start training model\n",
      "src.model - INFO - Tensorboard Logging Started\n",
      "src.model - INFO - Use the following command in the terminal to view the logs during training: tensorboard --logdir logs/training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 08:51:32.941476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22324 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:3b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 08:51:36.086723: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600\n",
      "2023-05-16 08:51:36.890369: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - ETA: 0s - loss: 2.7450 - accuracy: 0.1022 - precision: 0.0815 - recall: 0.0076 - fmeasure: 0.0136src.model - INFO - {Epoch: 0} loss: 2.745022, accuracy: 0.102174, precision: 0.081522, recall: 0.007609, fmeasure: 0.013564, val_loss: 2.293684, val_accuracy: 0.104348, val_precision: 0.000000, val_recall: 0.000000, val_fmeasure: 0.000000\n",
      "92/92 [==============================] - 6s 15ms/step - loss: 2.7450 - accuracy: 0.1022 - precision: 0.0815 - recall: 0.0076 - fmeasure: 0.0136 - val_loss: 2.2937 - val_accuracy: 0.1043 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fmeasure: 0.0000e+00\n",
      "Epoch 2/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 2.2820 - accuracy: 0.1379 - precision: 0.0659 - recall: 0.0038 - fmeasure: 0.0072src.model - INFO - {Epoch: 1} loss: 2.281546, accuracy: 0.136957, precision: 0.065217, recall: 0.003804, fmeasure: 0.007152, val_loss: 2.271280, val_accuracy: 0.132609, val_precision: 0.094203, val_recall: 0.010870, val_fmeasure: 0.019419\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 2.2815 - accuracy: 0.1370 - precision: 0.0652 - recall: 0.0038 - fmeasure: 0.0072 - val_loss: 2.2713 - val_accuracy: 0.1326 - val_precision: 0.0942 - val_recall: 0.0109 - val_fmeasure: 0.0194\n",
      "Epoch 3/67\n",
      "92/92 [==============================] - ETA: 0s - loss: 2.2393 - accuracy: 0.1641 - precision: 0.2627 - recall: 0.0174 - fmeasure: 0.0323src.model - INFO - {Epoch: 2} loss: 2.239281, accuracy: 0.164130, precision: 0.262681, recall: 0.017391, fmeasure: 0.032335, val_loss: 2.214020, val_accuracy: 0.182609, val_precision: 0.156522, val_recall: 0.015217, val_fmeasure: 0.026621\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 2.2393 - accuracy: 0.1641 - precision: 0.2627 - recall: 0.0174 - fmeasure: 0.0323 - val_loss: 2.2140 - val_accuracy: 0.1826 - val_precision: 0.1565 - val_recall: 0.0152 - val_fmeasure: 0.0266\n",
      "Epoch 4/67\n",
      "92/92 [==============================] - ETA: 0s - loss: 2.2352 - accuracy: 0.1685 - precision: 0.3116 - recall: 0.0212 - fmeasure: 0.0392src.model - INFO - {Epoch: 3} loss: 2.235166, accuracy: 0.168478, precision: 0.311594, recall: 0.021196, fmeasure: 0.039182, val_loss: 2.190007, val_accuracy: 0.167391, val_precision: 0.108696, val_recall: 0.010870, val_fmeasure: 0.019292\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 2.2352 - accuracy: 0.1685 - precision: 0.3116 - recall: 0.0212 - fmeasure: 0.0392 - val_loss: 2.1900 - val_accuracy: 0.1674 - val_precision: 0.1087 - val_recall: 0.0109 - val_fmeasure: 0.0193\n",
      "Epoch 5/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 2.1622 - accuracy: 0.1835 - precision: 0.3974 - recall: 0.0319 - fmeasure: 0.0583src.model - INFO - {Epoch: 4} loss: 2.163337, accuracy: 0.183152, precision: 0.393116, recall: 0.031522, fmeasure: 0.057651, val_loss: 2.127283, val_accuracy: 0.195652, val_precision: 0.152174, val_recall: 0.013043, val_fmeasure: 0.023433\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 2.1633 - accuracy: 0.1832 - precision: 0.3931 - recall: 0.0315 - fmeasure: 0.0577 - val_loss: 2.1273 - val_accuracy: 0.1957 - val_precision: 0.1522 - val_recall: 0.0130 - val_fmeasure: 0.0234\n",
      "Epoch 6/67\n",
      "90/92 [============================>.] - ETA: 0s - loss: 2.1354 - accuracy: 0.2117 - precision: 0.3565 - recall: 0.0333 - fmeasure: 0.0599src.model - INFO - {Epoch: 5} loss: 2.135426, accuracy: 0.211957, precision: 0.359601, recall: 0.033152, fmeasure: 0.059661, val_loss: 2.024803, val_accuracy: 0.256522, val_precision: 0.365942, val_recall: 0.043478, val_fmeasure: 0.076263\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 2.1354 - accuracy: 0.2120 - precision: 0.3596 - recall: 0.0332 - fmeasure: 0.0597 - val_loss: 2.0248 - val_accuracy: 0.2565 - val_precision: 0.3659 - val_recall: 0.0435 - val_fmeasure: 0.0763\n",
      "Epoch 7/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 2.0177 - accuracy: 0.2747 - precision: 0.4860 - recall: 0.0599 - fmeasure: 0.1036src.model - INFO - {Epoch: 6} loss: 2.013547, accuracy: 0.276087, precision: 0.488471, recall: 0.061957, fmeasure: 0.106480, val_loss: 1.868744, val_accuracy: 0.321739, val_precision: 0.588095, val_recall: 0.117391, val_fmeasure: 0.183923\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 2.0135 - accuracy: 0.2761 - precision: 0.4885 - recall: 0.0620 - fmeasure: 0.1065 - val_loss: 1.8687 - val_accuracy: 0.3217 - val_precision: 0.5881 - val_recall: 0.1174 - val_fmeasure: 0.1839\n",
      "Epoch 8/67\n",
      "92/92 [==============================] - ETA: 0s - loss: 1.9506 - accuracy: 0.2929 - precision: 0.6330 - recall: 0.1005 - fmeasure: 0.1682src.model - INFO - {Epoch: 7} loss: 1.950603, accuracy: 0.292935, precision: 0.633036, recall: 0.100543, fmeasure: 0.168250, val_loss: 1.807116, val_accuracy: 0.360870, val_precision: 0.680763, val_recall: 0.152174, val_fmeasure: 0.235043\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 1.9506 - accuracy: 0.2929 - precision: 0.6330 - recall: 0.1005 - fmeasure: 0.1682 - val_loss: 1.8071 - val_accuracy: 0.3609 - val_precision: 0.6808 - val_recall: 0.1522 - val_fmeasure: 0.2350\n",
      "Epoch 9/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 1.8700 - accuracy: 0.3407 - precision: 0.6886 - recall: 0.1379 - fmeasure: 0.2242src.model - INFO - {Epoch: 8} loss: 1.863567, accuracy: 0.343478, precision: 0.690757, recall: 0.140761, fmeasure: 0.227747, val_loss: 1.686812, val_accuracy: 0.447826, val_precision: 0.786835, val_recall: 0.219565, val_fmeasure: 0.322857\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 1.8636 - accuracy: 0.3435 - precision: 0.6908 - recall: 0.1408 - fmeasure: 0.2277 - val_loss: 1.6868 - val_accuracy: 0.4478 - val_precision: 0.7868 - val_recall: 0.2196 - val_fmeasure: 0.3229\n",
      "Epoch 10/67\n",
      "88/92 [===========================>..] - ETA: 0s - loss: 1.7406 - accuracy: 0.3960 - precision: 0.7907 - recall: 0.2057 - fmeasure: 0.3179src.model - INFO - {Epoch: 9} loss: 1.735957, accuracy: 0.394022, precision: 0.789696, recall: 0.207609, fmeasure: 0.320050, val_loss: 1.704600, val_accuracy: 0.450000, val_precision: 0.723220, val_recall: 0.204348, val_fmeasure: 0.306499\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 1.7360 - accuracy: 0.3940 - precision: 0.7897 - recall: 0.2076 - fmeasure: 0.3201 - val_loss: 1.7046 - val_accuracy: 0.4500 - val_precision: 0.7232 - val_recall: 0.2043 - val_fmeasure: 0.3065\n",
      "Epoch 11/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 1.5966 - accuracy: 0.4324 - precision: 0.8300 - recall: 0.2604 - fmeasure: 0.3861src.model - INFO - {Epoch: 10} loss: 1.595692, accuracy: 0.432065, precision: 0.828633, recall: 0.261413, fmeasure: 0.386935, val_loss: 1.412429, val_accuracy: 0.541304, val_precision: 0.775802, val_recall: 0.313043, val_fmeasure: 0.438310\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 1.5957 - accuracy: 0.4321 - precision: 0.8286 - recall: 0.2614 - fmeasure: 0.3869 - val_loss: 1.4124 - val_accuracy: 0.5413 - val_precision: 0.7758 - val_recall: 0.3130 - val_fmeasure: 0.4383\n",
      "Epoch 12/67\n",
      "92/92 [==============================] - ETA: 0s - loss: 1.5160 - accuracy: 0.4826 - precision: 0.8186 - recall: 0.3027 - fmeasure: 0.4331src.model - INFO - {Epoch: 11} loss: 1.516042, accuracy: 0.482609, precision: 0.818559, recall: 0.302717, fmeasure: 0.433116, val_loss: 1.435846, val_accuracy: 0.563043, val_precision: 0.843495, val_recall: 0.300000, val_fmeasure: 0.428465\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 1.5160 - accuracy: 0.4826 - precision: 0.8186 - recall: 0.3027 - fmeasure: 0.4331 - val_loss: 1.4358 - val_accuracy: 0.5630 - val_precision: 0.8435 - val_recall: 0.3000 - val_fmeasure: 0.4285\n",
      "Epoch 13/67\n",
      "92/92 [==============================] - ETA: 0s - loss: 1.3996 - accuracy: 0.4929 - precision: 0.8456 - recall: 0.3380 - fmeasure: 0.4744src.model - INFO - {Epoch: 12} loss: 1.399629, accuracy: 0.492935, precision: 0.845618, recall: 0.338044, fmeasure: 0.474393, val_loss: 1.321856, val_accuracy: 0.573913, val_precision: 0.857221, val_recall: 0.347826, val_fmeasure: 0.484441\n",
      "92/92 [==============================] - 1s 11ms/step - loss: 1.3996 - accuracy: 0.4929 - precision: 0.8456 - recall: 0.3380 - fmeasure: 0.4744 - val_loss: 1.3219 - val_accuracy: 0.5739 - val_precision: 0.8572 - val_recall: 0.3478 - val_fmeasure: 0.4844\n",
      "Epoch 14/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 1.3044 - accuracy: 0.5379 - precision: 0.8542 - recall: 0.3632 - fmeasure: 0.5006src.model - INFO - {Epoch: 13} loss: 1.305783, accuracy: 0.538043, precision: 0.855799, recall: 0.363043, fmeasure: 0.500835, val_loss: 1.285423, val_accuracy: 0.589130, val_precision: 0.860746, val_recall: 0.393478, val_fmeasure: 0.535570\n",
      "92/92 [==============================] - 1s 11ms/step - loss: 1.3058 - accuracy: 0.5380 - precision: 0.8558 - recall: 0.3630 - fmeasure: 0.5008 - val_loss: 1.2854 - val_accuracy: 0.5891 - val_precision: 0.8607 - val_recall: 0.3935 - val_fmeasure: 0.5356\n",
      "Epoch 15/67\n",
      "88/92 [===========================>..] - ETA: 0s - loss: 1.2264 - accuracy: 0.5585 - precision: 0.8647 - recall: 0.3994 - fmeasure: 0.5397src.model - INFO - {Epoch: 14} loss: 1.238014, accuracy: 0.560326, precision: 0.862903, recall: 0.398913, fmeasure: 0.539121, val_loss: 1.260600, val_accuracy: 0.621739, val_precision: 0.850861, val_recall: 0.406522, val_fmeasure: 0.544334\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 1.2380 - accuracy: 0.5603 - precision: 0.8629 - recall: 0.3989 - fmeasure: 0.5391 - val_loss: 1.2606 - val_accuracy: 0.6217 - val_precision: 0.8509 - val_recall: 0.4065 - val_fmeasure: 0.5443\n",
      "Epoch 16/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 1.4231 - accuracy: 0.5385 - precision: 0.8131 - recall: 0.3544 - fmeasure: 0.4870src.model - INFO - {Epoch: 15} loss: 1.425166, accuracy: 0.538043, precision: 0.810765, recall: 0.353804, fmeasure: 0.486057, val_loss: 1.408127, val_accuracy: 0.552174, val_precision: 0.788258, val_recall: 0.371739, val_fmeasure: 0.499788\n",
      "92/92 [==============================] - 1s 13ms/step - loss: 1.4252 - accuracy: 0.5380 - precision: 0.8108 - recall: 0.3538 - fmeasure: 0.4861 - val_loss: 1.4081 - val_accuracy: 0.5522 - val_precision: 0.7883 - val_recall: 0.3717 - val_fmeasure: 0.4998\n",
      "Epoch 17/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 1.3336 - accuracy: 0.5544 - precision: 0.8203 - recall: 0.3802 - fmeasure: 0.5096src.model - INFO - {Epoch: 16} loss: 1.329567, accuracy: 0.555978, precision: 0.820480, recall: 0.381522, fmeasure: 0.510863, val_loss: 1.215730, val_accuracy: 0.643478, val_precision: 0.881064, val_recall: 0.404348, val_fmeasure: 0.548605\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 1.3296 - accuracy: 0.5560 - precision: 0.8205 - recall: 0.3815 - fmeasure: 0.5109 - val_loss: 1.2157 - val_accuracy: 0.6435 - val_precision: 0.8811 - val_recall: 0.4043 - val_fmeasure: 0.5486\n",
      "Epoch 18/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 1.1696 - accuracy: 0.6044 - precision: 0.8562 - recall: 0.4247 - fmeasure: 0.5611src.model - INFO - {Epoch: 17} loss: 1.163797, accuracy: 0.608152, precision: 0.857150, recall: 0.428804, fmeasure: 0.564405, val_loss: 1.053845, val_accuracy: 0.695652, val_precision: 0.899351, val_recall: 0.465217, val_fmeasure: 0.606229\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 1.1638 - accuracy: 0.6082 - precision: 0.8571 - recall: 0.4288 - fmeasure: 0.5644 - val_loss: 1.0538 - val_accuracy: 0.6957 - val_precision: 0.8994 - val_recall: 0.4652 - val_fmeasure: 0.6062\n",
      "Epoch 19/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 1.0654 - accuracy: 0.6154 - precision: 0.8626 - recall: 0.4429 - fmeasure: 0.5792src.model - INFO - {Epoch: 18} loss: 1.060360, accuracy: 0.616848, precision: 0.863420, recall: 0.446196, fmeasure: 0.581928, val_loss: 0.965146, val_accuracy: 0.643478, val_precision: 0.879744, val_recall: 0.476087, val_fmeasure: 0.608754\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 1.0604 - accuracy: 0.6168 - precision: 0.8634 - recall: 0.4462 - fmeasure: 0.5819 - val_loss: 0.9651 - val_accuracy: 0.6435 - val_precision: 0.8797 - val_recall: 0.4761 - val_fmeasure: 0.6088\n",
      "Epoch 20/67\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.9902 - accuracy: 0.6462 - precision: 0.8605 - recall: 0.4679 - fmeasure: 0.5997src.model - INFO - {Epoch: 19} loss: 0.990229, accuracy: 0.646196, precision: 0.860499, recall: 0.467935, fmeasure: 0.599748, val_loss: 0.989843, val_accuracy: 0.700000, val_precision: 0.921759, val_recall: 0.484783, val_fmeasure: 0.629566\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.9902 - accuracy: 0.6462 - precision: 0.8605 - recall: 0.4679 - fmeasure: 0.5997 - val_loss: 0.9898 - val_accuracy: 0.7000 - val_precision: 0.9218 - val_recall: 0.4848 - val_fmeasure: 0.6296\n",
      "Epoch 21/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.9524 - accuracy: 0.6643 - precision: 0.8700 - recall: 0.5011 - fmeasure: 0.6314src.model - INFO - {Epoch: 20} loss: 0.951548, accuracy: 0.664130, precision: 0.871440, recall: 0.501087, fmeasure: 0.631815, val_loss: 0.928101, val_accuracy: 0.689130, val_precision: 0.871964, val_recall: 0.495652, val_fmeasure: 0.625489\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.9515 - accuracy: 0.6641 - precision: 0.8714 - recall: 0.5011 - fmeasure: 0.6318 - val_loss: 0.9281 - val_accuracy: 0.6891 - val_precision: 0.8720 - val_recall: 0.4957 - val_fmeasure: 0.6255\n",
      "Epoch 22/67\n",
      "88/92 [===========================>..] - ETA: 0s - loss: 0.9168 - accuracy: 0.6716 - precision: 0.8799 - recall: 0.5114 - fmeasure: 0.6406src.model - INFO - {Epoch: 21} loss: 0.914884, accuracy: 0.669565, precision: 0.878959, recall: 0.510326, fmeasure: 0.639583, val_loss: 0.884872, val_accuracy: 0.739130, val_precision: 0.899011, val_recall: 0.523913, val_fmeasure: 0.654349\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.9149 - accuracy: 0.6696 - precision: 0.8790 - recall: 0.5103 - fmeasure: 0.6396 - val_loss: 0.8849 - val_accuracy: 0.7391 - val_precision: 0.8990 - val_recall: 0.5239 - val_fmeasure: 0.6543\n",
      "Epoch 23/67\n",
      "89/92 [============================>.] - ETA: 0s - loss: 0.8731 - accuracy: 0.6955 - precision: 0.8735 - recall: 0.5258 - fmeasure: 0.6506src.model - INFO - {Epoch: 22} loss: 0.877819, accuracy: 0.695109, precision: 0.873643, recall: 0.525000, fmeasure: 0.650156, val_loss: 0.876077, val_accuracy: 0.752174, val_precision: 0.915757, val_recall: 0.539130, val_fmeasure: 0.671736\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.8778 - accuracy: 0.6951 - precision: 0.8736 - recall: 0.5250 - fmeasure: 0.6502 - val_loss: 0.8761 - val_accuracy: 0.7522 - val_precision: 0.9158 - val_recall: 0.5391 - val_fmeasure: 0.6717\n",
      "Epoch 24/67\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.9373 - accuracy: 0.6886 - precision: 0.8659 - recall: 0.5168 - fmeasure: 0.6402src.model - INFO - {Epoch: 23} loss: 0.937280, accuracy: 0.688587, precision: 0.865911, recall: 0.516848, fmeasure: 0.640225, val_loss: 1.177864, val_accuracy: 0.671739, val_precision: 0.815364, val_recall: 0.467391, val_fmeasure: 0.586043\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.9373 - accuracy: 0.6886 - precision: 0.8659 - recall: 0.5168 - fmeasure: 0.6402 - val_loss: 1.1779 - val_accuracy: 0.6717 - val_precision: 0.8154 - val_recall: 0.4674 - val_fmeasure: 0.5860\n",
      "Epoch 25/67\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.9695 - accuracy: 0.6614 - precision: 0.8432 - recall: 0.5054 - fmeasure: 0.6258src.model - INFO - {Epoch: 24} loss: 0.969514, accuracy: 0.661413, precision: 0.843229, recall: 0.505435, fmeasure: 0.625806, val_loss: 0.789024, val_accuracy: 0.758696, val_precision: 0.907657, val_recall: 0.536956, val_fmeasure: 0.664885\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.9695 - accuracy: 0.6614 - precision: 0.8432 - recall: 0.5054 - fmeasure: 0.6258 - val_loss: 0.7890 - val_accuracy: 0.7587 - val_precision: 0.9077 - val_recall: 0.5370 - val_fmeasure: 0.6649\n",
      "Epoch 26/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.8350 - accuracy: 0.7099 - precision: 0.8565 - recall: 0.5560 - fmeasure: 0.6695src.model - INFO - {Epoch: 25} loss: 0.833977, accuracy: 0.711413, precision: 0.857205, recall: 0.556522, fmeasure: 0.670081, val_loss: 0.865939, val_accuracy: 0.747826, val_precision: 0.878317, val_recall: 0.547826, val_fmeasure: 0.664971\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.8340 - accuracy: 0.7114 - precision: 0.8572 - recall: 0.5565 - fmeasure: 0.6701 - val_loss: 0.8659 - val_accuracy: 0.7478 - val_precision: 0.8783 - val_recall: 0.5478 - val_fmeasure: 0.6650\n",
      "Epoch 27/67\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.7448 - accuracy: 0.7239 - precision: 0.8660 - recall: 0.5832 - fmeasure: 0.6921src.model - INFO - {Epoch: 26} loss: 0.744751, accuracy: 0.723913, precision: 0.866042, recall: 0.583152, fmeasure: 0.692135, val_loss: 0.795884, val_accuracy: 0.767391, val_precision: 0.878452, val_recall: 0.584783, val_fmeasure: 0.692506\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.7448 - accuracy: 0.7239 - precision: 0.8660 - recall: 0.5832 - fmeasure: 0.6921 - val_loss: 0.7959 - val_accuracy: 0.7674 - val_precision: 0.8785 - val_recall: 0.5848 - val_fmeasure: 0.6925\n",
      "Epoch 28/67\n",
      "90/92 [============================>.] - ETA: 0s - loss: 0.7028 - accuracy: 0.7356 - precision: 0.8760 - recall: 0.5894 - fmeasure: 0.7015src.model - INFO - {Epoch: 27} loss: 0.701005, accuracy: 0.736413, precision: 0.875812, recall: 0.590217, fmeasure: 0.702027, val_loss: 0.785889, val_accuracy: 0.786957, val_precision: 0.865481, val_recall: 0.634783, val_fmeasure: 0.725715\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.7010 - accuracy: 0.7364 - precision: 0.8758 - recall: 0.5902 - fmeasure: 0.7020 - val_loss: 0.7859 - val_accuracy: 0.7870 - val_precision: 0.8655 - val_recall: 0.6348 - val_fmeasure: 0.7257\n",
      "Epoch 29/67\n",
      "87/92 [===========================>..] - ETA: 0s - loss: 0.7254 - accuracy: 0.7557 - precision: 0.8570 - recall: 0.6299 - fmeasure: 0.7232src.model - INFO - {Epoch: 28} loss: 0.714923, accuracy: 0.760326, precision: 0.860302, recall: 0.633696, fmeasure: 0.726774, val_loss: 0.754421, val_accuracy: 0.776087, val_precision: 0.898927, val_recall: 0.610870, val_fmeasure: 0.717484\n",
      "92/92 [==============================] - 1s 13ms/step - loss: 0.7149 - accuracy: 0.7603 - precision: 0.8603 - recall: 0.6337 - fmeasure: 0.7268 - val_loss: 0.7544 - val_accuracy: 0.7761 - val_precision: 0.8989 - val_recall: 0.6109 - val_fmeasure: 0.7175\n",
      "Epoch 30/67\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.6911 - accuracy: 0.7543 - precision: 0.8783 - recall: 0.6299 - fmeasure: 0.7298src.model - INFO - {Epoch: 29} loss: 0.691073, accuracy: 0.754348, precision: 0.878338, recall: 0.629891, fmeasure: 0.729809, val_loss: 0.737664, val_accuracy: 0.765217, val_precision: 0.852525, val_recall: 0.643478, val_fmeasure: 0.725635\n",
      "92/92 [==============================] - 1s 13ms/step - loss: 0.6911 - accuracy: 0.7543 - precision: 0.8783 - recall: 0.6299 - fmeasure: 0.7298 - val_loss: 0.7377 - val_accuracy: 0.7652 - val_precision: 0.8525 - val_recall: 0.6435 - val_fmeasure: 0.7256\n",
      "Epoch 31/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.6227 - accuracy: 0.7731 - precision: 0.8641 - recall: 0.6549 - fmeasure: 0.7424src.model - INFO - {Epoch: 30} loss: 0.621975, accuracy: 0.773370, precision: 0.863523, recall: 0.654891, fmeasure: 0.742141, val_loss: 0.678777, val_accuracy: 0.823913, val_precision: 0.905258, val_recall: 0.660870, val_fmeasure: 0.756180\n",
      "92/92 [==============================] - 1s 13ms/step - loss: 0.6220 - accuracy: 0.7734 - precision: 0.8635 - recall: 0.6549 - fmeasure: 0.7421 - val_loss: 0.6788 - val_accuracy: 0.8239 - val_precision: 0.9053 - val_recall: 0.6609 - val_fmeasure: 0.7562\n",
      "Epoch 32/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.5401 - accuracy: 0.8005 - precision: 0.8850 - recall: 0.6984 - fmeasure: 0.7774src.model - INFO - {Epoch: 31} loss: 0.540883, accuracy: 0.801630, precision: 0.884998, recall: 0.698913, fmeasure: 0.777787, val_loss: 0.777638, val_accuracy: 0.791304, val_precision: 0.852221, val_recall: 0.667391, val_fmeasure: 0.742323\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.5409 - accuracy: 0.8016 - precision: 0.8850 - recall: 0.6989 - fmeasure: 0.7778 - val_loss: 0.7776 - val_accuracy: 0.7913 - val_precision: 0.8522 - val_recall: 0.6674 - val_fmeasure: 0.7423\n",
      "Epoch 33/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.5804 - accuracy: 0.7940 - precision: 0.8774 - recall: 0.6912 - fmeasure: 0.7705src.model - INFO - {Epoch: 32} loss: 0.579259, accuracy: 0.794565, precision: 0.876548, recall: 0.690217, fmeasure: 0.769599, val_loss: 0.661767, val_accuracy: 0.823913, val_precision: 0.877262, val_recall: 0.741304, val_fmeasure: 0.801675\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.5793 - accuracy: 0.7946 - precision: 0.8765 - recall: 0.6902 - fmeasure: 0.7696 - val_loss: 0.6618 - val_accuracy: 0.8239 - val_precision: 0.8773 - val_recall: 0.7413 - val_fmeasure: 0.8017\n",
      "Epoch 34/67\n",
      "89/92 [============================>.] - ETA: 0s - loss: 0.5382 - accuracy: 0.8090 - precision: 0.8915 - recall: 0.7174 - fmeasure: 0.7920src.model - INFO - {Epoch: 33} loss: 0.539922, accuracy: 0.808152, precision: 0.891769, recall: 0.717935, fmeasure: 0.792477, val_loss: 0.619292, val_accuracy: 0.830435, val_precision: 0.886049, val_recall: 0.739130, val_fmeasure: 0.803076\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.5399 - accuracy: 0.8082 - precision: 0.8918 - recall: 0.7179 - fmeasure: 0.7925 - val_loss: 0.6193 - val_accuracy: 0.8304 - val_precision: 0.8860 - val_recall: 0.7391 - val_fmeasure: 0.8031\n",
      "Epoch 35/67\n",
      "90/92 [============================>.] - ETA: 0s - loss: 0.6149 - accuracy: 0.7894 - precision: 0.8722 - recall: 0.7078 - fmeasure: 0.7787src.model - INFO - {Epoch: 34} loss: 0.612776, accuracy: 0.788587, precision: 0.871149, recall: 0.708152, fmeasure: 0.778478, val_loss: 0.670886, val_accuracy: 0.786957, val_precision: 0.858564, val_recall: 0.717391, val_fmeasure: 0.776429\n",
      "92/92 [==============================] - 1s 13ms/step - loss: 0.6128 - accuracy: 0.7886 - precision: 0.8711 - recall: 0.7082 - fmeasure: 0.7785 - val_loss: 0.6709 - val_accuracy: 0.7870 - val_precision: 0.8586 - val_recall: 0.7174 - val_fmeasure: 0.7764\n",
      "Epoch 36/67\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.5588 - accuracy: 0.7957 - precision: 0.8713 - recall: 0.7103 - fmeasure: 0.7805src.model - INFO - {Epoch: 35} loss: 0.558805, accuracy: 0.795652, precision: 0.871303, recall: 0.710326, fmeasure: 0.780499, val_loss: 0.717604, val_accuracy: 0.821739, val_precision: 0.884323, val_recall: 0.778261, val_fmeasure: 0.825678\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.5588 - accuracy: 0.7957 - precision: 0.8713 - recall: 0.7103 - fmeasure: 0.7805 - val_loss: 0.7176 - val_accuracy: 0.8217 - val_precision: 0.8843 - val_recall: 0.7783 - val_fmeasure: 0.8257\n",
      "Epoch 37/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.5483 - accuracy: 0.8066 - precision: 0.8728 - recall: 0.7242 - fmeasure: 0.7896src.model - INFO - {Epoch: 36} loss: 0.549301, accuracy: 0.805435, precision: 0.871864, recall: 0.722283, fmeasure: 0.788097, val_loss: 0.660183, val_accuracy: 0.834783, val_precision: 0.886072, val_recall: 0.726087, val_fmeasure: 0.794521\n",
      "92/92 [==============================] - 1s 13ms/step - loss: 0.5493 - accuracy: 0.8054 - precision: 0.8719 - recall: 0.7223 - fmeasure: 0.7881 - val_loss: 0.6602 - val_accuracy: 0.8348 - val_precision: 0.8861 - val_recall: 0.7261 - val_fmeasure: 0.7945\n",
      "Epoch 38/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.4447 - accuracy: 0.8258 - precision: 0.9005 - recall: 0.7495 - fmeasure: 0.8150src.model - INFO - {Epoch: 37} loss: 0.444090, accuracy: 0.826087, precision: 0.900277, recall: 0.749457, fmeasure: 0.814909, val_loss: 0.719948, val_accuracy: 0.826087, val_precision: 0.863870, val_recall: 0.780435, val_fmeasure: 0.818523\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.4441 - accuracy: 0.8261 - precision: 0.9003 - recall: 0.7495 - fmeasure: 0.8149 - val_loss: 0.7199 - val_accuracy: 0.8261 - val_precision: 0.8639 - val_recall: 0.7804 - val_fmeasure: 0.8185\n",
      "Epoch 39/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.6239 - accuracy: 0.7874 - precision: 0.8566 - recall: 0.7126 - fmeasure: 0.7764src.model - INFO - {Epoch: 38} loss: 0.622010, accuracy: 0.787500, precision: 0.857398, recall: 0.712500, fmeasure: 0.776667, val_loss: 1.225005, val_accuracy: 0.797826, val_precision: 0.835485, val_recall: 0.760870, val_fmeasure: 0.793828\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.6220 - accuracy: 0.7875 - precision: 0.8574 - recall: 0.7125 - fmeasure: 0.7767 - val_loss: 1.2250 - val_accuracy: 0.7978 - val_precision: 0.8355 - val_recall: 0.7609 - val_fmeasure: 0.7938\n",
      "Epoch 40/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.6857 - accuracy: 0.7978 - precision: 0.8604 - recall: 0.7220 - fmeasure: 0.7832src.model - INFO - {Epoch: 39} loss: 0.683952, accuracy: 0.797283, precision: 0.861897, recall: 0.721739, fmeasure: 0.783662, val_loss: 0.770844, val_accuracy: 0.819565, val_precision: 0.881181, val_recall: 0.791304, val_fmeasure: 0.832397\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.6840 - accuracy: 0.7973 - precision: 0.8619 - recall: 0.7217 - fmeasure: 0.7837 - val_loss: 0.7708 - val_accuracy: 0.8196 - val_precision: 0.8812 - val_recall: 0.7913 - val_fmeasure: 0.8324\n",
      "Epoch 41/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.5472 - accuracy: 0.8115 - precision: 0.8643 - recall: 0.7363 - fmeasure: 0.7931src.model - INFO - {Epoch: 40} loss: 0.550129, accuracy: 0.809783, precision: 0.862802, recall: 0.735326, fmeasure: 0.791925, val_loss: 0.660497, val_accuracy: 0.810870, val_precision: 0.867427, val_recall: 0.773913, val_fmeasure: 0.815661\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.5501 - accuracy: 0.8098 - precision: 0.8628 - recall: 0.7353 - fmeasure: 0.7919 - val_loss: 0.6605 - val_accuracy: 0.8109 - val_precision: 0.8674 - val_recall: 0.7739 - val_fmeasure: 0.8157\n",
      "Epoch 42/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.7036 - accuracy: 0.8143 - precision: 0.8656 - recall: 0.7407 - fmeasure: 0.7965src.model - INFO - {Epoch: 41} loss: 0.719103, accuracy: 0.811957, precision: 0.864114, recall: 0.738587, fmeasure: 0.794654, val_loss: 0.945831, val_accuracy: 0.765217, val_precision: 0.833344, val_recall: 0.702174, val_fmeasure: 0.759853\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.7191 - accuracy: 0.8120 - precision: 0.8641 - recall: 0.7386 - fmeasure: 0.7947 - val_loss: 0.9458 - val_accuracy: 0.7652 - val_precision: 0.8333 - val_recall: 0.7022 - val_fmeasure: 0.7599\n",
      "Epoch 43/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.7016 - accuracy: 0.7747 - precision: 0.8421 - recall: 0.6940 - fmeasure: 0.7583src.model - INFO - {Epoch: 42} loss: 0.699924, accuracy: 0.775000, precision: 0.842574, recall: 0.694565, fmeasure: 0.758904, val_loss: 0.767917, val_accuracy: 0.789130, val_precision: 0.825860, val_recall: 0.723913, val_fmeasure: 0.768305\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.6999 - accuracy: 0.7750 - precision: 0.8426 - recall: 0.6946 - fmeasure: 0.7589 - val_loss: 0.7679 - val_accuracy: 0.7891 - val_precision: 0.8259 - val_recall: 0.7239 - val_fmeasure: 0.7683\n",
      "Epoch 44/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.5630 - accuracy: 0.8110 - precision: 0.8709 - recall: 0.7385 - fmeasure: 0.7974src.model - INFO - {Epoch: 43} loss: 0.564364, accuracy: 0.811413, precision: 0.870583, recall: 0.739130, fmeasure: 0.797682, val_loss: 0.658076, val_accuracy: 0.832609, val_precision: 0.870074, val_recall: 0.780435, val_fmeasure: 0.820263\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.5644 - accuracy: 0.8114 - precision: 0.8706 - recall: 0.7391 - fmeasure: 0.7977 - val_loss: 0.6581 - val_accuracy: 0.8326 - val_precision: 0.8701 - val_recall: 0.7804 - val_fmeasure: 0.8203\n",
      "Epoch 45/67\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.4471 - accuracy: 0.8293 - precision: 0.8759 - recall: 0.7712 - fmeasure: 0.8189src.model - INFO - {Epoch: 44} loss: 0.447090, accuracy: 0.829348, precision: 0.875892, recall: 0.771196, fmeasure: 0.818918, val_loss: 0.572554, val_accuracy: 0.852174, val_precision: 0.890456, val_recall: 0.826087, val_fmeasure: 0.854793\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.4471 - accuracy: 0.8293 - precision: 0.8759 - recall: 0.7712 - fmeasure: 0.8189 - val_loss: 0.5726 - val_accuracy: 0.8522 - val_precision: 0.8905 - val_recall: 0.8261 - val_fmeasure: 0.8548\n",
      "Epoch 46/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.3905 - accuracy: 0.8522 - precision: 0.8997 - recall: 0.8038 - fmeasure: 0.8479src.model - INFO - {Epoch: 45} loss: 0.389395, accuracy: 0.852717, precision: 0.900772, recall: 0.804348, fmeasure: 0.848635, val_loss: 0.628368, val_accuracy: 0.858696, val_precision: 0.885531, val_recall: 0.826087, val_fmeasure: 0.852367\n",
      "92/92 [==============================] - 1s 13ms/step - loss: 0.3894 - accuracy: 0.8527 - precision: 0.9008 - recall: 0.8043 - fmeasure: 0.8486 - val_loss: 0.6284 - val_accuracy: 0.8587 - val_precision: 0.8855 - val_recall: 0.8261 - val_fmeasure: 0.8524\n",
      "Epoch 47/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.3901 - accuracy: 0.8527 - precision: 0.8924 - recall: 0.7984 - fmeasure: 0.8413src.model - INFO - {Epoch: 46} loss: 0.388590, accuracy: 0.853261, precision: 0.892998, recall: 0.798913, fmeasure: 0.841881, val_loss: 0.692837, val_accuracy: 0.860870, val_precision: 0.888514, val_recall: 0.823913, val_fmeasure: 0.851647\n",
      "92/92 [==============================] - 1s 13ms/step - loss: 0.3886 - accuracy: 0.8533 - precision: 0.8930 - recall: 0.7989 - fmeasure: 0.8419 - val_loss: 0.6928 - val_accuracy: 0.8609 - val_precision: 0.8885 - val_recall: 0.8239 - val_fmeasure: 0.8516\n",
      "Epoch 48/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.4108 - accuracy: 0.8429 - precision: 0.8861 - recall: 0.7912 - fmeasure: 0.8346src.model - INFO - {Epoch: 47} loss: 0.412418, accuracy: 0.842935, precision: 0.887307, recall: 0.790761, fmeasure: 0.834873, val_loss: 0.784762, val_accuracy: 0.845652, val_precision: 0.863027, val_recall: 0.813043, val_fmeasure: 0.836357\n",
      "92/92 [==============================] - 1s 13ms/step - loss: 0.4124 - accuracy: 0.8429 - precision: 0.8873 - recall: 0.7908 - fmeasure: 0.8349 - val_loss: 0.7848 - val_accuracy: 0.8457 - val_precision: 0.8630 - val_recall: 0.8130 - val_fmeasure: 0.8364\n",
      "Epoch 49/67\n",
      "88/92 [===========================>..] - ETA: 0s - loss: 0.5181 - accuracy: 0.8261 - precision: 0.8759 - recall: 0.7750 - fmeasure: 0.8209src.model - INFO - {Epoch: 48} loss: 0.560641, accuracy: 0.826087, precision: 0.875392, recall: 0.776087, fmeasure: 0.821295, val_loss: 0.615486, val_accuracy: 0.850000, val_precision: 0.879182, val_recall: 0.819565, val_fmeasure: 0.846777\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.5606 - accuracy: 0.8261 - precision: 0.8754 - recall: 0.7761 - fmeasure: 0.8213 - val_loss: 0.6155 - val_accuracy: 0.8500 - val_precision: 0.8792 - val_recall: 0.8196 - val_fmeasure: 0.8468\n",
      "Epoch 50/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.4917 - accuracy: 0.8368 - precision: 0.8867 - recall: 0.7813 - fmeasure: 0.8294src.model - INFO - {Epoch: 49} loss: 0.493174, accuracy: 0.836957, precision: 0.886085, recall: 0.780978, fmeasure: 0.828920, val_loss: 0.792961, val_accuracy: 0.858696, val_precision: 0.881109, val_recall: 0.841304, val_fmeasure: 0.859943\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.4932 - accuracy: 0.8370 - precision: 0.8861 - recall: 0.7810 - fmeasure: 0.8289 - val_loss: 0.7930 - val_accuracy: 0.8587 - val_precision: 0.8811 - val_recall: 0.8413 - val_fmeasure: 0.8599\n",
      "Epoch 51/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.4035 - accuracy: 0.8516 - precision: 0.8924 - recall: 0.8016 - fmeasure: 0.8431src.model - INFO - {Epoch: 50} loss: 0.403721, accuracy: 0.852174, precision: 0.892291, recall: 0.801087, fmeasure: 0.842718, val_loss: 0.500883, val_accuracy: 0.863043, val_precision: 0.888706, val_recall: 0.836957, val_fmeasure: 0.860707\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.4037 - accuracy: 0.8522 - precision: 0.8923 - recall: 0.8011 - fmeasure: 0.8427 - val_loss: 0.5009 - val_accuracy: 0.8630 - val_precision: 0.8887 - val_recall: 0.8370 - val_fmeasure: 0.8607\n",
      "Epoch 52/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.3625 - accuracy: 0.8643 - precision: 0.9000 - recall: 0.8165 - fmeasure: 0.8551src.model - INFO - {Epoch: 51} loss: 0.361436, accuracy: 0.865217, precision: 0.900538, recall: 0.817935, fmeasure: 0.856148, val_loss: 0.575945, val_accuracy: 0.860870, val_precision: 0.882434, val_recall: 0.845652, val_fmeasure: 0.862665\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.3614 - accuracy: 0.8652 - precision: 0.9005 - recall: 0.8179 - fmeasure: 0.8561 - val_loss: 0.5759 - val_accuracy: 0.8609 - val_precision: 0.8824 - val_recall: 0.8457 - val_fmeasure: 0.8627\n",
      "Epoch 53/67\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.4074 - accuracy: 0.8533 - precision: 0.8981 - recall: 0.8130 - fmeasure: 0.8523src.model - INFO - {Epoch: 52} loss: 0.407390, accuracy: 0.853261, precision: 0.898096, recall: 0.813043, fmeasure: 0.852319, val_loss: 0.610350, val_accuracy: 0.863043, val_precision: 0.881853, val_recall: 0.841304, val_fmeasure: 0.860222\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.4074 - accuracy: 0.8533 - precision: 0.8981 - recall: 0.8130 - fmeasure: 0.8523 - val_loss: 0.6103 - val_accuracy: 0.8630 - val_precision: 0.8819 - val_recall: 0.8413 - val_fmeasure: 0.8602\n",
      "Epoch 54/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.3555 - accuracy: 0.8610 - precision: 0.8921 - recall: 0.8198 - fmeasure: 0.8534src.model - INFO - {Epoch: 53} loss: 0.355004, accuracy: 0.860870, precision: 0.892129, recall: 0.820109, fmeasure: 0.853649, val_loss: 0.660812, val_accuracy: 0.867391, val_precision: 0.885767, val_recall: 0.852174, val_fmeasure: 0.868225\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.3550 - accuracy: 0.8609 - precision: 0.8921 - recall: 0.8201 - fmeasure: 0.8536 - val_loss: 0.6608 - val_accuracy: 0.8674 - val_precision: 0.8858 - val_recall: 0.8522 - val_fmeasure: 0.8682\n",
      "Epoch 55/67\n",
      "89/92 [============================>.] - ETA: 0s - loss: 0.3499 - accuracy: 0.8792 - precision: 0.9143 - recall: 0.8354 - fmeasure: 0.8721src.model - INFO - {Epoch: 54} loss: 0.348640, accuracy: 0.879348, precision: 0.915869, recall: 0.835869, fmeasure: 0.873065, val_loss: 0.567973, val_accuracy: 0.860870, val_precision: 0.893912, val_recall: 0.845652, val_fmeasure: 0.867245\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.3486 - accuracy: 0.8793 - precision: 0.9159 - recall: 0.8359 - fmeasure: 0.8731 - val_loss: 0.5680 - val_accuracy: 0.8609 - val_precision: 0.8939 - val_recall: 0.8457 - val_fmeasure: 0.8672\n",
      "Epoch 56/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.4272 - accuracy: 0.8571 - precision: 0.8920 - recall: 0.8115 - fmeasure: 0.8483src.model - INFO - {Epoch: 55} loss: 0.426406, accuracy: 0.857609, precision: 0.892555, recall: 0.812500, fmeasure: 0.849072, val_loss: 0.792578, val_accuracy: 0.834783, val_precision: 0.875757, val_recall: 0.826087, val_fmeasure: 0.848825\n",
      "92/92 [==============================] - 1s 13ms/step - loss: 0.4264 - accuracy: 0.8576 - precision: 0.8926 - recall: 0.8125 - fmeasure: 0.8491 - val_loss: 0.7926 - val_accuracy: 0.8348 - val_precision: 0.8758 - val_recall: 0.8261 - val_fmeasure: 0.8488\n",
      "Epoch 57/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.5272 - accuracy: 0.8632 - precision: 0.8914 - recall: 0.8269 - fmeasure: 0.8573src.model - INFO - {Epoch: 56} loss: 0.549381, accuracy: 0.860870, precision: 0.888624, recall: 0.824457, fmeasure: 0.854650, val_loss: 1.271949, val_accuracy: 0.806522, val_precision: 0.820201, val_recall: 0.782609, val_fmeasure: 0.800139\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.5494 - accuracy: 0.8609 - precision: 0.8886 - recall: 0.8245 - fmeasure: 0.8547 - val_loss: 1.2719 - val_accuracy: 0.8065 - val_precision: 0.8202 - val_recall: 0.7826 - val_fmeasure: 0.8001\n",
      "Epoch 58/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.5486 - accuracy: 0.8407 - precision: 0.8739 - recall: 0.7945 - fmeasure: 0.8310src.model - INFO - {Epoch: 57} loss: 0.548505, accuracy: 0.840761, precision: 0.873427, recall: 0.794022, fmeasure: 0.830522, val_loss: 1.167462, val_accuracy: 0.804348, val_precision: 0.822384, val_recall: 0.771739, val_fmeasure: 0.795210\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.5485 - accuracy: 0.8408 - precision: 0.8734 - recall: 0.7940 - fmeasure: 0.8305 - val_loss: 1.1675 - val_accuracy: 0.8043 - val_precision: 0.8224 - val_recall: 0.7717 - val_fmeasure: 0.7952\n",
      "Epoch 59/67\n",
      "90/92 [============================>.] - ETA: 0s - loss: 0.4673 - accuracy: 0.8456 - precision: 0.8796 - recall: 0.8139 - fmeasure: 0.8447src.model - INFO - {Epoch: 58} loss: 0.468017, accuracy: 0.845109, precision: 0.878866, recall: 0.814130, fmeasure: 0.844479, val_loss: 0.580459, val_accuracy: 0.858696, val_precision: 0.885606, val_recall: 0.845652, val_fmeasure: 0.863591\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.4680 - accuracy: 0.8451 - precision: 0.8789 - recall: 0.8141 - fmeasure: 0.8445 - val_loss: 0.5805 - val_accuracy: 0.8587 - val_precision: 0.8856 - val_recall: 0.8457 - val_fmeasure: 0.8636\n",
      "Epoch 60/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.3489 - accuracy: 0.8731 - precision: 0.9010 - recall: 0.8451 - fmeasure: 0.8714src.model - INFO - {Epoch: 59} loss: 0.347739, accuracy: 0.873370, precision: 0.901492, recall: 0.845109, fmeasure: 0.871622, val_loss: 0.588104, val_accuracy: 0.873913, val_precision: 0.902490, val_recall: 0.858696, val_fmeasure: 0.879012\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.3477 - accuracy: 0.8734 - precision: 0.9015 - recall: 0.8451 - fmeasure: 0.8716 - val_loss: 0.5881 - val_accuracy: 0.8739 - val_precision: 0.9025 - val_recall: 0.8587 - val_fmeasure: 0.8790\n",
      "Epoch 61/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.3379 - accuracy: 0.8731 - precision: 0.9064 - recall: 0.8456 - fmeasure: 0.8742src.model - INFO - {Epoch: 60} loss: 0.339302, accuracy: 0.872826, precision: 0.906792, recall: 0.845652, fmeasure: 0.874468, val_loss: 0.556626, val_accuracy: 0.878261, val_precision: 0.904429, val_recall: 0.858696, val_fmeasure: 0.879249\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.3393 - accuracy: 0.8728 - precision: 0.9068 - recall: 0.8457 - fmeasure: 0.8745 - val_loss: 0.5566 - val_accuracy: 0.8783 - val_precision: 0.9044 - val_recall: 0.8587 - val_fmeasure: 0.8792\n",
      "Epoch 62/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.3078 - accuracy: 0.8813 - precision: 0.9079 - recall: 0.8489 - fmeasure: 0.8767src.model - INFO - {Epoch: 61} loss: 0.309658, accuracy: 0.880978, precision: 0.908235, recall: 0.848370, fmeasure: 0.876577, val_loss: 0.600028, val_accuracy: 0.865217, val_precision: 0.891014, val_recall: 0.852174, val_fmeasure: 0.870359\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.3097 - accuracy: 0.8810 - precision: 0.9082 - recall: 0.8484 - fmeasure: 0.8766 - val_loss: 0.6000 - val_accuracy: 0.8652 - val_precision: 0.8910 - val_recall: 0.8522 - val_fmeasure: 0.8704\n",
      "Epoch 63/67\n",
      "89/92 [============================>.] - ETA: 0s - loss: 0.2849 - accuracy: 0.8933 - precision: 0.9223 - recall: 0.8736 - fmeasure: 0.8966src.model - INFO - {Epoch: 62} loss: 0.286275, accuracy: 0.892391, precision: 0.921781, recall: 0.872283, fmeasure: 0.895688, val_loss: 0.522560, val_accuracy: 0.900000, val_precision: 0.921234, val_recall: 0.882609, val_fmeasure: 0.900504\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.2863 - accuracy: 0.8924 - precision: 0.9218 - recall: 0.8723 - fmeasure: 0.8957 - val_loss: 0.5226 - val_accuracy: 0.9000 - val_precision: 0.9212 - val_recall: 0.8826 - val_fmeasure: 0.9005\n",
      "Epoch 64/67\n",
      "90/92 [============================>.] - ETA: 0s - loss: 0.2916 - accuracy: 0.9050 - precision: 0.9264 - recall: 0.8800 - fmeasure: 0.9022src.model - INFO - {Epoch: 63} loss: 0.299954, accuracy: 0.905435, precision: 0.926342, recall: 0.880435, fmeasure: 0.902377, val_loss: 0.514232, val_accuracy: 0.893478, val_precision: 0.908447, val_recall: 0.876087, val_fmeasure: 0.891207\n",
      "92/92 [==============================] - 1s 13ms/step - loss: 0.3000 - accuracy: 0.9054 - precision: 0.9263 - recall: 0.8804 - fmeasure: 0.9024 - val_loss: 0.5142 - val_accuracy: 0.8935 - val_precision: 0.9084 - val_recall: 0.8761 - val_fmeasure: 0.8912\n",
      "Epoch 65/67\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.5496 - accuracy: 0.8407 - precision: 0.8784 - recall: 0.8011 - fmeasure: 0.8368src.model - INFO - {Epoch: 64} loss: 0.546756, accuracy: 0.841304, precision: 0.878587, recall: 0.802174, fmeasure: 0.837508, val_loss: 0.716294, val_accuracy: 0.847826, val_precision: 0.883924, val_recall: 0.823913, val_fmeasure: 0.850940\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.5468 - accuracy: 0.8413 - precision: 0.8786 - recall: 0.8022 - fmeasure: 0.8375 - val_loss: 0.7163 - val_accuracy: 0.8478 - val_precision: 0.8839 - val_recall: 0.8239 - val_fmeasure: 0.8509\n",
      "Epoch 66/67\n",
      "90/92 [============================>.] - ETA: 0s - loss: 0.4032 - accuracy: 0.8700 - precision: 0.9050 - recall: 0.8344 - fmeasure: 0.8671src.model - INFO - {Epoch: 65} loss: 0.405373, accuracy: 0.869565, precision: 0.904614, recall: 0.833696, fmeasure: 0.866505, val_loss: 0.563927, val_accuracy: 0.869565, val_precision: 0.893606, val_recall: 0.854348, val_fmeasure: 0.872831\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.4054 - accuracy: 0.8696 - precision: 0.9046 - recall: 0.8337 - fmeasure: 0.8665 - val_loss: 0.5639 - val_accuracy: 0.8696 - val_precision: 0.8936 - val_recall: 0.8543 - val_fmeasure: 0.8728\n",
      "Epoch 67/67\n",
      "89/92 [============================>.] - ETA: 0s - loss: 0.3335 - accuracy: 0.8820 - precision: 0.9017 - recall: 0.8584 - fmeasure: 0.8789src.model - INFO - {Epoch: 66} loss: 0.328033, accuracy: 0.884239, precision: 0.903171, recall: 0.860870, fmeasure: 0.880888, val_loss: 0.584576, val_accuracy: 0.873913, val_precision: 0.892731, val_recall: 0.871739, val_fmeasure: 0.881711\n",
      "92/92 [==============================] - 1s 12ms/step - loss: 0.3280 - accuracy: 0.8842 - precision: 0.9032 - recall: 0.8609 - fmeasure: 0.8809 - val_loss: 0.5846 - val_accuracy: 0.8739 - val_precision: 0.8927 - val_recall: 0.8717 - val_fmeasure: 0.8817\n",
      "src.model - INFO - Training completed\n",
      "15/15 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import keras\n",
    "import os, glob\n",
    "import logging\n",
    "import librosa, librosa.display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, \\\n",
    "                         Flatten, MaxPooling2D\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras import backend as K\n",
    "\n",
    "from src.metrics import *\n",
    "from settings import *\n",
    "from src.data import generate\n",
    "from src.processing import *\n",
    "from src.model import CNN\n",
    "from src.data.preprocessing import get_most_shape\n",
    "from setup_logging import setup_logging\n",
    "\n",
    "setup_logging()\n",
    "logger = logging.getLogger('src.train')\n",
    "\n",
    "augmented = False\n",
    "\n",
    "train_datas = []\n",
    "test_datas = []\n",
    "test_instruments = []\n",
    "for dataset, insrument in datasets:\n",
    "    train_data, test_data = train_test_split(dataset, augmented=augmented, split_ratio=0.8)\n",
    "    train_datas.append(train_data)\n",
    "    test_datas.append(test_data)\n",
    "\n",
    "    test_instruments.append(insrument)\n",
    "\n",
    "train_data = pd.concat(train_datas)\n",
    "test_data = pd.concat(test_datas)\n",
    "\n",
    "most_shape = get_most_shape(train_data)\n",
    "\n",
    "logger.info(f\"Number of train samples: {len(train_data)}\")\n",
    "logger.info(f\"Number of test samples: {len(test_data)}\")\n",
    "# most_shape = get_most_shape(dataset)\n",
    "#train_data, test_data = train_test_split(dataset, augmented=augmented, split_ratio=0.65)\n",
    "\n",
    "X_train, y_train = features_target_split(train_data)\n",
    "X_test, y_test = features_target_split(test_data)\n",
    "\n",
    "# Reshape for CNN input\n",
    "X_train, X_test = reshape_feature_CNN(X_train), reshape_feature_CNN(X_test)\n",
    "\n",
    "# Preserve y_test values\n",
    "y_test_values = y_test.copy()\n",
    "\n",
    "# One-Hot encoding for classes\n",
    "y_train, y_test = one_hot_encode(y_train), one_hot_encode(y_test)\n",
    "\n",
    "# Instance of CNN model\n",
    "cnn = CNN(most_shape)\n",
    "logger.info(str(cnn))\n",
    "\n",
    "cnn.train(X_train, y_train, X_test, y_test)\n",
    "#cnn.evaluate(X_train, y_train, X_test, y_test)\n",
    "\n",
    "if tf.__version__ != '1.8.0':\n",
    "    predict_x=cnn.model.predict(X_test)\n",
    "    predictions = np.argmax(predict_x,axis=1)\n",
    "else:    \n",
    "    predictions = cnn.model.predict_classes(X_test)\n",
    "\n",
    "#conf_matrix=confusion_matrix(y_test_values, predictions, labels=range(10))\n",
    "#logger.info('Confusion Matrix for classes {}:\\n{}'.format(CLASSES, conf_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4443 - accuracy: 0.9100 - precision: 0.9201 - recall: 0.9087 - fmeasure: 0.9142\n",
      "Test score for instrument: Guitar\n",
      "\tTest loss: 0.44427064061164856\n",
      "\tTest accuracy: 0.9100000262260437\n",
      "\tTest precision: 0.9200527667999268\n",
      "\tTest recall: 0.9086538553237915\n",
      "\tTest f1-score: 0.9142233729362488\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4031 - accuracy: 0.7000 - precision: 0.7647 - recall: 0.6500 - fmeasure: 0.7027\n",
      "Test score for instrument: Accordion\n",
      "\tTest loss: 1.4031049013137817\n",
      "\tTest accuracy: 0.699999988079071\n",
      "\tTest precision: 0.7647058963775635\n",
      "\tTest recall: 0.6499999761581421\n",
      "\tTest f1-score: 0.7027026414871216\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8092 - accuracy: 0.6500 - precision: 0.6842 - recall: 0.6500 - fmeasure: 0.6667\n",
      "Test score for instrument: Violin\n",
      "\tTest loss: 0.8092098236083984\n",
      "\tTest accuracy: 0.6499999761581421\n",
      "\tTest precision: 0.6842105388641357\n",
      "\tTest recall: 0.6499999761581421\n",
      "\tTest f1-score: 0.6666666269302368\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.3474 - accuracy: 0.5500 - precision: 0.6471 - recall: 0.5500 - fmeasure: 0.5946\n",
      "Test score for instrument: Piano\n",
      "\tTest loss: 2.3474366664886475\n",
      "\tTest accuracy: 0.550000011920929\n",
      "\tTest precision: 0.6470588445663452\n",
      "\tTest recall: 0.550000011920929\n",
      "\tTest f1-score: 0.5945945382118225\n"
     ]
    }
   ],
   "source": [
    "for test_data, instrument in zip(test_datas, test_instruments):\n",
    "    X_test = test_data['spectrogram']\n",
    "    X_test = np.array([x.reshape( (128, 87, 1) ) for x in X_test])\n",
    "    y_test = test_data['class_ID']\n",
    "\n",
    "    y_test_values=y_test\n",
    "    y_test = np.array(keras.utils.to_categorical(y_test, 10))\n",
    "\n",
    "    score = cnn.model.evaluate(X_test,y_test)\n",
    "    print(f'Test score for instrument: {instrument}')\n",
    "    print('\\tTest loss:', score[0])\n",
    "    print('\\tTest accuracy:', score[1])\n",
    "    print('\\tTest precision:', score[2])\n",
    "    print('\\tTest recall:', score[3])\n",
    "    print('\\tTest f1-score:', score[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save_model(name=\"model_all_data_noaugment_3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "danigil-steganalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
