{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 1300\n",
      "src.processing - INFO - Number of testing samples is 700\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 585\n",
      "src.processing - INFO - Number of testing samples is 315\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 585\n",
      "src.processing - INFO - Number of testing samples is 315\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 585\n",
      "src.processing - INFO - Number of testing samples is 315\n",
      "src.processing - INFO - Train test split completed\n",
      "The most frequent shape is (128, 107)\n",
      "src.train - INFO - Number of train samples: 3055\n",
      "src.train - INFO - Number of test samples: 1645\n",
      "src.processing - INFO - Start feature target split\n",
      "src.processing - INFO - Feature target split completed\n",
      "src.processing - INFO - Start feature target split\n",
      "src.processing - INFO - Feature target split completed\n",
      "src.processing - INFO - Features reshaped for CNN Input\n",
      "src.processing - INFO - Features reshaped for CNN Input\n",
      "src.processing - INFO - Target one hot encoded\n",
      "src.processing - INFO - Target one hot encoded\n",
      "src.model - INFO - Input shape = (128, 107, 1)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 124, 103, 24)      624       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 31, 51, 24)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 31, 51, 24)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 27, 47, 48)        28848     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 6, 23, 48)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 6, 23, 48)         0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 2, 19, 48)         57648     \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 2, 19, 48)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1824)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                116800    \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 204,570\n",
      "Trainable params: 204,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "src.train - INFO - None\n",
      "src.model - INFO - Start training model\n",
      "src.model - INFO - Tensorboard Logging Started\n",
      "src.model - INFO - Use the following command in the terminal to view the logs during training: tensorboard --logdir logs/training\n",
      "Epoch 1/25\n",
      "152/153 [============================>.] - ETA: 0s - loss: 2.2981 - accuracy: 0.2230 - precision: 0.5433 - recall: 0.0750 - fmeasure: 0.1277src.model - INFO - {Epoch: 0} loss: 2.295161, accuracy: 0.223568, precision: 0.546265, recall: 0.076253, fmeasure: 0.129607, val_loss: 2.014331, val_accuracy: 0.283283, val_precision: 0.638239, val_recall: 0.124699, val_fmeasure: 0.202778\n",
      "153/153 [==============================] - 4s 16ms/step - loss: 2.2952 - accuracy: 0.2236 - precision: 0.5463 - recall: 0.0763 - fmeasure: 0.1296 - val_loss: 2.0143 - val_accuracy: 0.2833 - val_precision: 0.6382 - val_recall: 0.1247 - val_fmeasure: 0.2028\n",
      "Epoch 2/25\n",
      "151/153 [============================>.] - ETA: 0s - loss: 1.7753 - accuracy: 0.3825 - precision: 0.8032 - recall: 0.2000 - fmeasure: 0.3134src.model - INFO - {Epoch: 1} loss: 1.773273, accuracy: 0.382979, precision: 0.804687, recall: 0.200218, fmeasure: 0.313638, val_loss: 1.759869, val_accuracy: 0.396353, val_precision: 0.797605, val_recall: 0.237952, val_fmeasure: 0.360057\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 1.7733 - accuracy: 0.3830 - precision: 0.8047 - recall: 0.2002 - fmeasure: 0.3136 - val_loss: 1.7599 - val_accuracy: 0.3964 - val_precision: 0.7976 - val_recall: 0.2380 - val_fmeasure: 0.3601\n",
      "Epoch 3/25\n",
      "151/153 [============================>.] - ETA: 0s - loss: 1.6977 - accuracy: 0.4344 - precision: 0.8186 - recall: 0.2487 - fmeasure: 0.3720src.model - INFO - {Epoch: 2} loss: 1.691650, accuracy: 0.436334, precision: 0.819666, recall: 0.251961, fmeasure: 0.375513, val_loss: 1.508807, val_accuracy: 0.448632, val_precision: 0.886020, val_recall: 0.313253, val_fmeasure: 0.453399\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 1.6917 - accuracy: 0.4363 - precision: 0.8197 - recall: 0.2520 - fmeasure: 0.3755 - val_loss: 1.5088 - val_accuracy: 0.4486 - val_precision: 0.8860 - val_recall: 0.3133 - val_fmeasure: 0.4534\n",
      "Epoch 4/25\n",
      "151/153 [============================>.] - ETA: 0s - loss: 1.4852 - accuracy: 0.5017 - precision: 0.8551 - recall: 0.3212 - fmeasure: 0.4584src.model - INFO - {Epoch: 3} loss: 1.486773, accuracy: 0.501473, precision: 0.853176, recall: 0.321351, fmeasure: 0.458161, val_loss: 1.430204, val_accuracy: 0.500912, val_precision: 0.823650, val_recall: 0.319277, val_fmeasure: 0.452730\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 1.4868 - accuracy: 0.5015 - precision: 0.8532 - recall: 0.3214 - fmeasure: 0.4582 - val_loss: 1.4302 - val_accuracy: 0.5009 - val_precision: 0.8237 - val_recall: 0.3193 - val_fmeasure: 0.4527\n",
      "Epoch 5/25\n",
      "151/153 [============================>.] - ETA: 0s - loss: 1.1946 - accuracy: 0.5891 - precision: 0.9044 - recall: 0.4387 - fmeasure: 0.5828src.model - INFO - {Epoch: 4} loss: 1.195241, accuracy: 0.587889, precision: 0.901800, recall: 0.438018, fmeasure: 0.581614, val_loss: 1.152768, val_accuracy: 0.615198, val_precision: 0.908516, val_recall: 0.484940, val_fmeasure: 0.625291\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 1.1952 - accuracy: 0.5879 - precision: 0.9018 - recall: 0.4380 - fmeasure: 0.5816 - val_loss: 1.1528 - val_accuracy: 0.6152 - val_precision: 0.9085 - val_recall: 0.4849 - val_fmeasure: 0.6253\n",
      "Epoch 6/25\n",
      "152/153 [============================>.] - ETA: 0s - loss: 1.0990 - accuracy: 0.6286 - precision: 0.9065 - recall: 0.5033 - fmeasure: 0.6418src.model - INFO - {Epoch: 5} loss: 1.098589, accuracy: 0.628478, precision: 0.907137, recall: 0.503050, fmeasure: 0.641736, val_loss: 1.209283, val_accuracy: 0.600608, val_precision: 0.864711, val_recall: 0.480120, val_fmeasure: 0.610716\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 1.0986 - accuracy: 0.6285 - precision: 0.9071 - recall: 0.5031 - fmeasure: 0.6417 - val_loss: 1.2093 - val_accuracy: 0.6006 - val_precision: 0.8647 - val_recall: 0.4801 - val_fmeasure: 0.6107\n",
      "Epoch 7/25\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.9555 - accuracy: 0.6762 - precision: 0.9048 - recall: 0.5709 - fmeasure: 0.6948src.model - INFO - {Epoch: 6} loss: 0.954843, accuracy: 0.676268, precision: 0.905119, recall: 0.571678, fmeasure: 0.695552, val_loss: 1.065659, val_accuracy: 0.671125, val_precision: 0.892135, val_recall: 0.540964, val_fmeasure: 0.668867\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.9548 - accuracy: 0.6763 - precision: 0.9051 - recall: 0.5717 - fmeasure: 0.6956 - val_loss: 1.0657 - val_accuracy: 0.6711 - val_precision: 0.8921 - val_recall: 0.5410 - val_fmeasure: 0.6689\n",
      "Epoch 8/25\n",
      "151/153 [============================>.] - ETA: 0s - loss: 1.0386 - accuracy: 0.6877 - precision: 0.9016 - recall: 0.5818 - fmeasure: 0.7025src.model - INFO - {Epoch: 7} loss: 1.040667, accuracy: 0.687725, precision: 0.899886, recall: 0.581373, fmeasure: 0.701760, val_loss: 1.647767, val_accuracy: 0.617021, val_precision: 0.808894, val_recall: 0.515060, val_fmeasure: 0.625019\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 1.0407 - accuracy: 0.6877 - precision: 0.8999 - recall: 0.5814 - fmeasure: 0.7018 - val_loss: 1.6478 - val_accuracy: 0.6170 - val_precision: 0.8089 - val_recall: 0.5151 - val_fmeasure: 0.6250\n",
      "Epoch 9/25\n",
      "152/153 [============================>.] - ETA: 0s - loss: 1.1154 - accuracy: 0.6599 - precision: 0.8711 - recall: 0.5513 - fmeasure: 0.6703src.model - INFO - {Epoch: 8} loss: 1.114396, accuracy: 0.660229, precision: 0.871316, recall: 0.551634, fmeasure: 0.670612, val_loss: 1.041844, val_accuracy: 0.643161, val_precision: 0.881050, val_recall: 0.549398, val_fmeasure: 0.671592\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 1.1144 - accuracy: 0.6602 - precision: 0.8713 - recall: 0.5516 - fmeasure: 0.6706 - val_loss: 1.0418 - val_accuracy: 0.6432 - val_precision: 0.8811 - val_recall: 0.5494 - val_fmeasure: 0.6716\n",
      "Epoch 10/25\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.8428 - accuracy: 0.7296 - precision: 0.9292 - recall: 0.6297 - fmeasure: 0.7453src.model - INFO - {Epoch: 9} loss: 0.842841, accuracy: 0.729624, precision: 0.929194, recall: 0.629738, fmeasure: 0.745262, val_loss: 1.001854, val_accuracy: 0.685714, val_precision: 0.900475, val_recall: 0.598193, val_fmeasure: 0.713869\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.8428 - accuracy: 0.7296 - precision: 0.9292 - recall: 0.6297 - fmeasure: 0.7453 - val_loss: 1.0019 - val_accuracy: 0.6857 - val_precision: 0.9005 - val_recall: 0.5982 - val_fmeasure: 0.7139\n",
      "Epoch 11/25\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.6526 - accuracy: 0.7768 - precision: 0.9603 - recall: 0.6993 - fmeasure: 0.8053src.model - INFO - {Epoch: 10} loss: 0.650048, accuracy: 0.777741, precision: 0.960789, recall: 0.700545, fmeasure: 0.806291, val_loss: 0.997601, val_accuracy: 0.716109, val_precision: 0.871988, val_recall: 0.631928, val_fmeasure: 0.729268\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.6500 - accuracy: 0.7777 - precision: 0.9608 - recall: 0.7005 - fmeasure: 0.8063 - val_loss: 0.9976 - val_accuracy: 0.7161 - val_precision: 0.8720 - val_recall: 0.6319 - val_fmeasure: 0.7293\n",
      "Epoch 12/25\n",
      "152/153 [============================>.] - ETA: 0s - loss: 0.6700 - accuracy: 0.7806 - precision: 0.9503 - recall: 0.7039 - fmeasure: 0.8054src.model - INFO - {Epoch: 11} loss: 0.668968, accuracy: 0.780687, precision: 0.950602, recall: 0.704575, fmeasure: 0.805947, val_loss: 0.855030, val_accuracy: 0.740426, val_precision: 0.901156, val_recall: 0.687952, val_fmeasure: 0.777209\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.6690 - accuracy: 0.7807 - precision: 0.9506 - recall: 0.7046 - fmeasure: 0.8059 - val_loss: 0.8550 - val_accuracy: 0.7404 - val_precision: 0.9012 - val_recall: 0.6880 - val_fmeasure: 0.7772\n",
      "Epoch 13/25\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.5777 - accuracy: 0.8053 - precision: 0.9547 - recall: 0.7281 - fmeasure: 0.8225src.model - INFO - {Epoch: 12} loss: 0.576282, accuracy: 0.805892, precision: 0.955276, recall: 0.729085, fmeasure: 0.823343, val_loss: 0.915420, val_accuracy: 0.751976, val_precision: 0.889699, val_recall: 0.672289, val_fmeasure: 0.762532\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.5763 - accuracy: 0.8059 - precision: 0.9553 - recall: 0.7291 - fmeasure: 0.8233 - val_loss: 0.9154 - val_accuracy: 0.7520 - val_precision: 0.8897 - val_recall: 0.6723 - val_fmeasure: 0.7625\n",
      "Epoch 14/25\n",
      "152/153 [============================>.] - ETA: 0s - loss: 0.4660 - accuracy: 0.8391 - precision: 0.9589 - recall: 0.7632 - fmeasure: 0.8470src.model - INFO - {Epoch: 13} loss: 0.465558, accuracy: 0.838953, precision: 0.959149, recall: 0.763399, fmeasure: 0.847281, val_loss: 0.910276, val_accuracy: 0.778723, val_precision: 0.882616, val_recall: 0.709036, val_fmeasure: 0.783593\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.4656 - accuracy: 0.8390 - precision: 0.9591 - recall: 0.7634 - fmeasure: 0.8473 - val_loss: 0.9103 - val_accuracy: 0.7787 - val_precision: 0.8826 - val_recall: 0.7090 - val_fmeasure: 0.7836\n",
      "Epoch 15/25\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.4481 - accuracy: 0.8493 - precision: 0.9531 - recall: 0.7712 - fmeasure: 0.8497src.model - INFO - {Epoch: 14} loss: 0.452968, accuracy: 0.846481, precision: 0.951588, recall: 0.769063, fmeasure: 0.847789, val_loss: 1.072115, val_accuracy: 0.757447, val_precision: 0.856439, val_recall: 0.670482, val_fmeasure: 0.749285\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.4530 - accuracy: 0.8465 - precision: 0.9516 - recall: 0.7691 - fmeasure: 0.8478 - val_loss: 1.0721 - val_accuracy: 0.7574 - val_precision: 0.8564 - val_recall: 0.6705 - val_fmeasure: 0.7493\n",
      "Epoch 16/25\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.5660 - accuracy: 0.8301 - precision: 0.9296 - recall: 0.7490 - fmeasure: 0.8272src.model - INFO - {Epoch: 15} loss: 0.568074, accuracy: 0.828805, precision: 0.928710, recall: 0.747277, fmeasure: 0.825749, val_loss: 0.836384, val_accuracy: 0.790881, val_precision: 0.876504, val_recall: 0.701205, val_fmeasure: 0.776584\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.5681 - accuracy: 0.8288 - precision: 0.9287 - recall: 0.7473 - fmeasure: 0.8257 - val_loss: 0.8364 - val_accuracy: 0.7909 - val_precision: 0.8765 - val_recall: 0.7012 - val_fmeasure: 0.7766\n",
      "Epoch 17/25\n",
      "152/153 [============================>.] - ETA: 0s - loss: 0.3698 - accuracy: 0.8720 - precision: 0.9537 - recall: 0.8128 - fmeasure: 0.8751src.model - INFO - {Epoch: 16} loss: 0.369351, accuracy: 0.872340, precision: 0.953993, recall: 0.813181, fmeasure: 0.875441, val_loss: 0.682431, val_accuracy: 0.825532, val_precision: 0.900944, val_recall: 0.745181, val_fmeasure: 0.813463\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.3694 - accuracy: 0.8723 - precision: 0.9540 - recall: 0.8132 - fmeasure: 0.8754 - val_loss: 0.6824 - val_accuracy: 0.8255 - val_precision: 0.9009 - val_recall: 0.7452 - val_fmeasure: 0.8135\n",
      "Epoch 18/25\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.3960 - accuracy: 0.8765 - precision: 0.9328 - recall: 0.8179 - fmeasure: 0.8702src.model - INFO - {Epoch: 17} loss: 0.398324, accuracy: 0.875941, precision: 0.932405, recall: 0.816884, fmeasure: 0.869413, val_loss: 1.101798, val_accuracy: 0.786626, val_precision: 0.861343, val_recall: 0.728313, val_fmeasure: 0.787150\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.3983 - accuracy: 0.8759 - precision: 0.9324 - recall: 0.8169 - fmeasure: 0.8694 - val_loss: 1.1018 - val_accuracy: 0.7866 - val_precision: 0.8613 - val_recall: 0.7283 - val_fmeasure: 0.7872\n",
      "Epoch 19/25\n",
      "152/153 [============================>.] - ETA: 0s - loss: 0.7936 - accuracy: 0.8253 - precision: 0.8919 - recall: 0.7576 - fmeasure: 0.8169src.model - INFO - {Epoch: 18} loss: 0.792796, accuracy: 0.824877, precision: 0.891236, recall: 0.757407, fmeasure: 0.816530, val_loss: 0.822433, val_accuracy: 0.810942, val_precision: 0.883588, val_recall: 0.759036, val_fmeasure: 0.814951\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.7928 - accuracy: 0.8249 - precision: 0.8912 - recall: 0.7574 - fmeasure: 0.8165 - val_loss: 0.8224 - val_accuracy: 0.8109 - val_precision: 0.8836 - val_recall: 0.7590 - val_fmeasure: 0.8150\n",
      "Epoch 20/25\n",
      "152/153 [============================>.] - ETA: 0s - loss: 0.3665 - accuracy: 0.8734 - precision: 0.9304 - recall: 0.8191 - fmeasure: 0.8692src.model - INFO - {Epoch: 19} loss: 0.367791, accuracy: 0.872668, precision: 0.929761, recall: 0.818083, fmeasure: 0.868336, val_loss: 1.085246, val_accuracy: 0.800608, val_precision: 0.868241, val_recall: 0.739759, val_fmeasure: 0.797041\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.3678 - accuracy: 0.8727 - precision: 0.9298 - recall: 0.8181 - fmeasure: 0.8683 - val_loss: 1.0852 - val_accuracy: 0.8006 - val_precision: 0.8682 - val_recall: 0.7398 - val_fmeasure: 0.7970\n",
      "Epoch 21/25\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.4124 - accuracy: 0.8848 - precision: 0.9322 - recall: 0.8311 - fmeasure: 0.8774src.model - INFO - {Epoch: 20} loss: 0.410957, accuracy: 0.885106, precision: 0.932641, recall: 0.831264, fmeasure: 0.877678, val_loss: 0.743828, val_accuracy: 0.832827, val_precision: 0.883840, val_recall: 0.775301, val_fmeasure: 0.824394\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.4110 - accuracy: 0.8851 - precision: 0.9326 - recall: 0.8313 - fmeasure: 0.8777 - val_loss: 0.7438 - val_accuracy: 0.8328 - val_precision: 0.8838 - val_recall: 0.7753 - val_fmeasure: 0.8244\n",
      "Epoch 22/25\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.2602 - accuracy: 0.9030 - precision: 0.9451 - recall: 0.8682 - fmeasure: 0.9042src.model - INFO - {Epoch: 21} loss: 0.260297, accuracy: 0.902782, precision: 0.945423, recall: 0.868301, fmeasure: 0.904369, val_loss: 0.709575, val_accuracy: 0.848632, val_precision: 0.883822, val_recall: 0.815663, val_fmeasure: 0.847727\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.2603 - accuracy: 0.9028 - precision: 0.9454 - recall: 0.8683 - fmeasure: 0.9044 - val_loss: 0.7096 - val_accuracy: 0.8486 - val_precision: 0.8838 - val_recall: 0.8157 - val_fmeasure: 0.8477\n",
      "Epoch 23/25\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.8028 - accuracy: 0.8180 - precision: 0.8739 - recall: 0.7614 - fmeasure: 0.8123src.model - INFO - {Epoch: 22} loss: 0.802773, accuracy: 0.818003, precision: 0.873918, recall: 0.761438, fmeasure: 0.812280, val_loss: 0.627496, val_accuracy: 0.824316, val_precision: 0.885643, val_recall: 0.781928, val_fmeasure: 0.829452\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.8028 - accuracy: 0.8180 - precision: 0.8739 - recall: 0.7614 - fmeasure: 0.8123 - val_loss: 0.6275 - val_accuracy: 0.8243 - val_precision: 0.8856 - val_recall: 0.7819 - val_fmeasure: 0.8295\n",
      "Epoch 24/25\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.2487 - accuracy: 0.9106 - precision: 0.9473 - recall: 0.8728 - fmeasure: 0.9075src.model - INFO - {Epoch: 23} loss: 0.247264, accuracy: 0.911293, precision: 0.947571, recall: 0.873747, fmeasure: 0.908076, val_loss: 0.521900, val_accuracy: 0.866869, val_precision: 0.896152, val_recall: 0.835542, val_fmeasure: 0.864061\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.2473 - accuracy: 0.9113 - precision: 0.9476 - recall: 0.8737 - fmeasure: 0.9081 - val_loss: 0.5219 - val_accuracy: 0.8669 - val_precision: 0.8962 - val_recall: 0.8355 - val_fmeasure: 0.8641\n",
      "Epoch 25/25\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.1862 - accuracy: 0.9252 - precision: 0.9553 - recall: 0.9033 - fmeasure: 0.9279src.model - INFO - {Epoch: 24} loss: 0.185247, accuracy: 0.925368, precision: 0.955579, recall: 0.903812, fmeasure: 0.928261, val_loss: 0.518044, val_accuracy: 0.864438, val_precision: 0.889807, val_recall: 0.837952, val_fmeasure: 0.862557\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.1852 - accuracy: 0.9254 - precision: 0.9556 - recall: 0.9038 - fmeasure: 0.9283 - val_loss: 0.5180 - val_accuracy: 0.8644 - val_precision: 0.8898 - val_recall: 0.8380 - val_fmeasure: 0.8626\n",
      "src.model - INFO - Training completed\n",
      "src.model - INFO - Evaluating model\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 0.5180 - accuracy: 0.8644 - precision: 0.8902 - recall: 0.8375 - fmeasure: 0.8626\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.1629 - accuracy: 0.9362 - precision: 0.9558 - recall: 0.9143 - fmeasure: 0.9343\n",
      "src.model - INFO - Train loss: 0.1629219651222229\n",
      "src.model - INFO - Train precision: 0.9558456540107727\n",
      "src.model - INFO - Train recall: 0.9143446087837219\n",
      "src.model - INFO - Train f1-score: 0.9342837929725647\n",
      "src.model - INFO - Test loss: 0.5180437564849854\n",
      "src.model - INFO - Test precision: 0.8901889324188232\n",
      "src.model - INFO - Test recall: 0.8374630212783813\n",
      "src.model - INFO - Test f1-score: 0.8626495003700256\n",
      "52/52 [==============================] - 0s 5ms/step\n",
      "src.train - INFO - Confusion Matrix for classes ['a', 'am', 'bm', 'c', 'd', 'dm', 'e', 'em', 'f', 'g']:\n",
      "[[145   8   0   0   1   0   2   2   0   0]\n",
      " [ 12 148   1   5   4   0   1   0   3   0]\n",
      " [  0   0 136   2   4   2   0   2   0   2]\n",
      " [  1   2   0 126   3   8   0   7   0   7]\n",
      " [  1   0   2   0 127  25   1   0   0   0]\n",
      " [  0   0   0   0  18 156   3   3   0   0]\n",
      " [  2   1   1   0   0   1 125  38   0   0]\n",
      " [  2   0   0   0   0   1   2 165   4   1]\n",
      " [  0   0   1   1   0   1   1   4 134   1]\n",
      " [  0   0   1   0   2   8   4  14   0 160]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import pandas as pd\n",
    "from src.metrics import *\n",
    "from settings import *\n",
    "from src.data import generate\n",
    "\n",
    "instruments = ['Guitar']\n",
    "instruments_aug = ['Accordion', 'Violin', 'Piano']\n",
    "\n",
    "# from setup_logging import setup_logging\n",
    "# setup_logging()\n",
    "\n",
    "#generate.my_run(instruments)\n",
    "datasets_raw = [pd.read_pickle(os.path.join(METADATA_DIR_PROCESSED, f'data_{instrument.lower()}.pkl')) for instrument in instruments]\n",
    "datasets_augmented = [pd.read_pickle(os.path.join(METADATA_DIR_AUGMENTED_RAW, f'data_{instrument.lower()}.pkl')) for instrument in instruments_aug]\n",
    "\n",
    "from src.data.preprocessing import get_max_shape\n",
    "max_spectrogram_size = max(map(lambda df: get_max_shape(df), datasets_raw+datasets_augmented))\n",
    "\n",
    "from src.data.preprocessing import uniform_shape\n",
    "uniform = lambda df: uniform_shape(df, max_spectrogram_size)\n",
    "\n",
    "datasets_raw = list(map(uniform,datasets_raw))\n",
    "datasets_augmented = list(map(uniform,datasets_augmented))\n",
    "datasets_augmented = list(map(lambda df: df[['spectrogram','class_ID', 'class_name','augmentation']],datasets_augmented))\n",
    "datasets_augmented = list(map(lambda df: df.reset_index(drop=True), datasets_augmented))\n",
    "\n",
    "import random\n",
    "import keras\n",
    "import os, glob\n",
    "import logging\n",
    "import librosa, librosa.display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import model_from_json\n",
    "from keras import backend as K\n",
    "\n",
    "from src.metrics import *\n",
    "from settings import *\n",
    "from src.data import generate\n",
    "from src.processing import *\n",
    "from src.model import CNN_nodropout\n",
    "from src.data.preprocessing import get_most_shape\n",
    "from setup_logging import setup_logging\n",
    "\n",
    "setup_logging()\n",
    "logger = logging.getLogger('src.train')\n",
    "\n",
    "train_datas = []\n",
    "test_datas = []\n",
    "\n",
    "for dataset in datasets_raw:\n",
    "    train_data, test_data = train_test_split(dataset, augmented=False, split_ratio=0.65)\n",
    "    train_datas.append(train_data)\n",
    "    test_datas.append(test_data)\n",
    "\n",
    "for dataset in datasets_augmented:\n",
    "    train_data, test_data = train_test_split(dataset, augmented=True, split_ratio=0.65)\n",
    "    train_datas.append(train_data)\n",
    "    test_datas.append(test_data)\n",
    "\n",
    "train_data = pd.concat(train_datas)\n",
    "test_data = pd.concat(test_datas)\n",
    "\n",
    "train_data = train_data.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "test_data = test_data.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "most_shape = get_most_shape(train_data)\n",
    "\n",
    "logger.info(f\"Number of train samples: {len(train_data)}\")\n",
    "logger.info(f\"Number of test samples: {len(test_data)}\")\n",
    "# most_shape = get_most_shape(dataset)\n",
    "#train_data, test_data = train_test_split(dataset, augmented=augmented, split_ratio=0.65)\n",
    "\n",
    "X_train, y_train = features_target_split(train_data)\n",
    "X_test, y_test = features_target_split(test_data)\n",
    "\n",
    "# Reshape for CNN input\n",
    "X_train, X_test = reshape_feature_CNN(X_train, size=max_spectrogram_size), reshape_feature_CNN(X_test, size=max_spectrogram_size)\n",
    "\n",
    "# Preserve y_test values\n",
    "y_test_values = y_test.copy()\n",
    "\n",
    "# One-Hot encoding for classes\n",
    "y_train, y_test = one_hot_encode(y_train), one_hot_encode(y_test)\n",
    "\n",
    "# Instance of CNN model\n",
    "cnn = CNN_nodropout(most_shape)\n",
    "logger.info(str(cnn))\n",
    "\n",
    "cnn.train(X_train, y_train, X_test, y_test, epochs=25)\n",
    "cnn.evaluate(X_train, y_train, X_test, y_test)\n",
    "\n",
    "if tf.__version__ != '1.8.0':\n",
    "    predict_x=cnn.model.predict(X_test)\n",
    "    predictions = np.argmax(predict_x,axis=1)\n",
    "else:    \n",
    "    predictions = cnn.model.predict_classes(X_test)\n",
    "conf_matrix=confusion_matrix(y_test_values, predictions, labels=range(10))\n",
    "logger.info('Confusion Matrix for classes {}:\\n{}'.format(CLASSES, conf_matrix))\n",
    "#cnn.save_model(name=\"model_all_data_augment_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 7ms/step - loss: 0.7460 - accuracy: 0.7743 - precision: 0.8125 - recall: 0.7141 - fmeasure: 0.7562\n",
      "Test score for instrument: Guitar\n",
      "\tTest loss: 0.7459526658058167\n",
      "\tTest accuracy: 0.7742857336997986\n",
      "\tTest precision: 0.8124560713768005\n",
      "\tTest recall: 0.7140827775001526\n",
      "\tTest f1-score: 0.7562323212623596\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4504 - accuracy: 0.9492 - precision: 0.9528 - recall: 0.9500 - fmeasure: 0.9514\n",
      "Test score for instrument: Accordion\n",
      "\tTest loss: 0.45035186409950256\n",
      "\tTest accuracy: 0.9492063522338867\n",
      "\tTest precision: 0.9528225660324097\n",
      "\tTest recall: 0.949999988079071\n",
      "\tTest f1-score: 0.951388955116272\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2914 - accuracy: 0.9365 - precision: 0.9392 - recall: 0.9344 - fmeasure: 0.9368\n",
      "Test score for instrument: Violin\n",
      "\tTest loss: 0.2913728356361389\n",
      "\tTest accuracy: 0.9365079402923584\n",
      "\tTest precision: 0.939213752746582\n",
      "\tTest recall: 0.934374988079071\n",
      "\tTest f1-score: 0.9367559552192688\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3059 - accuracy: 0.9079 - precision: 0.9185 - recall: 0.8969 - fmeasure: 0.9070\n",
      "Test score for instrument: Piano\n",
      "\tTest loss: 0.3059425354003906\n",
      "\tTest accuracy: 0.9079365134239197\n",
      "\tTest precision: 0.9185339212417603\n",
      "\tTest recall: 0.8968750238418579\n",
      "\tTest f1-score: 0.9070337414741516\n"
     ]
    }
   ],
   "source": [
    "test_instruments = instruments + instruments_aug\n",
    "for test_data, instrument in zip(test_datas, test_instruments):\n",
    "    X_test = test_data['spectrogram']\n",
    "    X_test = np.array([x.reshape( (128, max_spectrogram_size, 1) ) for x in X_test])\n",
    "    y_test = test_data['class_ID']\n",
    "\n",
    "    y_test_values=y_test\n",
    "    y_test = np.array(keras.utils.to_categorical(y_test, 10))\n",
    "\n",
    "    score = cnn.model.evaluate(X_test,y_test)\n",
    "    print(f'Test score for instrument: {instrument}')\n",
    "    print('\\tTest loss:', score[0])\n",
    "    print('\\tTest accuracy:', score[1])\n",
    "    print('\\tTest precision:', score[2])\n",
    "    print('\\tTest recall:', score[3])\n",
    "    print('\\tTest f1-score:', score[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 15:15:19.477892: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-20 15:15:19.612286: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-20 15:15:20.213779: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvrtc.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-20 15:15:20.213853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-20 15:15:20.213860: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 1300\n",
      "src.processing - INFO - Number of testing samples is 700\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 585\n",
      "src.processing - INFO - Number of testing samples is 62\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 585\n",
      "src.processing - INFO - Number of testing samples is 62\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 585\n",
      "src.processing - INFO - Number of testing samples is 62\n",
      "src.processing - INFO - Train test split completed\n",
      "The most frequent shape is (128, 213)\n",
      "src.train - INFO - Number of train samples: 3055\n",
      "src.train - INFO - Number of test samples: 886\n",
      "src.processing - INFO - Start feature target split\n",
      "src.processing - INFO - Feature target split completed\n",
      "src.processing - INFO - Start feature target split\n",
      "src.processing - INFO - Feature target split completed\n",
      "src.processing - INFO - Features reshaped for CNN Input\n",
      "src.processing - INFO - Features reshaped for CNN Input\n",
      "src.processing - INFO - Target one hot encoded\n",
      "src.processing - INFO - Target one hot encoded\n",
      "src.model - INFO - Input shape = (128, 213, 1)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 124, 209, 24)      624       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 104, 24)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " activation (Activation)     (None, 31, 104, 24)       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 27, 100, 48)       28848     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 50, 48)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 6, 50, 48)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 2, 46, 48)         57648     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 2, 46, 48)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4416)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                282688    \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 370,458\n",
      "Trainable params: 370,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "src.train - INFO - None\n",
      "src.model - INFO - Start training model\n",
      "src.model - INFO - Tensorboard Logging Started\n",
      "src.model - INFO - Use the following command in the terminal to view the logs during training: tensorboard --logdir logs/training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 15:15:23.065962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22324 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:3b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 15:15:26.486640: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8600\n",
      "2023-05-20 15:15:27.283620: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/153 [==============================] - ETA: 0s - loss: 2.1523 - accuracy: 0.1961 - precision: 0.1993 - recall: 0.0191 - fmeasure: 0.0338src.model - INFO - {Epoch: 0} loss: 2.152259, accuracy: 0.196072, precision: 0.199346, recall: 0.019063, fmeasure: 0.033792, val_loss: 1.648882, val_accuracy: 0.393905, val_precision: 0.777037, val_recall: 0.122593, val_fmeasure: 0.206370\n",
      "153/153 [==============================] - 7s 17ms/step - loss: 2.1523 - accuracy: 0.1961 - precision: 0.1993 - recall: 0.0191 - fmeasure: 0.0338 - val_loss: 1.6489 - val_accuracy: 0.3939 - val_precision: 0.7770 - val_recall: 0.1226 - val_fmeasure: 0.2064\n",
      "Epoch 2/8\n",
      "151/153 [============================>.] - ETA: 0s - loss: 1.0894 - accuracy: 0.6242 - precision: 0.8209 - recall: 0.4411 - fmeasure: 0.5594src.model - INFO - {Epoch: 1} loss: 1.085702, accuracy: 0.626187, precision: 0.821234, recall: 0.444553, fmeasure: 0.562184, val_loss: 0.611489, val_accuracy: 0.816027, val_precision: 0.901853, val_recall: 0.705926, val_fmeasure: 0.788795\n",
      "153/153 [==============================] - 2s 13ms/step - loss: 1.0857 - accuracy: 0.6262 - precision: 0.8212 - recall: 0.4446 - fmeasure: 0.5622 - val_loss: 0.6115 - val_accuracy: 0.8160 - val_precision: 0.9019 - val_recall: 0.7059 - val_fmeasure: 0.7888\n",
      "Epoch 3/8\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.5505 - accuracy: 0.8142 - precision: 0.8914 - recall: 0.7530 - fmeasure: 0.8142src.model - INFO - {Epoch: 2} loss: 0.549658, accuracy: 0.814403, precision: 0.890812, recall: 0.753268, fmeasure: 0.814106, val_loss: 0.458197, val_accuracy: 0.855531, val_precision: 0.900850, val_recall: 0.813333, val_fmeasure: 0.853676\n",
      "153/153 [==============================] - 2s 13ms/step - loss: 0.5497 - accuracy: 0.8144 - precision: 0.8908 - recall: 0.7533 - fmeasure: 0.8141 - val_loss: 0.4582 - val_accuracy: 0.8555 - val_precision: 0.9009 - val_recall: 0.8133 - val_fmeasure: 0.8537\n",
      "Epoch 4/8\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.3330 - accuracy: 0.8887 - precision: 0.9237 - recall: 0.8576 - fmeasure: 0.8887src.model - INFO - {Epoch: 3} loss: 0.331106, accuracy: 0.889689, precision: 0.924711, recall: 0.858715, fmeasure: 0.889751, val_loss: 0.398409, val_accuracy: 0.875847, val_precision: 0.900193, val_recall: 0.854074, val_fmeasure: 0.876010\n",
      "153/153 [==============================] - 2s 13ms/step - loss: 0.3311 - accuracy: 0.8897 - precision: 0.9247 - recall: 0.8587 - fmeasure: 0.8898 - val_loss: 0.3984 - val_accuracy: 0.8758 - val_precision: 0.9002 - val_recall: 0.8541 - val_fmeasure: 0.8760\n",
      "Epoch 5/8\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.2305 - accuracy: 0.9280 - precision: 0.9462 - recall: 0.9019 - fmeasure: 0.9229src.model - INFO - {Epoch: 4} loss: 0.230518, accuracy: 0.927987, precision: 0.946184, recall: 0.901851, fmeasure: 0.922919, val_loss: 0.311690, val_accuracy: 0.888262, val_precision: 0.915494, val_recall: 0.880000, val_fmeasure: 0.896958\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.2305 - accuracy: 0.9280 - precision: 0.9462 - recall: 0.9019 - fmeasure: 0.9229 - val_loss: 0.3117 - val_accuracy: 0.8883 - val_precision: 0.9155 - val_recall: 0.8800 - val_fmeasure: 0.8970\n",
      "Epoch 6/8\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.1719 - accuracy: 0.9457 - precision: 0.9582 - recall: 0.9315 - fmeasure: 0.9443src.model - INFO - {Epoch: 5} loss: 0.171176, accuracy: 0.945663, precision: 0.958116, recall: 0.931699, fmeasure: 0.944351, val_loss: 0.287808, val_accuracy: 0.916479, val_precision: 0.937140, val_recall: 0.903334, val_fmeasure: 0.919482\n",
      "153/153 [==============================] - 2s 13ms/step - loss: 0.1712 - accuracy: 0.9457 - precision: 0.9581 - recall: 0.9317 - fmeasure: 0.9444 - val_loss: 0.2878 - val_accuracy: 0.9165 - val_precision: 0.9371 - val_recall: 0.9033 - val_fmeasure: 0.9195\n",
      "Epoch 7/8\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.1327 - accuracy: 0.9583 - precision: 0.9680 - recall: 0.9450 - fmeasure: 0.9561src.model - INFO - {Epoch: 6} loss: 0.133385, accuracy: 0.957774, precision: 0.967448, recall: 0.944771, fmeasure: 0.955732, val_loss: 0.286158, val_accuracy: 0.908578, val_precision: 0.917531, val_recall: 0.901111, val_fmeasure: 0.909084\n",
      "153/153 [==============================] - 2s 13ms/step - loss: 0.1334 - accuracy: 0.9578 - precision: 0.9674 - recall: 0.9448 - fmeasure: 0.9557 - val_loss: 0.2862 - val_accuracy: 0.9086 - val_precision: 0.9175 - val_recall: 0.9011 - val_fmeasure: 0.9091\n",
      "Epoch 8/8\n",
      "150/153 [============================>.] - ETA: 0s - loss: 0.0927 - accuracy: 0.9710 - precision: 0.9761 - recall: 0.9640 - fmeasure: 0.9699src.model - INFO - {Epoch: 7} loss: 0.094327, accuracy: 0.970867, precision: 0.976281, recall: 0.963616, fmeasure: 0.969758, val_loss: 0.244183, val_accuracy: 0.927765, val_precision: 0.936082, val_recall: 0.924445, val_fmeasure: 0.930084\n",
      "153/153 [==============================] - 2s 13ms/step - loss: 0.0943 - accuracy: 0.9709 - precision: 0.9763 - recall: 0.9636 - fmeasure: 0.9698 - val_loss: 0.2442 - val_accuracy: 0.9278 - val_precision: 0.9361 - val_recall: 0.9244 - val_fmeasure: 0.9301\n",
      "src.model - INFO - Training completed\n",
      "src.model - INFO - Evaluating model\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.2442 - accuracy: 0.9278 - precision: 0.9356 - recall: 0.9241 - fmeasure: 0.9297\n",
      "96/96 [==============================] - 1s 8ms/step - loss: 0.0537 - accuracy: 0.9840 - precision: 0.9878 - recall: 0.9807 - fmeasure: 0.9842\n",
      "src.model - INFO - Train loss: 0.05370834842324257\n",
      "src.model - INFO - Train precision: 0.9877850413322449\n",
      "src.model - INFO - Train recall: 0.9807074666023254\n",
      "src.model - INFO - Train f1-score: 0.9841790795326233\n",
      "src.model - INFO - Test loss: 0.24418321251869202\n",
      "src.model - INFO - Test precision: 0.935623049736023\n",
      "src.model - INFO - Test recall: 0.9241071343421936\n",
      "src.model - INFO - Test f1-score: 0.9297384023666382\n",
      "28/28 [==============================] - 0s 5ms/step\n",
      "src.train - INFO - Confusion Matrix for classes ['a', 'am', 'bm', 'c', 'd', 'dm', 'e', 'em', 'f', 'g']:\n",
      "[[ 81   2   0   0   0   0   0   2   0   1]\n",
      " [  4  66   0   2   0   0   1   0   2   0]\n",
      " [  0   0  73   0   0   0   0   0   0   0]\n",
      " [  1   1   0  89   3   0   0   0   0   0]\n",
      " [  0   1   2   0  87   8   0   0   0   1]\n",
      " [  0   0   0   0   5  79   0   0   0   0]\n",
      " [  2   2   1   0   3   0  86   2   0   0]\n",
      " [  0   0   0   0   0   0   4  80   0   1]\n",
      " [  0   4   0   1   0   1   1   1  81   0]\n",
      " [  0   0   1   0   0   1   0   3   0 100]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import pandas as pd\n",
    "from src.metrics import *\n",
    "from settings import *\n",
    "from src.data import generate\n",
    "\n",
    "instruments = ['Guitar']\n",
    "instruments_aug = ['Accordion', 'Violin', 'Piano']\n",
    "\n",
    "# from setup_logging import setup_logging\n",
    "# setup_logging()\n",
    "\n",
    "#generate.my_run(instruments)\n",
    "datasets_raw = [pd.read_pickle(os.path.join(METADATA_DIR_PROCESSED_NORMALIZED, f'data_{instrument.lower()}.pkl')) for instrument in instruments]\n",
    "datasets_augmented = [pd.read_pickle(os.path.join(METADATA_DIR_AUGMENTED_RAW_NORMALIZED, f'data_{instrument.lower()}.pkl')) for instrument in instruments_aug]\n",
    "\n",
    "from src.data.preprocessing import get_max_shape\n",
    "max_spectrogram_size = max(map(lambda df: get_max_shape(df), datasets_raw+datasets_augmented))\n",
    "\n",
    "from src.data.preprocessing import uniform_shape\n",
    "uniform = lambda df: uniform_shape(df, max_spectrogram_size)\n",
    "\n",
    "datasets_raw = list(map(uniform,datasets_raw))\n",
    "datasets_augmented = list(map(uniform,datasets_augmented))\n",
    "datasets_augmented = list(map(lambda df: df[['spectrogram','class_ID', 'class_name','augmentation']],datasets_augmented))\n",
    "datasets_augmented = list(map(lambda df: df.reset_index(drop=True), datasets_augmented))\n",
    "\n",
    "import random\n",
    "import keras\n",
    "import os, glob\n",
    "import logging\n",
    "import librosa, librosa.display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import model_from_json\n",
    "from keras import backend as K\n",
    "\n",
    "from src.metrics import *\n",
    "from settings import *\n",
    "from src.data import generate\n",
    "from src.processing import *\n",
    "from src.model import CNN_nodropout\n",
    "from src.data.preprocessing import get_most_shape\n",
    "from setup_logging import setup_logging\n",
    "\n",
    "setup_logging()\n",
    "logger = logging.getLogger('src.train')\n",
    "\n",
    "train_datas = []\n",
    "test_datas = []\n",
    "\n",
    "for dataset in datasets_raw:\n",
    "    train_data, test_data = train_test_split(dataset, augmented=False, split_ratio=0.65)\n",
    "    train_datas.append(train_data)\n",
    "    test_datas.append(test_data)\n",
    "\n",
    "for dataset in datasets_augmented:\n",
    "    train_data, test_data = train_test_split(dataset, augmented=True, split_ratio=0.65)\n",
    "    train_datas.append(train_data)\n",
    "    test_datas.append(test_data)\n",
    "\n",
    "train_data = pd.concat(train_datas)\n",
    "test_data = pd.concat(test_datas)\n",
    "\n",
    "train_data = train_data.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "test_data = test_data.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "most_shape = get_most_shape(train_data)\n",
    "\n",
    "logger.info(f\"Number of train samples: {len(train_data)}\")\n",
    "logger.info(f\"Number of test samples: {len(test_data)}\")\n",
    "# most_shape = get_most_shape(dataset)\n",
    "#train_data, test_data = train_test_split(dataset, augmented=augmented, split_ratio=0.65)\n",
    "\n",
    "X_train, y_train = features_target_split(train_data)\n",
    "X_test, y_test = features_target_split(test_data)\n",
    "\n",
    "# Reshape for CNN input\n",
    "X_train, X_test = reshape_feature_CNN(X_train, size=max_spectrogram_size), reshape_feature_CNN(X_test, size=max_spectrogram_size)\n",
    "\n",
    "# Preserve y_test values\n",
    "y_test_values = y_test.copy()\n",
    "\n",
    "# One-Hot encoding for classes\n",
    "y_train, y_test = one_hot_encode(y_train), one_hot_encode(y_test)\n",
    "\n",
    "# Instance of CNN model\n",
    "cnn = CNN_nodropout(most_shape)\n",
    "logger.info(str(cnn))\n",
    "\n",
    "cnn.train(X_train, y_train, X_test, y_test, epochs=8)\n",
    "cnn.evaluate(X_train, y_train, X_test, y_test)\n",
    "\n",
    "if tf.__version__ != '1.8.0':\n",
    "    predict_x=cnn.model.predict(X_test)\n",
    "    predictions = np.argmax(predict_x,axis=1)\n",
    "else:    \n",
    "    predictions = cnn.model.predict_classes(X_test)\n",
    "conf_matrix=confusion_matrix(y_test_values, predictions, labels=range(10))\n",
    "logger.info('Confusion Matrix for classes {}:\\n{}'.format(CLASSES, conf_matrix))\n",
    "#cnn.save_model(name=\"model_all_data_augment_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 10ms/step - loss: 0.3014 - accuracy: 0.9100 - precision: 0.9193 - recall: 0.9046 - fmeasure: 0.9118\n",
      "Test score for instrument: Guitar\n",
      "\tTest loss: 0.3013662099838257\n",
      "\tTest accuracy: 0.9100000262260437\n",
      "\tTest precision: 0.919274091720581\n",
      "\tTest recall: 0.9046266078948975\n",
      "\tTest f1-score: 0.9117681384086609\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.0130 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - fmeasure: 1.0000\n",
      "Test score for instrument: Accordion\n",
      "\tTest loss: 0.01303529180586338\n",
      "\tTest accuracy: 1.0\n",
      "\tTest precision: 1.0\n",
      "\tTest recall: 1.0\n",
      "\tTest f1-score: 1.0\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0257 - accuracy: 0.9839 - precision: 0.9844 - recall: 0.9844 - fmeasure: 0.9844\n",
      "Test score for instrument: Violin\n",
      "\tTest loss: 0.025706904008984566\n",
      "\tTest accuracy: 0.9838709831237793\n",
      "\tTest precision: 0.984375\n",
      "\tTest recall: 0.984375\n",
      "\tTest f1-score: 0.984375\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0482 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - fmeasure: 1.0000\n",
      "Test score for instrument: Piano\n",
      "\tTest loss: 0.04817156493663788\n",
      "\tTest accuracy: 1.0\n",
      "\tTest precision: 1.0\n",
      "\tTest recall: 1.0\n",
      "\tTest f1-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_instruments = instruments + instruments_aug\n",
    "for test_data, instrument in zip(test_datas, test_instruments):\n",
    "    X_test = test_data['spectrogram']\n",
    "    X_test = np.array([x.reshape( (128, max_spectrogram_size, 1) ) for x in X_test])\n",
    "    y_test = test_data['class_ID']\n",
    "\n",
    "    y_test_values=y_test\n",
    "    y_test = np.array(keras.utils.to_categorical(y_test, 10))\n",
    "\n",
    "    score = cnn.model.evaluate(X_test,y_test)\n",
    "    print(f'Test score for instrument: {instrument}')\n",
    "    print('\\tTest loss:', score[0])\n",
    "    print('\\tTest accuracy:', score[1])\n",
    "    print('\\tTest precision:', score[2])\n",
    "    print('\\tTest recall:', score[3])\n",
    "    print('\\tTest f1-score:', score[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "danigil-steganalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
