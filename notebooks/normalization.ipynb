{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 11:01:46.953420: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-19 11:01:47.078399: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-19 11:01:47.733663: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvrtc.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-19 11:01:47.733743: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-19 11:01:47.733750: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import pandas as pd\n",
    "from src.metrics import *\n",
    "from settings import *\n",
    "from src.data import generate\n",
    "\n",
    "instruments = ['Guitar']\n",
    "instruments_aug = ['Accordion', 'Violin', 'Piano']\n",
    "\n",
    "datasets_raw = [pd.read_pickle(os.path.join(METADATA_DIR_PROCESSED, f'data_{instrument.lower()}.pkl')) for instrument in instruments]\n",
    "datasets_augmented = [pd.read_pickle(os.path.join(METADATA_DIR_AUGMENTED_RAW, f'data_{instrument.lower()}.pkl')) for instrument in instruments_aug]\n",
    "\n",
    "from src.data.preprocessing import get_max_shape\n",
    "max_spectrogram_size = max(map(lambda df: get_max_shape(df), datasets_raw+datasets_augmented))\n",
    "max_spectrogram_size\n",
    "\n",
    "from src.data.preprocessing import uniform_shape\n",
    "uniform = lambda df: uniform_shape(df, max_spectrogram_size)\n",
    "\n",
    "datasets_raw = list(map(uniform,datasets_raw))\n",
    "datasets_augmented = list(map(uniform,datasets_augmented))\n",
    "datasets_augmented = list(map(lambda df: df[['spectrogram','class_ID', 'class_name','augmentation']],datasets_augmented))\n",
    "datasets_augmented = list(map(lambda df: df.reset_index(drop=True), datasets_augmented))\n",
    "\n",
    "import numpy as np\n",
    "#spectrograms_raw = [[x for x in dataset['spectrogram']] for dataset in datasets_raw]\n",
    "#spectrograms_augmented = [[x for x in dataset['spectrogram']] for dataset in datasets_augmented]\n",
    "#all_spectrograms = np.concatenate(spectrograms_raw + spectrograms_augmented)\n",
    "\n",
    "#all_spectrograms_flattened = all_spectrograms.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatsRecorder:\n",
    "    def __init__(self, data=None):\n",
    "        \"\"\"\n",
    "        data: ndarray, shape (nobservations, ndimensions)\n",
    "        \"\"\"\n",
    "        if data is not None:\n",
    "            data = np.atleast_2d(data)\n",
    "            self.mean = data.mean(axis=0)\n",
    "            self.std  = data.std(axis=0)\n",
    "            self.nobservations = data.shape[0]\n",
    "            self.ndimensions   = data.shape[1]\n",
    "        else:\n",
    "            self.nobservations = 0\n",
    "\n",
    "    def update(self, data):\n",
    "        \"\"\"\n",
    "        data: ndarray, shape (nobservations, ndimensions)\n",
    "        \"\"\"\n",
    "        if self.nobservations == 0:\n",
    "            self.__init__(data)\n",
    "        else:\n",
    "            data = np.atleast_2d(data)\n",
    "            if data.shape[1] != self.ndimensions:\n",
    "                raise ValueError(\"Data dims don't match prev observations.\")\n",
    "\n",
    "            newmean = data.mean(axis=0)\n",
    "            newstd  = data.std(axis=0)\n",
    "\n",
    "            m = self.nobservations * 1.0\n",
    "            n = data.shape[0]\n",
    "\n",
    "            tmp = self.mean\n",
    "\n",
    "            self.mean = m/(m+n)*tmp + n/(m+n)*newmean\n",
    "            self.std  = m/(m+n)*self.std**2 + n/(m+n)*newstd**2 +\\\n",
    "                        m*n/(m+n)**2 * (tmp - newmean)**2\n",
    "            self.std  = np.sqrt(self.std)\n",
    "\n",
    "            self.nobservations += n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normalized['spectrogram'].reset_index(drop=True).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 1300\n",
      "src.processing - INFO - Number of testing samples is 700\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 585\n",
      "src.processing - INFO - Number of testing samples is 315\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 585\n",
      "src.processing - INFO - Number of testing samples is 315\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 585\n",
      "src.processing - INFO - Number of testing samples is 315\n",
      "src.processing - INFO - Train test split completed\n",
      "The most frequent shape is (128, 107)\n",
      "src.processing - INFO - Start feature target split\n",
      "src.processing - INFO - Feature target split completed\n",
      "src.processing - INFO - Start feature target split\n",
      "src.processing - INFO - Feature target split completed\n",
      "src.processing - INFO - Features reshaped for CNN Input\n",
      "src.processing - INFO - Features reshaped for CNN Input\n",
      "src.processing - INFO - Target one hot encoded\n",
      "src.processing - INFO - Target one hot encoded\n",
      "src.model - INFO - Initializing CNN\n",
      "src.model - INFO - Input shape = (128, 107, 1)\n",
      "src.model - INFO - CNN Initialized\n",
      "src.model - INFO - Start training model\n",
      "src.model - INFO - Tensorboard Logging Started\n",
      "src.model - INFO - Use the following command in the terminal to view the logs during training: tensorboard --logdir logs/training\n",
      "Epoch 1/67\n",
      "152/153 [============================>.] - ETA: 0s - loss: 2.2598 - accuracy: 0.1487 - precision: 0.1668 - recall: 0.0164 - fmeasure: 0.0290src.model - INFO - {Epoch: 0} loss: 2.258377, accuracy: 0.149264, precision: 0.172222, recall: 0.017211, fmeasure: 0.030372, val_loss: 2.109955, val_accuracy: 0.204863, val_precision: 0.244578, val_recall: 0.045181, val_fmeasure: 0.072775\n",
      "153/153 [==============================] - 4s 16ms/step - loss: 2.2584 - accuracy: 0.1493 - precision: 0.1722 - recall: 0.0172 - fmeasure: 0.0304 - val_loss: 2.1100 - val_accuracy: 0.2049 - val_precision: 0.2446 - val_recall: 0.0452 - val_fmeasure: 0.0728\n",
      "Epoch 2/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 2.0704 - accuracy: 0.2255 - precision: 0.5985 - recall: 0.0752 - fmeasure: 0.1298src.model - INFO - {Epoch: 1} loss: 2.070954, accuracy: 0.224877, precision: 0.597168, recall: 0.074510, fmeasure: 0.128713, val_loss: 1.945860, val_accuracy: 0.303951, val_precision: 0.311386, val_recall: 0.109036, val_fmeasure: 0.147554\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 2.0710 - accuracy: 0.2249 - precision: 0.5972 - recall: 0.0745 - fmeasure: 0.1287 - val_loss: 1.9459 - val_accuracy: 0.3040 - val_precision: 0.3114 - val_recall: 0.1090 - val_fmeasure: 0.1476\n",
      "Epoch 3/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 1.9749 - accuracy: 0.2785 - precision: 0.7302 - recall: 0.1215 - fmeasure: 0.2035src.model - INFO - {Epoch: 2} loss: 1.973739, accuracy: 0.279214, precision: 0.733743, recall: 0.122004, fmeasure: 0.204230, val_loss: 1.881421, val_accuracy: 0.308815, val_precision: 0.333687, val_recall: 0.150000, val_fmeasure: 0.194523\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 1.9737 - accuracy: 0.2792 - precision: 0.7337 - recall: 0.1220 - fmeasure: 0.2042 - val_loss: 1.8814 - val_accuracy: 0.3088 - val_precision: 0.3337 - val_recall: 0.1500 - val_fmeasure: 0.1945\n",
      "Epoch 4/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 1.8451 - accuracy: 0.3331 - precision: 0.8097 - recall: 0.1709 - fmeasure: 0.2750src.model - INFO - {Epoch: 3} loss: 1.843408, accuracy: 0.334534, precision: 0.807615, recall: 0.171024, fmeasure: 0.275091, val_loss: 1.702346, val_accuracy: 0.393921, val_precision: 0.447165, val_recall: 0.222892, val_fmeasure: 0.273187\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 1.8434 - accuracy: 0.3345 - precision: 0.8076 - recall: 0.1710 - fmeasure: 0.2751 - val_loss: 1.7023 - val_accuracy: 0.3939 - val_precision: 0.4472 - val_recall: 0.2229 - val_fmeasure: 0.2732\n",
      "Epoch 5/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 1.7729 - accuracy: 0.3689 - precision: 0.8407 - recall: 0.2036 - fmeasure: 0.3191src.model - INFO - {Epoch: 4} loss: 1.773158, accuracy: 0.368903, precision: 0.840653, recall: 0.203159, fmeasure: 0.318565, val_loss: 1.651334, val_accuracy: 0.409726, val_precision: 0.451073, val_recall: 0.224096, val_fmeasure: 0.279955\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 1.7732 - accuracy: 0.3689 - precision: 0.8407 - recall: 0.2032 - fmeasure: 0.3186 - val_loss: 1.6513 - val_accuracy: 0.4097 - val_precision: 0.4511 - val_recall: 0.2241 - val_fmeasure: 0.2800\n",
      "Epoch 6/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 1.6748 - accuracy: 0.4083 - precision: 0.8455 - recall: 0.2344 - fmeasure: 0.3585src.model - INFO - {Epoch: 5} loss: 1.674771, accuracy: 0.408183, precision: 0.847530, recall: 0.234096, fmeasure: 0.358222, val_loss: 1.598385, val_accuracy: 0.463830, val_precision: 0.483291, val_recall: 0.257831, val_fmeasure: 0.310866\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 1.6748 - accuracy: 0.4082 - precision: 0.8475 - recall: 0.2341 - fmeasure: 0.3582 - val_loss: 1.5984 - val_accuracy: 0.4638 - val_precision: 0.4833 - val_recall: 0.2578 - val_fmeasure: 0.3109\n",
      "Epoch 7/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 1.6304 - accuracy: 0.4301 - precision: 0.8402 - recall: 0.2576 - fmeasure: 0.3877src.model - INFO - {Epoch: 6} loss: 1.629867, accuracy: 0.429460, precision: 0.842337, recall: 0.258279, fmeasure: 0.388741, val_loss: 1.401108, val_accuracy: 0.511854, val_precision: 0.642450, val_recall: 0.333133, val_fmeasure: 0.389425\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 1.6299 - accuracy: 0.4295 - precision: 0.8423 - recall: 0.2583 - fmeasure: 0.3887 - val_loss: 1.4011 - val_accuracy: 0.5119 - val_precision: 0.6424 - val_recall: 0.3331 - val_fmeasure: 0.3894\n",
      "Epoch 8/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 1.4636 - accuracy: 0.4815 - precision: 0.8750 - recall: 0.3225 - fmeasure: 0.4638src.model - INFO - {Epoch: 7} loss: 1.469356, accuracy: 0.481506, precision: 0.874768, recall: 0.322767, fmeasure: 0.464085, val_loss: 1.345243, val_accuracy: 0.530091, val_precision: 0.676979, val_recall: 0.348193, val_fmeasure: 0.410675\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 1.4694 - accuracy: 0.4815 - precision: 0.8748 - recall: 0.3228 - fmeasure: 0.4641 - val_loss: 1.3452 - val_accuracy: 0.5301 - val_precision: 0.6770 - val_recall: 0.3482 - val_fmeasure: 0.4107\n",
      "Epoch 9/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 1.3791 - accuracy: 0.5089 - precision: 0.8804 - recall: 0.3566 - fmeasure: 0.5002src.model - INFO - {Epoch: 8} loss: 1.377829, accuracy: 0.509329, precision: 0.880075, recall: 0.357081, fmeasure: 0.500659, val_loss: 1.256307, val_accuracy: 0.572036, val_precision: 0.761948, val_recall: 0.409036, val_fmeasure: 0.475151\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 1.3778 - accuracy: 0.5093 - precision: 0.8801 - recall: 0.3571 - fmeasure: 0.5007 - val_loss: 1.2563 - val_accuracy: 0.5720 - val_precision: 0.7619 - val_recall: 0.4090 - val_fmeasure: 0.4752\n",
      "Epoch 10/67\n",
      "150/153 [============================>.] - ETA: 0s - loss: 1.4183 - accuracy: 0.5197 - precision: 0.8688 - recall: 0.3540 - fmeasure: 0.4950src.model - INFO - {Epoch: 9} loss: 1.415536, accuracy: 0.520131, precision: 0.869956, recall: 0.355120, fmeasure: 0.496287, val_loss: 1.217628, val_accuracy: 0.596353, val_precision: 0.772310, val_recall: 0.411446, val_fmeasure: 0.478359\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 1.4155 - accuracy: 0.5201 - precision: 0.8700 - recall: 0.3551 - fmeasure: 0.4963 - val_loss: 1.2176 - val_accuracy: 0.5964 - val_precision: 0.7723 - val_recall: 0.4114 - val_fmeasure: 0.4784\n",
      "Epoch 11/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 1.2574 - accuracy: 0.5589 - precision: 0.8763 - recall: 0.4139 - fmeasure: 0.5554src.model - INFO - {Epoch: 10} loss: 1.257192, accuracy: 0.558429, precision: 0.876481, recall: 0.414706, fmeasure: 0.556146, val_loss: 1.146390, val_accuracy: 0.603647, val_precision: 0.867676, val_recall: 0.459036, val_fmeasure: 0.540646\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 1.2572 - accuracy: 0.5584 - precision: 0.8765 - recall: 0.4147 - fmeasure: 0.5561 - val_loss: 1.1464 - val_accuracy: 0.6036 - val_precision: 0.8677 - val_recall: 0.4590 - val_fmeasure: 0.5406\n",
      "Epoch 12/67\n",
      "152/153 [============================>.] - ETA: 0s - loss: 1.2022 - accuracy: 0.5872 - precision: 0.8838 - recall: 0.4470 - fmeasure: 0.5861src.model - INFO - {Epoch: 11} loss: 1.204043, accuracy: 0.585925, precision: 0.883512, recall: 0.446296, fmeasure: 0.585347, val_loss: 1.144476, val_accuracy: 0.598784, val_precision: 0.814996, val_recall: 0.459036, val_fmeasure: 0.536608\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 1.2040 - accuracy: 0.5859 - precision: 0.8835 - recall: 0.4463 - fmeasure: 0.5853 - val_loss: 1.1445 - val_accuracy: 0.5988 - val_precision: 0.8150 - val_recall: 0.4590 - val_fmeasure: 0.5366\n",
      "Epoch 13/67\n",
      "150/153 [============================>.] - ETA: 0s - loss: 1.1453 - accuracy: 0.5970 - precision: 0.8873 - recall: 0.4703 - fmeasure: 0.6086src.model - INFO - {Epoch: 12} loss: 1.148687, accuracy: 0.596727, precision: 0.886845, recall: 0.470043, fmeasure: 0.608376, val_loss: 1.109445, val_accuracy: 0.648024, val_precision: 0.861903, val_recall: 0.510241, val_fmeasure: 0.594798\n",
      "153/153 [==============================] - 2s 15ms/step - loss: 1.1487 - accuracy: 0.5967 - precision: 0.8868 - recall: 0.4700 - fmeasure: 0.6084 - val_loss: 1.1094 - val_accuracy: 0.6480 - val_precision: 0.8619 - val_recall: 0.5102 - val_fmeasure: 0.5948\n",
      "Epoch 14/67\n",
      "150/153 [============================>.] - ETA: 0s - loss: 1.1508 - accuracy: 0.6013 - precision: 0.8890 - recall: 0.4757 - fmeasure: 0.6130src.model - INFO - {Epoch: 13} loss: 1.147506, accuracy: 0.602946, precision: 0.890315, recall: 0.477887, fmeasure: 0.615159, val_loss: 1.113372, val_accuracy: 0.624316, val_precision: 0.814845, val_recall: 0.493976, val_fmeasure: 0.574540\n",
      "153/153 [==============================] - 2s 15ms/step - loss: 1.1475 - accuracy: 0.6029 - precision: 0.8903 - recall: 0.4779 - fmeasure: 0.6152 - val_loss: 1.1134 - val_accuracy: 0.6243 - val_precision: 0.8148 - val_recall: 0.4940 - val_fmeasure: 0.5745\n",
      "Epoch 15/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 1.0931 - accuracy: 0.6192 - precision: 0.8972 - recall: 0.4967 - fmeasure: 0.6340src.model - INFO - {Epoch: 14} loss: 1.091214, accuracy: 0.619967, precision: 0.897636, recall: 0.496732, fmeasure: 0.634175, val_loss: 0.974307, val_accuracy: 0.669301, val_precision: 0.886415, val_recall: 0.536145, val_fmeasure: 0.628025\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 1.0912 - accuracy: 0.6200 - precision: 0.8976 - recall: 0.4967 - fmeasure: 0.6342 - val_loss: 0.9743 - val_accuracy: 0.6693 - val_precision: 0.8864 - val_recall: 0.5361 - val_fmeasure: 0.6280\n",
      "Epoch 16/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 1.0408 - accuracy: 0.6493 - precision: 0.9168 - recall: 0.5387 - fmeasure: 0.6733src.model - INFO - {Epoch: 15} loss: 1.041374, accuracy: 0.648772, precision: 0.917127, recall: 0.537799, fmeasure: 0.672637, val_loss: 0.970553, val_accuracy: 0.666261, val_precision: 0.868716, val_recall: 0.560843, val_fmeasure: 0.650824\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 1.0414 - accuracy: 0.6488 - precision: 0.9171 - recall: 0.5378 - fmeasure: 0.6726 - val_loss: 0.9706 - val_accuracy: 0.6663 - val_precision: 0.8687 - val_recall: 0.5608 - val_fmeasure: 0.6508\n",
      "Epoch 17/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 1.0730 - accuracy: 0.6394 - precision: 0.8928 - recall: 0.5374 - fmeasure: 0.6655src.model - INFO - {Epoch: 16} loss: 1.072883, accuracy: 0.639280, precision: 0.892817, recall: 0.537037, fmeasure: 0.665247, val_loss: 1.068070, val_accuracy: 0.663830, val_precision: 0.851515, val_recall: 0.519277, val_fmeasure: 0.609471\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 1.0729 - accuracy: 0.6393 - precision: 0.8928 - recall: 0.5370 - fmeasure: 0.6652 - val_loss: 1.0681 - val_accuracy: 0.6638 - val_precision: 0.8515 - val_recall: 0.5193 - val_fmeasure: 0.6095\n",
      "Epoch 18/67\n",
      "150/153 [============================>.] - ETA: 0s - loss: 1.0217 - accuracy: 0.6510 - precision: 0.9094 - recall: 0.5423 - fmeasure: 0.6740src.model - INFO - {Epoch: 17} loss: 1.019920, accuracy: 0.651064, precision: 0.907871, recall: 0.542048, fmeasure: 0.673384, val_loss: 1.046238, val_accuracy: 0.681459, val_precision: 0.881748, val_recall: 0.551205, val_fmeasure: 0.645982\n",
      "153/153 [==============================] - 2s 15ms/step - loss: 1.0199 - accuracy: 0.6511 - precision: 0.9079 - recall: 0.5420 - fmeasure: 0.6734 - val_loss: 1.0462 - val_accuracy: 0.6815 - val_precision: 0.8817 - val_recall: 0.5512 - val_fmeasure: 0.6460\n",
      "Epoch 19/67\n",
      "150/153 [============================>.] - ETA: 0s - loss: 0.9330 - accuracy: 0.6700 - precision: 0.9161 - recall: 0.5630 - fmeasure: 0.6936src.model - INFO - {Epoch: 18} loss: 0.933088, accuracy: 0.670376, precision: 0.917246, recall: 0.563072, fmeasure: 0.693987, val_loss: 0.868742, val_accuracy: 0.717325, val_precision: 0.915375, val_recall: 0.603012, val_fmeasure: 0.698357\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.9331 - accuracy: 0.6704 - precision: 0.9172 - recall: 0.5631 - fmeasure: 0.6940 - val_loss: 0.8687 - val_accuracy: 0.7173 - val_precision: 0.9154 - val_recall: 0.6030 - val_fmeasure: 0.6984\n",
      "Epoch 20/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.9226 - accuracy: 0.6788 - precision: 0.9137 - recall: 0.5775 - fmeasure: 0.7030src.model - INFO - {Epoch: 19} loss: 0.920421, accuracy: 0.679214, precision: 0.914053, recall: 0.577560, fmeasure: 0.703030, val_loss: 0.841416, val_accuracy: 0.730091, val_precision: 0.908462, val_recall: 0.619277, val_fmeasure: 0.713191\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.9204 - accuracy: 0.6792 - precision: 0.9141 - recall: 0.5776 - fmeasure: 0.7030 - val_loss: 0.8414 - val_accuracy: 0.7301 - val_precision: 0.9085 - val_recall: 0.6193 - val_fmeasure: 0.7132\n",
      "Epoch 21/67\n",
      "152/153 [============================>.] - ETA: 0s - loss: 0.8348 - accuracy: 0.7086 - precision: 0.9306 - recall: 0.6102 - fmeasure: 0.7326src.model - INFO - {Epoch: 20} loss: 0.837349, accuracy: 0.707365, precision: 0.931038, recall: 0.608823, fmeasure: 0.731501, val_loss: 0.839348, val_accuracy: 0.739818, val_precision: 0.919475, val_recall: 0.632530, val_fmeasure: 0.723880\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.8373 - accuracy: 0.7074 - precision: 0.9310 - recall: 0.6088 - fmeasure: 0.7315 - val_loss: 0.8393 - val_accuracy: 0.7398 - val_precision: 0.9195 - val_recall: 0.6325 - val_fmeasure: 0.7239\n",
      "Epoch 22/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.8652 - accuracy: 0.7079 - precision: 0.9286 - recall: 0.6129 - fmeasure: 0.7335src.model - INFO - {Epoch: 21} loss: 0.867171, accuracy: 0.706710, precision: 0.927662, recall: 0.611329, fmeasure: 0.732108, val_loss: 0.818398, val_accuracy: 0.739210, val_precision: 0.909504, val_recall: 0.643976, val_fmeasure: 0.731271\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.8672 - accuracy: 0.7067 - precision: 0.9277 - recall: 0.6113 - fmeasure: 0.7321 - val_loss: 0.8184 - val_accuracy: 0.7392 - val_precision: 0.9095 - val_recall: 0.6440 - val_fmeasure: 0.7313\n",
      "Epoch 23/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.8973 - accuracy: 0.6990 - precision: 0.9130 - recall: 0.6030 - fmeasure: 0.7215src.model - INFO - {Epoch: 22} loss: 0.896293, accuracy: 0.699182, precision: 0.913607, recall: 0.603050, fmeasure: 0.721788, val_loss: 0.890589, val_accuracy: 0.708207, val_precision: 0.896773, val_recall: 0.617470, val_fmeasure: 0.707528\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.8963 - accuracy: 0.6992 - precision: 0.9136 - recall: 0.6031 - fmeasure: 0.7218 - val_loss: 0.8906 - val_accuracy: 0.7082 - val_precision: 0.8968 - val_recall: 0.6175 - val_fmeasure: 0.7075\n",
      "Epoch 24/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.7976 - accuracy: 0.7169 - precision: 0.9327 - recall: 0.6281 - fmeasure: 0.7464src.model - INFO - {Epoch: 23} loss: 0.798327, accuracy: 0.717512, precision: 0.933014, recall: 0.628214, fmeasure: 0.746599, val_loss: 0.808268, val_accuracy: 0.747720, val_precision: 0.926359, val_recall: 0.657831, val_fmeasure: 0.745883\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.7983 - accuracy: 0.7175 - precision: 0.9330 - recall: 0.6282 - fmeasure: 0.7466 - val_loss: 0.8083 - val_accuracy: 0.7477 - val_precision: 0.9264 - val_recall: 0.6578 - val_fmeasure: 0.7459\n",
      "Epoch 25/67\n",
      "150/153 [============================>.] - ETA: 0s - loss: 0.8186 - accuracy: 0.7187 - precision: 0.9320 - recall: 0.6383 - fmeasure: 0.7525src.model - INFO - {Epoch: 24} loss: 0.824779, accuracy: 0.719804, precision: 0.932252, recall: 0.639325, fmeasure: 0.753345, val_loss: 0.849192, val_accuracy: 0.741641, val_precision: 0.906264, val_recall: 0.648795, val_fmeasure: 0.733357\n",
      "153/153 [==============================] - 2s 15ms/step - loss: 0.8248 - accuracy: 0.7198 - precision: 0.9323 - recall: 0.6393 - fmeasure: 0.7533 - val_loss: 0.8492 - val_accuracy: 0.7416 - val_precision: 0.9063 - val_recall: 0.6488 - val_fmeasure: 0.7334\n",
      "Epoch 26/67\n",
      "150/153 [============================>.] - ETA: 0s - loss: 0.9382 - accuracy: 0.6940 - precision: 0.9080 - recall: 0.5997 - fmeasure: 0.7182src.model - INFO - {Epoch: 25} loss: 0.941979, accuracy: 0.694272, precision: 0.908909, recall: 0.599891, fmeasure: 0.718597, val_loss: 0.823400, val_accuracy: 0.747720, val_precision: 0.914557, val_recall: 0.661446, val_fmeasure: 0.745298\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.9420 - accuracy: 0.6943 - precision: 0.9089 - recall: 0.5999 - fmeasure: 0.7186 - val_loss: 0.8234 - val_accuracy: 0.7477 - val_precision: 0.9146 - val_recall: 0.6614 - val_fmeasure: 0.7453\n",
      "Epoch 27/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.8398 - accuracy: 0.7113 - precision: 0.9191 - recall: 0.6235 - fmeasure: 0.7386src.model - INFO - {Epoch: 26} loss: 0.841545, accuracy: 0.711948, precision: 0.919617, recall: 0.624401, fmeasure: 0.739462, val_loss: 0.792867, val_accuracy: 0.758663, val_precision: 0.936016, val_recall: 0.656024, val_fmeasure: 0.746630\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.8415 - accuracy: 0.7119 - precision: 0.9196 - recall: 0.6244 - fmeasure: 0.7395 - val_loss: 0.7929 - val_accuracy: 0.7587 - val_precision: 0.9360 - val_recall: 0.6560 - val_fmeasure: 0.7466\n",
      "Epoch 28/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.7181 - accuracy: 0.7447 - precision: 0.9459 - recall: 0.6695 - fmeasure: 0.7797src.model - INFO - {Epoch: 27} loss: 0.720601, accuracy: 0.745336, precision: 0.945406, recall: 0.669281, fmeasure: 0.779456, val_loss: 0.710890, val_accuracy: 0.763526, val_precision: 0.928314, val_recall: 0.683735, val_fmeasure: 0.765433\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.7206 - accuracy: 0.7453 - precision: 0.9454 - recall: 0.6693 - fmeasure: 0.7795 - val_loss: 0.7109 - val_accuracy: 0.7635 - val_precision: 0.9283 - val_recall: 0.6837 - val_fmeasure: 0.7654\n",
      "Epoch 29/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.7118 - accuracy: 0.7520 - precision: 0.9414 - recall: 0.6632 - fmeasure: 0.7738src.model - INFO - {Epoch: 28} loss: 0.712406, accuracy: 0.752209, precision: 0.941544, recall: 0.663181, fmeasure: 0.773832, val_loss: 0.700346, val_accuracy: 0.768389, val_precision: 0.925449, val_recall: 0.689157, val_fmeasure: 0.767907\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.7124 - accuracy: 0.7522 - precision: 0.9415 - recall: 0.6632 - fmeasure: 0.7738 - val_loss: 0.7003 - val_accuracy: 0.7684 - val_precision: 0.9254 - val_recall: 0.6892 - val_fmeasure: 0.7679\n",
      "Epoch 30/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.7386 - accuracy: 0.7411 - precision: 0.9253 - recall: 0.6613 - fmeasure: 0.7671src.model - INFO - {Epoch: 29} loss: 0.740501, accuracy: 0.740426, precision: 0.924498, recall: 0.660131, fmeasure: 0.766138, val_loss: 0.792602, val_accuracy: 0.751976, val_precision: 0.913715, val_recall: 0.668072, val_fmeasure: 0.749015\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.7405 - accuracy: 0.7404 - precision: 0.9245 - recall: 0.6601 - fmeasure: 0.7661 - val_loss: 0.7926 - val_accuracy: 0.7520 - val_precision: 0.9137 - val_recall: 0.6681 - val_fmeasure: 0.7490\n",
      "Epoch 31/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.7275 - accuracy: 0.7361 - precision: 0.9304 - recall: 0.6526 - fmeasure: 0.7632src.model - INFO - {Epoch: 30} loss: 0.728755, accuracy: 0.734861, precision: 0.929182, recall: 0.652179, fmeasure: 0.762481, val_loss: 0.687036, val_accuracy: 0.778723, val_precision: 0.933897, val_recall: 0.693976, val_fmeasure: 0.773736\n",
      "153/153 [==============================] - 2s 15ms/step - loss: 0.7288 - accuracy: 0.7349 - precision: 0.9292 - recall: 0.6522 - fmeasure: 0.7625 - val_loss: 0.6870 - val_accuracy: 0.7787 - val_precision: 0.9339 - val_recall: 0.6940 - val_fmeasure: 0.7737\n",
      "Epoch 32/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.6993 - accuracy: 0.7530 - precision: 0.9424 - recall: 0.6821 - fmeasure: 0.7889src.model - INFO - {Epoch: 31} loss: 0.699386, accuracy: 0.752537, precision: 0.942331, recall: 0.681808, fmeasure: 0.788674, val_loss: 0.699843, val_accuracy: 0.776292, val_precision: 0.919126, val_recall: 0.692169, val_fmeasure: 0.768807\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.6994 - accuracy: 0.7525 - precision: 0.9423 - recall: 0.6818 - fmeasure: 0.7887 - val_loss: 0.6998 - val_accuracy: 0.7763 - val_precision: 0.9191 - val_recall: 0.6922 - val_fmeasure: 0.7688\n",
      "Epoch 33/67\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.7742 - accuracy: 0.7545 - precision: 0.9341 - recall: 0.6775 - fmeasure: 0.7814src.model - INFO - {Epoch: 32} loss: 0.774166, accuracy: 0.754501, precision: 0.934116, recall: 0.677451, fmeasure: 0.781423, val_loss: 0.698238, val_accuracy: 0.772644, val_precision: 0.913460, val_recall: 0.686145, val_fmeasure: 0.762518\n",
      "153/153 [==============================] - 2s 15ms/step - loss: 0.7742 - accuracy: 0.7545 - precision: 0.9341 - recall: 0.6775 - fmeasure: 0.7814 - val_loss: 0.6982 - val_accuracy: 0.7726 - val_precision: 0.9135 - val_recall: 0.6861 - val_fmeasure: 0.7625\n",
      "Epoch 34/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.8184 - accuracy: 0.7533 - precision: 0.9246 - recall: 0.6656 - fmeasure: 0.7705src.model - INFO - {Epoch: 33} loss: 0.815697, accuracy: 0.753519, precision: 0.925188, recall: 0.666667, fmeasure: 0.771489, val_loss: 0.667562, val_accuracy: 0.782979, val_precision: 0.931487, val_recall: 0.710843, val_fmeasure: 0.786241\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.8157 - accuracy: 0.7535 - precision: 0.9252 - recall: 0.6667 - fmeasure: 0.7715 - val_loss: 0.6676 - val_accuracy: 0.7830 - val_precision: 0.9315 - val_recall: 0.7108 - val_fmeasure: 0.7862\n",
      "Epoch 35/67\n",
      "152/153 [============================>.] - ETA: 0s - loss: 0.6546 - accuracy: 0.7724 - precision: 0.9374 - recall: 0.6901 - fmeasure: 0.7911src.model - INFO - {Epoch: 34} loss: 0.654969, accuracy: 0.772504, precision: 0.937853, recall: 0.689543, fmeasure: 0.790827, val_loss: 1.078261, val_accuracy: 0.787234, val_precision: 0.919345, val_recall: 0.698193, val_fmeasure: 0.772308\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.6550 - accuracy: 0.7725 - precision: 0.9379 - recall: 0.6895 - fmeasure: 0.7908 - val_loss: 1.0783 - val_accuracy: 0.7872 - val_precision: 0.9193 - val_recall: 0.6982 - val_fmeasure: 0.7723\n",
      "Epoch 36/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.6656 - accuracy: 0.7685 - precision: 0.9441 - recall: 0.6921 - fmeasure: 0.7957src.model - INFO - {Epoch: 35} loss: 0.669711, accuracy: 0.769885, precision: 0.944001, recall: 0.693682, fmeasure: 0.796650, val_loss: 0.674421, val_accuracy: 0.787842, val_precision: 0.921978, val_recall: 0.707229, val_fmeasure: 0.779613\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.6697 - accuracy: 0.7699 - precision: 0.9440 - recall: 0.6937 - fmeasure: 0.7966 - val_loss: 0.6744 - val_accuracy: 0.7878 - val_precision: 0.9220 - val_recall: 0.7072 - val_fmeasure: 0.7796\n",
      "Epoch 37/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.6056 - accuracy: 0.7778 - precision: 0.9469 - recall: 0.7053 - fmeasure: 0.8048src.model - INFO - {Epoch: 36} loss: 0.609009, accuracy: 0.776759, precision: 0.946098, recall: 0.703377, fmeasure: 0.803197, val_loss: 0.753851, val_accuracy: 0.789058, val_precision: 0.920811, val_recall: 0.715663, val_fmeasure: 0.786424\n",
      "153/153 [==============================] - 2s 15ms/step - loss: 0.6090 - accuracy: 0.7768 - precision: 0.9461 - recall: 0.7034 - fmeasure: 0.8032 - val_loss: 0.7539 - val_accuracy: 0.7891 - val_precision: 0.9208 - val_recall: 0.7157 - val_fmeasure: 0.7864\n",
      "Epoch 38/67\n",
      "150/153 [============================>.] - ETA: 0s - loss: 0.5902 - accuracy: 0.7943 - precision: 0.9490 - recall: 0.7133 - fmeasure: 0.8119src.model - INFO - {Epoch: 37} loss: 0.590393, accuracy: 0.794108, precision: 0.949550, recall: 0.713834, fmeasure: 0.812394, val_loss: 0.696650, val_accuracy: 0.799392, val_precision: 0.933898, val_recall: 0.706626, val_fmeasure: 0.785112\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.5904 - accuracy: 0.7941 - precision: 0.9496 - recall: 0.7138 - fmeasure: 0.8124 - val_loss: 0.6966 - val_accuracy: 0.7994 - val_precision: 0.9339 - val_recall: 0.7066 - val_fmeasure: 0.7851\n",
      "Epoch 39/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.6117 - accuracy: 0.7884 - precision: 0.9459 - recall: 0.7126 - fmeasure: 0.8099src.model - INFO - {Epoch: 38} loss: 0.613814, accuracy: 0.788216, precision: 0.946156, recall: 0.712309, fmeasure: 0.809817, val_loss: 0.681654, val_accuracy: 0.800608, val_precision: 0.917952, val_recall: 0.721084, val_fmeasure: 0.790112\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.6138 - accuracy: 0.7882 - precision: 0.9462 - recall: 0.7123 - fmeasure: 0.8098 - val_loss: 0.6817 - val_accuracy: 0.8006 - val_precision: 0.9180 - val_recall: 0.7211 - val_fmeasure: 0.7901\n",
      "Epoch 40/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.6088 - accuracy: 0.7848 - precision: 0.9312 - recall: 0.7050 - fmeasure: 0.7986src.model - INFO - {Epoch: 39} loss: 0.610764, accuracy: 0.783633, precision: 0.930530, recall: 0.704030, fmeasure: 0.797822, val_loss: 0.662867, val_accuracy: 0.801216, val_precision: 0.928305, val_recall: 0.718072, val_fmeasure: 0.790184\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.6108 - accuracy: 0.7836 - precision: 0.9305 - recall: 0.7040 - fmeasure: 0.7978 - val_loss: 0.6629 - val_accuracy: 0.8012 - val_precision: 0.9283 - val_recall: 0.7181 - val_fmeasure: 0.7902\n",
      "Epoch 41/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.5879 - accuracy: 0.7934 - precision: 0.9445 - recall: 0.7162 - fmeasure: 0.8116src.model - INFO - {Epoch: 40} loss: 0.585374, accuracy: 0.794108, precision: 0.944649, recall: 0.717211, fmeasure: 0.812284, val_loss: 0.656140, val_accuracy: 0.803039, val_precision: 0.927331, val_recall: 0.726506, val_fmeasure: 0.796009\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.5854 - accuracy: 0.7941 - precision: 0.9446 - recall: 0.7172 - fmeasure: 0.8123 - val_loss: 0.6561 - val_accuracy: 0.8030 - val_precision: 0.9273 - val_recall: 0.7265 - val_fmeasure: 0.7960\n",
      "Epoch 42/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.5768 - accuracy: 0.8010 - precision: 0.9409 - recall: 0.7162 - fmeasure: 0.8107src.model - INFO - {Epoch: 41} loss: 0.575846, accuracy: 0.800982, precision: 0.940425, recall: 0.717102, fmeasure: 0.811043, val_loss: 0.633089, val_accuracy: 0.792705, val_precision: 0.929114, val_recall: 0.727711, val_fmeasure: 0.797454\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.5758 - accuracy: 0.8010 - precision: 0.9404 - recall: 0.7171 - fmeasure: 0.8110 - val_loss: 0.6331 - val_accuracy: 0.7927 - val_precision: 0.9291 - val_recall: 0.7277 - val_fmeasure: 0.7975\n",
      "Epoch 43/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.5596 - accuracy: 0.7983 - precision: 0.9456 - recall: 0.7262 - fmeasure: 0.8187src.model - INFO - {Epoch: 42} loss: 0.560987, accuracy: 0.797054, precision: 0.945444, recall: 0.725272, fmeasure: 0.818045, val_loss: 0.637740, val_accuracy: 0.808511, val_precision: 0.919722, val_recall: 0.729518, val_fmeasure: 0.796277\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.5610 - accuracy: 0.7971 - precision: 0.9454 - recall: 0.7253 - fmeasure: 0.8180 - val_loss: 0.6377 - val_accuracy: 0.8085 - val_precision: 0.9197 - val_recall: 0.7295 - val_fmeasure: 0.7963\n",
      "Epoch 44/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.5658 - accuracy: 0.8023 - precision: 0.9481 - recall: 0.7265 - fmeasure: 0.8195src.model - INFO - {Epoch: 43} loss: 0.568866, accuracy: 0.801637, precision: 0.947830, recall: 0.726362, fmeasure: 0.819312, val_loss: 0.696865, val_accuracy: 0.798784, val_precision: 0.929102, val_recall: 0.705422, val_fmeasure: 0.781916\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.5689 - accuracy: 0.8016 - precision: 0.9478 - recall: 0.7264 - fmeasure: 0.8193 - val_loss: 0.6969 - val_accuracy: 0.7988 - val_precision: 0.9291 - val_recall: 0.7054 - val_fmeasure: 0.7819\n",
      "Epoch 45/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.5946 - accuracy: 0.7874 - precision: 0.9303 - recall: 0.7156 - fmeasure: 0.8060src.model - INFO - {Epoch: 44} loss: 0.599327, accuracy: 0.787889, precision: 0.929628, recall: 0.714706, fmeasure: 0.805204, val_loss: 0.642589, val_accuracy: 0.803647, val_precision: 0.931784, val_recall: 0.727109, val_fmeasure: 0.796945\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.5993 - accuracy: 0.7879 - precision: 0.9296 - recall: 0.7147 - fmeasure: 0.8052 - val_loss: 0.6426 - val_accuracy: 0.8036 - val_precision: 0.9318 - val_recall: 0.7271 - val_fmeasure: 0.7969\n",
      "Epoch 46/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.5455 - accuracy: 0.7944 - precision: 0.9471 - recall: 0.7245 - fmeasure: 0.8177src.model - INFO - {Epoch: 45} loss: 0.544780, accuracy: 0.794435, precision: 0.947755, recall: 0.725055, fmeasure: 0.818330, val_loss: 0.630321, val_accuracy: 0.813982, val_precision: 0.927541, val_recall: 0.740362, val_fmeasure: 0.806291\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.5448 - accuracy: 0.7944 - precision: 0.9478 - recall: 0.7251 - fmeasure: 0.8183 - val_loss: 0.6303 - val_accuracy: 0.8140 - val_precision: 0.9275 - val_recall: 0.7404 - val_fmeasure: 0.8063\n",
      "Epoch 47/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.7445 - accuracy: 0.7881 - precision: 0.9206 - recall: 0.7089 - fmeasure: 0.7983src.model - INFO - {Epoch: 46} loss: 0.745181, accuracy: 0.787889, precision: 0.920574, recall: 0.708388, fmeasure: 0.797946, val_loss: 0.843999, val_accuracy: 0.797568, val_precision: 0.903295, val_recall: 0.706627, val_fmeasure: 0.775541\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.7452 - accuracy: 0.7879 - precision: 0.9206 - recall: 0.7084 - fmeasure: 0.7979 - val_loss: 0.8440 - val_accuracy: 0.7976 - val_precision: 0.9033 - val_recall: 0.7066 - val_fmeasure: 0.7755\n",
      "Epoch 48/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.6718 - accuracy: 0.7762 - precision: 0.9182 - recall: 0.7030 - fmeasure: 0.7936src.model - INFO - {Epoch: 47} loss: 0.668976, accuracy: 0.776432, precision: 0.918517, recall: 0.703812, fmeasure: 0.794258, val_loss: 0.588902, val_accuracy: 0.812766, val_precision: 0.929721, val_recall: 0.733133, val_fmeasure: 0.801700\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.6690 - accuracy: 0.7764 - precision: 0.9185 - recall: 0.7038 - fmeasure: 0.7943 - val_loss: 0.5889 - val_accuracy: 0.8128 - val_precision: 0.9297 - val_recall: 0.7331 - val_fmeasure: 0.8017\n",
      "Epoch 49/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.6151 - accuracy: 0.8013 - precision: 0.9402 - recall: 0.7225 - fmeasure: 0.8140src.model - INFO - {Epoch: 48} loss: 0.616831, accuracy: 0.800982, precision: 0.940972, recall: 0.721242, fmeasure: 0.813424, val_loss: 0.739316, val_accuracy: 0.822492, val_precision: 0.928843, val_recall: 0.726506, val_fmeasure: 0.795808\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.6168 - accuracy: 0.8010 - precision: 0.9410 - recall: 0.7212 - fmeasure: 0.8134 - val_loss: 0.7393 - val_accuracy: 0.8225 - val_precision: 0.9288 - val_recall: 0.7265 - val_fmeasure: 0.7958\n",
      "Epoch 50/67\n",
      "149/153 [============================>.] - ETA: 0s - loss: 0.5976 - accuracy: 0.8003 - precision: 0.9259 - recall: 0.7225 - fmeasure: 0.8084src.model - INFO - {Epoch: 49} loss: 0.594909, accuracy: 0.800655, precision: 0.925326, recall: 0.722876, fmeasure: 0.808430, val_loss: 0.686549, val_accuracy: 0.819453, val_precision: 0.927223, val_recall: 0.741566, val_fmeasure: 0.806896\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.5949 - accuracy: 0.8007 - precision: 0.9253 - recall: 0.7229 - fmeasure: 0.8084 - val_loss: 0.6865 - val_accuracy: 0.8195 - val_precision: 0.9272 - val_recall: 0.7416 - val_fmeasure: 0.8069\n",
      "Epoch 51/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.5396 - accuracy: 0.8060 - precision: 0.9409 - recall: 0.7278 - fmeasure: 0.8176src.model - INFO - {Epoch: 50} loss: 0.536916, accuracy: 0.807201, precision: 0.941263, recall: 0.728214, fmeasure: 0.818034, val_loss: 0.540524, val_accuracy: 0.835258, val_precision: 0.938878, val_recall: 0.750000, val_fmeasure: 0.816317\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.5369 - accuracy: 0.8072 - precision: 0.9413 - recall: 0.7282 - fmeasure: 0.8180 - val_loss: 0.5405 - val_accuracy: 0.8353 - val_precision: 0.9389 - val_recall: 0.7500 - val_fmeasure: 0.8163\n",
      "Epoch 52/67\n",
      "150/153 [============================>.] - ETA: 0s - loss: 0.4899 - accuracy: 0.8270 - precision: 0.9556 - recall: 0.7560 - fmeasure: 0.8412src.model - INFO - {Epoch: 51} loss: 0.488613, accuracy: 0.827169, precision: 0.955576, recall: 0.756536, fmeasure: 0.841575, val_loss: 0.612075, val_accuracy: 0.843769, val_precision: 0.938995, val_recall: 0.754819, val_fmeasure: 0.819402\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.4886 - accuracy: 0.8272 - precision: 0.9556 - recall: 0.7565 - fmeasure: 0.8416 - val_loss: 0.6121 - val_accuracy: 0.8438 - val_precision: 0.9390 - val_recall: 0.7548 - val_fmeasure: 0.8194\n",
      "Epoch 53/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.4650 - accuracy: 0.8268 - precision: 0.9539 - recall: 0.7586 - fmeasure: 0.8424src.model - INFO - {Epoch: 52} loss: 0.463491, accuracy: 0.827496, precision: 0.954494, recall: 0.759586, fmeasure: 0.843308, val_loss: 0.542490, val_accuracy: 0.841945, val_precision: 0.938737, val_recall: 0.748795, val_fmeasure: 0.815498\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.4635 - accuracy: 0.8275 - precision: 0.9545 - recall: 0.7596 - fmeasure: 0.8433 - val_loss: 0.5425 - val_accuracy: 0.8419 - val_precision: 0.9387 - val_recall: 0.7488 - val_fmeasure: 0.8155\n",
      "Epoch 54/67\n",
      "150/153 [============================>.] - ETA: 0s - loss: 0.5599 - accuracy: 0.8220 - precision: 0.9377 - recall: 0.7510 - fmeasure: 0.8315src.model - INFO - {Epoch: 53} loss: 0.586940, accuracy: 0.819313, precision: 0.935650, recall: 0.748148, fmeasure: 0.828940, val_loss: 0.780737, val_accuracy: 0.789666, val_precision: 0.899759, val_recall: 0.715663, val_fmeasure: 0.779941\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.5869 - accuracy: 0.8193 - precision: 0.9357 - recall: 0.7481 - fmeasure: 0.8289 - val_loss: 0.7807 - val_accuracy: 0.7897 - val_precision: 0.8998 - val_recall: 0.7157 - val_fmeasure: 0.7799\n",
      "Epoch 55/67\n",
      "150/153 [============================>.] - ETA: 0s - loss: 0.5904 - accuracy: 0.8013 - precision: 0.9344 - recall: 0.7290 - fmeasure: 0.8163src.model - INFO - {Epoch: 54} loss: 0.588839, accuracy: 0.802291, precision: 0.934191, recall: 0.730719, fmeasure: 0.817212, val_loss: 0.566406, val_accuracy: 0.818237, val_precision: 0.938707, val_recall: 0.742771, val_fmeasure: 0.810927\n",
      "153/153 [==============================] - 2s 15ms/step - loss: 0.5888 - accuracy: 0.8023 - precision: 0.9342 - recall: 0.7307 - fmeasure: 0.8172 - val_loss: 0.5664 - val_accuracy: 0.8182 - val_precision: 0.9387 - val_recall: 0.7428 - val_fmeasure: 0.8109\n",
      "Epoch 56/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.5199 - accuracy: 0.8169 - precision: 0.9417 - recall: 0.7377 - fmeasure: 0.8246src.model - INFO - {Epoch: 55} loss: 0.519932, accuracy: 0.816367, precision: 0.941708, recall: 0.737800, fmeasure: 0.824618, val_loss: 0.770007, val_accuracy: 0.822492, val_precision: 0.925595, val_recall: 0.745181, val_fmeasure: 0.808286\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.5199 - accuracy: 0.8164 - precision: 0.9417 - recall: 0.7378 - fmeasure: 0.8246 - val_loss: 0.7700 - val_accuracy: 0.8225 - val_precision: 0.9256 - val_recall: 0.7452 - val_fmeasure: 0.8083\n",
      "Epoch 57/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.4832 - accuracy: 0.8298 - precision: 0.9444 - recall: 0.7586 - fmeasure: 0.8390src.model - INFO - {Epoch: 56} loss: 0.483789, accuracy: 0.829133, precision: 0.944721, recall: 0.758824, fmeasure: 0.839326, val_loss: 0.840932, val_accuracy: 0.822492, val_precision: 0.912628, val_recall: 0.741566, val_fmeasure: 0.802190\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.4838 - accuracy: 0.8291 - precision: 0.9447 - recall: 0.7588 - fmeasure: 0.8393 - val_loss: 0.8409 - val_accuracy: 0.8225 - val_precision: 0.9126 - val_recall: 0.7416 - val_fmeasure: 0.8022\n",
      "Epoch 58/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.5078 - accuracy: 0.8189 - precision: 0.9351 - recall: 0.7490 - fmeasure: 0.8289src.model - INFO - {Epoch: 57} loss: 0.510966, accuracy: 0.817349, precision: 0.933318, recall: 0.747930, fmeasure: 0.827527, val_loss: 0.532097, val_accuracy: 0.844985, val_precision: 0.936690, val_recall: 0.760241, val_fmeasure: 0.822771\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.5110 - accuracy: 0.8173 - precision: 0.9333 - recall: 0.7479 - fmeasure: 0.8275 - val_loss: 0.5321 - val_accuracy: 0.8450 - val_precision: 0.9367 - val_recall: 0.7602 - val_fmeasure: 0.8228\n",
      "Epoch 59/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.5873 - accuracy: 0.8232 - precision: 0.9390 - recall: 0.7513 - fmeasure: 0.8323src.model - INFO - {Epoch: 58} loss: 0.587216, accuracy: 0.823241, precision: 0.939023, recall: 0.751307, fmeasure: 0.832339, val_loss: 0.696663, val_accuracy: 0.810942, val_precision: 0.909680, val_recall: 0.737952, val_fmeasure: 0.799558\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.5872 - accuracy: 0.8232 - precision: 0.9390 - recall: 0.7513 - fmeasure: 0.8323 - val_loss: 0.6967 - val_accuracy: 0.8109 - val_precision: 0.9097 - val_recall: 0.7380 - val_fmeasure: 0.7996\n",
      "Epoch 60/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.5022 - accuracy: 0.8172 - precision: 0.9336 - recall: 0.7507 - fmeasure: 0.8297src.model - INFO - {Epoch: 59} loss: 0.503998, accuracy: 0.816694, precision: 0.933189, recall: 0.749891, fmeasure: 0.829022, val_loss: 0.589341, val_accuracy: 0.832827, val_precision: 0.931692, val_recall: 0.754819, val_fmeasure: 0.817379\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.5040 - accuracy: 0.8167 - precision: 0.9332 - recall: 0.7499 - fmeasure: 0.8290 - val_loss: 0.5893 - val_accuracy: 0.8328 - val_precision: 0.9317 - val_recall: 0.7548 - val_fmeasure: 0.8174\n",
      "Epoch 61/67\n",
      "152/153 [============================>.] - ETA: 0s - loss: 0.4993 - accuracy: 0.8257 - precision: 0.9397 - recall: 0.7546 - fmeasure: 0.8345src.model - INFO - {Epoch: 60} loss: 0.498611, accuracy: 0.825859, precision: 0.939551, recall: 0.754902, fmeasure: 0.834639, val_loss: 0.538275, val_accuracy: 0.835866, val_precision: 0.936613, val_recall: 0.771084, val_fmeasure: 0.831135\n",
      "153/153 [==============================] - 2s 15ms/step - loss: 0.4986 - accuracy: 0.8259 - precision: 0.9396 - recall: 0.7549 - fmeasure: 0.8346 - val_loss: 0.5383 - val_accuracy: 0.8359 - val_precision: 0.9366 - val_recall: 0.7711 - val_fmeasure: 0.8311\n",
      "Epoch 62/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.4571 - accuracy: 0.8401 - precision: 0.9491 - recall: 0.7685 - fmeasure: 0.8467src.model - INFO - {Epoch: 61} loss: 0.456097, accuracy: 0.841244, precision: 0.949329, recall: 0.770044, fmeasure: 0.847714, val_loss: 0.771699, val_accuracy: 0.841337, val_precision: 0.928052, val_recall: 0.757831, val_fmeasure: 0.818942\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.4561 - accuracy: 0.8412 - precision: 0.9493 - recall: 0.7700 - fmeasure: 0.8477 - val_loss: 0.7717 - val_accuracy: 0.8413 - val_precision: 0.9281 - val_recall: 0.7578 - val_fmeasure: 0.8189\n",
      "Epoch 63/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.4381 - accuracy: 0.8411 - precision: 0.9470 - recall: 0.7742 - fmeasure: 0.8496src.model - INFO - {Epoch: 62} loss: 0.436595, accuracy: 0.841244, precision: 0.946839, recall: 0.774510, fmeasure: 0.849783, val_loss: 0.523086, val_accuracy: 0.856535, val_precision: 0.934717, val_recall: 0.777711, val_fmeasure: 0.834623\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.4366 - accuracy: 0.8412 - precision: 0.9468 - recall: 0.7745 - fmeasure: 0.8498 - val_loss: 0.5231 - val_accuracy: 0.8565 - val_precision: 0.9347 - val_recall: 0.7777 - val_fmeasure: 0.8346\n",
      "Epoch 64/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.4264 - accuracy: 0.8487 - precision: 0.9547 - recall: 0.7805 - fmeasure: 0.8562src.model - INFO - {Epoch: 63} loss: 0.425999, accuracy: 0.848445, precision: 0.954955, recall: 0.781155, fmeasure: 0.856728, val_loss: 0.513801, val_accuracy: 0.852280, val_precision: 0.931448, val_recall: 0.765060, val_fmeasure: 0.824762\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.4260 - accuracy: 0.8484 - precision: 0.9550 - recall: 0.7812 - fmeasure: 0.8567 - val_loss: 0.5138 - val_accuracy: 0.8523 - val_precision: 0.9314 - val_recall: 0.7651 - val_fmeasure: 0.8248\n",
      "Epoch 65/67\n",
      "153/153 [==============================] - ETA: 0s - loss: 0.5218 - accuracy: 0.8259 - precision: 0.9344 - recall: 0.7609 - fmeasure: 0.8371src.model - INFO - {Epoch: 64} loss: 0.521797, accuracy: 0.825859, precision: 0.934384, recall: 0.760893, fmeasure: 0.837103, val_loss: 0.619564, val_accuracy: 0.823708, val_precision: 0.902107, val_recall: 0.751205, val_fmeasure: 0.805939\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.5218 - accuracy: 0.8259 - precision: 0.9344 - recall: 0.7609 - fmeasure: 0.8371 - val_loss: 0.6196 - val_accuracy: 0.8237 - val_precision: 0.9021 - val_recall: 0.7512 - val_fmeasure: 0.8059\n",
      "Epoch 66/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.5134 - accuracy: 0.8232 - precision: 0.9345 - recall: 0.7563 - fmeasure: 0.8338src.model - INFO - {Epoch: 65} loss: 0.514588, accuracy: 0.822259, precision: 0.933052, recall: 0.755338, fmeasure: 0.832581, val_loss: 0.536321, val_accuracy: 0.849240, val_precision: 0.947741, val_recall: 0.769880, val_fmeasure: 0.832959\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.5146 - accuracy: 0.8223 - precision: 0.9331 - recall: 0.7553 - fmeasure: 0.8326 - val_loss: 0.5363 - val_accuracy: 0.8492 - val_precision: 0.9477 - val_recall: 0.7699 - val_fmeasure: 0.8330\n",
      "Epoch 67/67\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.4377 - accuracy: 0.8404 - precision: 0.9504 - recall: 0.7715 - fmeasure: 0.8489src.model - INFO - {Epoch: 66} loss: 0.435006, accuracy: 0.841244, precision: 0.950598, recall: 0.772985, fmeasure: 0.849876, val_loss: 0.467542, val_accuracy: 0.865654, val_precision: 0.945547, val_recall: 0.775904, val_fmeasure: 0.836459\n",
      "153/153 [==============================] - 2s 14ms/step - loss: 0.4350 - accuracy: 0.8412 - precision: 0.9506 - recall: 0.7730 - fmeasure: 0.8499 - val_loss: 0.4675 - val_accuracy: 0.8657 - val_precision: 0.9455 - val_recall: 0.7759 - val_fmeasure: 0.8365\n",
      "src.model - INFO - Training completed\n"
     ]
    }
   ],
   "source": [
    "from src.metrics import *\n",
    "from settings import *\n",
    "from src.data import generate\n",
    "from src.processing import *\n",
    "from src.model import CNN\n",
    "from src.data.preprocessing import get_most_shape\n",
    "from setup_logging import setup_logging\n",
    "\n",
    "from scipy.stats import boxcox\n",
    "from scipy.stats import boxcox_normmax\n",
    "\n",
    "train_datas = []\n",
    "test_datas = []\n",
    "\n",
    "for dataset in datasets_raw:\n",
    "    train_data, test_data = train_test_split(dataset, augmented=False, split_ratio=0.65)\n",
    "    train_datas.append(train_data)\n",
    "    test_datas.append(test_data)\n",
    "\n",
    "for dataset in datasets_augmented:\n",
    "    train_data, test_data = train_test_split(dataset, augmented=False, split_ratio=0.65)\n",
    "    train_datas.append(train_data)\n",
    "    test_datas.append(test_data)\n",
    "\n",
    "train_data = pd.concat(train_datas)\n",
    "test_data = pd.concat(test_datas)\n",
    "\n",
    "spectrograms_train = np.array([x for x in train_data['spectrogram']])\n",
    "curr_shape = spectrograms_train.shape\n",
    "spectrograms_train_squashed = spectrograms_train.reshape(curr_shape[0]*curr_shape[1], curr_shape[2])\n",
    "\n",
    "means = np.mean(spectrograms_train_squashed, axis=0)\n",
    "stds = np.std(spectrograms_train_squashed, axis=0)\n",
    "#lmbdas = np.apply_along_axis(lambda col: boxcox_normmax(col + 1), 0, spectrograms_train_squashed)\n",
    "#print('finished calculating lambdas')\n",
    "#lmbdas = np.apply_along_axis(lambda col: col.shape, 0, spectrograms_train_squashed)\n",
    "#print(lmbdas.shape)\n",
    "# global_stats  = StatsRecorder()\n",
    "\n",
    "# for index, row in train_data.iterrows():\n",
    "#     global_stats.update(row['spectrogram'])\n",
    "\n",
    "# normalize = lambda x: (x-global_stats.mean)/global_stats.std\n",
    "# def normalize(spectro):\n",
    "#     axis = 1\n",
    "#     Ni, Nk = a.shape[:axis], a.shape[axis+1:]\n",
    "#     for ii in np.ndindex(Ni):\n",
    "#         for kk in np.ndindex(Nk):\n",
    "#             f = func1d(arr[ii + np.s_[:,] + kk])\n",
    "#             Nj = f.shape\n",
    "#             for jj in ndindex(Nj):\n",
    "#                 out[ii + jj + kk] = f[jj]\n",
    "i=0\n",
    "def normalize_by_column(col):\n",
    "    global i\n",
    "    tmp = boxcox(x=col + 1, lmbda=lmbdas[i])\n",
    "    i+=1\n",
    "    return tmp\n",
    "\n",
    "def normalize_boxcox(spectro):\n",
    "    global i\n",
    "    i=0\n",
    "    #print(spectro.shape)\n",
    "    tmp = np.apply_along_axis(normalize_by_column, 0, spectro)\n",
    "    #print(tmp.shape)\n",
    "    return tmp\n",
    "\n",
    "def normalize_mean_std(spectro):\n",
    "    return (spectro - means) / stds\n",
    "\n",
    "def ret_normalized(df):\n",
    "    return pd.concat((df.loc[:,[\"class_ID\",\"class_name\"]], df['spectrogram'].apply(normalize_mean_std, 1)), axis=1)\n",
    "\n",
    "train_normalized = ret_normalized(train_data)\n",
    "test_normalized = ret_normalized(test_data)\n",
    "\n",
    "most_shape = get_most_shape(train_normalized)\n",
    "\n",
    "X_train, y_train = features_target_split(train_normalized)\n",
    "X_test, y_test = features_target_split(test_normalized)\n",
    "\n",
    "X_train, X_test = reshape_feature_CNN(X_train, size=max_spectrogram_size), reshape_feature_CNN(X_test, size=max_spectrogram_size)\n",
    "\n",
    "y_test_values = y_test.copy()\n",
    "\n",
    "# One-Hot encoding for classes\n",
    "y_train, y_test = one_hot_encode(y_train), one_hot_encode(y_test)\n",
    "\n",
    "# Instance of CNN model\n",
    "cnn = CNN(most_shape)\n",
    "\n",
    "cnn.train(X_train, y_train, X_test, y_test)\n",
    "#cnn.evaluate(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmbdas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instruments = instruments + instruments_aug\n",
    "for test_data, instrument in zip(test_datas, test_instruments):\n",
    "    X_test = test_data['spectrogram']\n",
    "    X_test = np.array([x.reshape( (128, max_spectrogram_size, 1) ) for x in X_test])\n",
    "    y_test = test_data['class_ID']\n",
    "\n",
    "    y_test_values=y_test\n",
    "    y_test = np.array(keras.utils.to_categorical(y_test, 10))\n",
    "\n",
    "    score = cnn.model.evaluate(X_test,y_test)\n",
    "    print(f'Test score for instrument: {instrument}')\n",
    "    print('\\tTest loss:', score[0])\n",
    "    print('\\tTest accuracy:', score[1])\n",
    "    print('\\tTest precision:', score[2])\n",
    "    print('\\tTest recall:', score[3])\n",
    "    print('\\tTest f1-score:', score[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "danigil-steganalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
