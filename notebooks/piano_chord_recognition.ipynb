{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 06:49:44.096189: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-22 06:49:44.217516: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-22 06:49:44.898334: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvrtc.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-22 06:49:44.898407: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-22 06:49:44.898414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "import keras\n",
    "import os, glob\n",
    "import librosa, librosa.display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, \\\n",
    "                         Flatten, MaxPooling2D\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras import backend as K\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.model import CNN, CNN_nodropout\n",
    "\n",
    "from settings import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.model - INFO - Initializing CNN\n",
      "src.model - INFO - Input shape = (128, 107, 1)\n",
      "src.model - INFO - CNN Initialized\n",
      "src.model - INFO - Loading saved model\n",
      "src.model - INFO - Model loaded from /home/tzag/danigil/dl/guitarCR/models\n",
      "Number of testing samples is 100\n",
      "     file_path file_name class_name  class_ID  \\\n",
      "0   em/em8.wav   em8.wav         em         7   \n",
      "1   em/em6.wav   em6.wav         em         7   \n",
      "2   em/em7.wav   em7.wav         em         7   \n",
      "3   em/em3.wav   em3.wav         em         7   \n",
      "4   em/em5.wav   em5.wav         em         7   \n",
      "5   em/em1.wav   em1.wav         em         7   \n",
      "6   em/em9.wav   em9.wav         em         7   \n",
      "7   em/em4.wav   em4.wav         em         7   \n",
      "8  em/em10.wav  em10.wav         em         7   \n",
      "9   em/em2.wav   em2.wav         em         7   \n",
      "\n",
      "                                                   y     sr  \\\n",
      "0  [0.026554763, 0.039172687, 0.034024365, 0.0322...  22050   \n",
      "1  [-0.00038409373, -0.0042537, -0.00555648, 0.00...  22050   \n",
      "2  [0.003031604, 0.0019594347, 0.002337981, 0.004...  22050   \n",
      "3  [0.0065301657, 0.0032108966, 0.003072461, -0.0...  22050   \n",
      "4  [0.00011465093, -0.0002595787, 0.0030536558, -...  22050   \n",
      "5  [0.005570584, 0.008230754, 0.00390023, 0.00548...  22050   \n",
      "6  [-0.0046899077, -0.0025560618, -0.0002417413, ...  22050   \n",
      "7  [-0.00466606, -0.004525639, -0.01841477, -0.03...  22050   \n",
      "8  [-0.028902877, -0.046145696, -0.037267804, -0....  22050   \n",
      "9  [0.0014920286, 0.005389747, -0.0009446009, -0....  22050   \n",
      "\n",
      "                                         spectrogram      shape  \n",
      "0  [[0.0012124031, 0.0048349383, 0.0098267095, 0....  (128, 29)  \n",
      "1  [[0.0029152043, 0.010677718, 0.021582976, 0.02...  (128, 32)  \n",
      "2  [[0.013534588, 0.021223627, 0.03506054, 0.0390...  (128, 22)  \n",
      "3  [[0.006477491, 0.01019449, 0.023282021, 0.0562...  (128, 29)  \n",
      "4  [[0.0021870092, 0.0038689221, 0.0013439865, 0....  (128, 35)  \n",
      "5  [[0.06775029, 0.10623203, 0.112250626, 0.07531...  (128, 35)  \n",
      "6  [[0.006919995, 0.016582007, 0.019411858, 0.012...  (128, 33)  \n",
      "7  [[0.008794072, 0.015328834, 0.017885255, 0.030...  (128, 30)  \n",
      "8  [[0.044440884, 0.04035565, 0.074726865, 0.1005...  (128, 27)  \n",
      "9  [[0.000985029, 0.0022883906, 0.006663131, 0.00...  (128, 34)  \n",
      "4/4 [==============================] - 0s 9ms/step - loss: 346.6071 - accuracy: 0.1900 - precision: 0.1403 - recall: 0.1328 - fmeasure: 0.1365            \n",
      "Test loss: 346.6071472167969\n",
      "Test accuracy: 0.1899999976158142\n",
      "Test precision: 0.14032258093357086\n",
      "Test recall: 0.1328125\n",
      "Test f1-score: 0.1364567130804062\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN((128, 107))\n",
    "cnn.load_model(\"baseline_results\")\n",
    "\n",
    "dataset_piano = pd.read_pickle(os.path.join(METADATA_DIR_RAW, 'data_violin.pkl'))\n",
    "size = 107\n",
    "dataset_piano['spectrogram'] = dataset_piano['spectrogram'].apply(lambda x: np.pad(x, ((0, 0), (0, size-x.shape[1])), 'constant'))\n",
    "\n",
    "test_data = dataset_piano\n",
    "\n",
    "print(\"Number of testing samples is\", len(test_data))\n",
    "print(test_data[:10])\n",
    "\n",
    "X_test = test_data['spectrogram']\n",
    "X_test = np.array([np.pad(x, ((0, 0), (0, size-x.shape[1])), 'constant') for x in dataset_piano['spectrogram']])\n",
    "y_test = test_data['class_ID']\n",
    "\n",
    "X_test = np.array([x.reshape( (128, size, 1) ) for x in X_test])\n",
    "\n",
    "y_test_values=y_test\n",
    "y_test = np.array(keras.utils.to_categorical(y_test, 10))\n",
    "\n",
    "score = cnn.model.evaluate(\n",
    "\tx=X_test,\n",
    "\ty=y_test)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test precision:', score[2])\n",
    "print('Test recall:', score[3])\n",
    "print('Test f1-score:', score[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.model - INFO - Input shape = (128, 213, 1)\n",
      "src.model - INFO - Loading saved model\n",
      "src.model - INFO - Model loaded from /home/tzag/danigil/dl/guitarCR/models\n",
      "Number of testing samples is 100\n",
      "     file_path file_name class_name  class_ID  \\\n",
      "0   em/em8.wav   em8.wav         em         7   \n",
      "1   em/em6.wav   em6.wav         em         7   \n",
      "2   em/em7.wav   em7.wav         em         7   \n",
      "3   em/em3.wav   em3.wav         em         7   \n",
      "4   em/em5.wav   em5.wav         em         7   \n",
      "5   em/em1.wav   em1.wav         em         7   \n",
      "6   em/em9.wav   em9.wav         em         7   \n",
      "7   em/em4.wav   em4.wav         em         7   \n",
      "8  em/em10.wav  em10.wav         em         7   \n",
      "9   em/em2.wav   em2.wav         em         7   \n",
      "\n",
      "                                                   y     sr  \\\n",
      "0  [0.06301807, 0.061424017, 0.06360255, 0.066206...  44100   \n",
      "1  [0.0032537961, -0.022001859, -0.015184382, -0....  44100   \n",
      "2  [0.011664668, 0.017987572, 0.00032704676, 0.00...  44100   \n",
      "3  [0.013433866, 0.014071045, 0.0030797005, -5.30...  44100   \n",
      "4  [0.0020957899, -0.0038217346, 0.0035135301, -0...  44100   \n",
      "5  [0.010366364, 0.022793123, 0.016225614, 0.0073...  44100   \n",
      "6  [-0.014503104, -0.00741636, -0.000494424, -0.0...  44100   \n",
      "7  [-0.008590971, -0.015266757, 0.0010396717, -0....  44100   \n",
      "8  [-0.062896095, -0.07668956, -0.07338765, -0.07...  44100   \n",
      "9  [0.0059090173, 0.0029949814, 0.02395985, 0.007...  44100   \n",
      "\n",
      "                                         spectrogram      shape  \n",
      "0  [[-0.53896147, -0.7448858, -0.53719485, -0.412...  (128, 57)  \n",
      "1  [[-0.50004226, -0.29744884, -0.21301274, -0.16...  (128, 64)  \n",
      "2  [[-0.2626275, -0.18769784, -0.27691397, -0.272...  (128, 43)  \n",
      "3  [[-0.41245425, -0.46958438, -0.37279114, -0.42...  (128, 57)  \n",
      "4  [[-0.51751184, -0.51724726, -0.48437372, -0.54...  (128, 69)  \n",
      "5  [[-0.13850193, -0.0956463, -0.0674215, -0.0590...  (128, 69)  \n",
      "6  [[-0.397268, -0.42491665, -0.3204691, -0.35336...  (128, 65)  \n",
      "7  [[-0.39037654, -0.37400022, -0.36016613, -0.45...  (128, 59)  \n",
      "8  [[-0.17640886, -0.27862367, -0.2823911, -0.342...  (128, 54)  \n",
      "9  [[-0.50992644, -0.64948255, -0.5454224, -0.555...  (128, 67)  \n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - fmeasure: 1.0000\n",
      "Test loss: 0.0011098097311332822\n",
      "Test accuracy: 1.0\n",
      "Test precision: 1.0\n",
      "Test recall: 1.0\n",
      "Test f1-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "size = 213\n",
    "cnn = CNN_nodropout((128, size))\n",
    "cnn.load_model(\"mymodel\")\n",
    "\n",
    "dataset_piano = pd.read_pickle(os.path.join(METADATA_DIR_RAW_NORMALIZED, 'data_violin.pkl'))\n",
    "#dataset_piano['spectrogram'] = dataset_piano['spectrogram'].apply(lambda x: np.pad(x, ((0, 0), (0, size-x.shape[1])), 'constant'))\n",
    "\n",
    "test_data = dataset_piano\n",
    "\n",
    "print(\"Number of testing samples is\", len(test_data))\n",
    "print(test_data[:10])\n",
    "\n",
    "X_test = test_data['spectrogram']\n",
    "X_test = np.array([np.pad(x, ((0, 0), (0, size-x.shape[1])), 'constant') for x in dataset_piano['spectrogram']])\n",
    "y_test = test_data['class_ID']\n",
    "\n",
    "X_test = np.array([x.reshape( (128, size, 1) ) for x in X_test])\n",
    "\n",
    "y_test_values=y_test\n",
    "y_test = np.array(keras.utils.to_categorical(y_test, 10))\n",
    "\n",
    "score = cnn.model.evaluate(\n",
    "\tx=X_test,\n",
    "\ty=y_test)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test precision:', score[2])\n",
    "print('Test recall:', score[3])\n",
    "print('Test f1-score:', score[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_piano = pd.read_pickle(os.path.join(METADATA_DIR_RAW, 'data_piano.pkl'))\n",
    "\n",
    "from itertools import groupby\n",
    "\n",
    "def all_equal(iterable):\n",
    "    g = groupby(iterable)\n",
    "    return next(g, True) and not next(g, False)\n",
    "\n",
    "assert all_equal(dataset_piano['spectrogram'].map(lambda x: x.shape[0]))\n",
    "\n",
    "max_size = max(dataset_piano['spectrogram'].map(lambda x: x.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_piano['spectrogram'] = dataset_piano['spectrogram'].apply(lambda x: np.pad(x, ((0, 0), (0, max_size-x.shape[1])), 'constant'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87)]\n"
     ]
    }
   ],
   "source": [
    "print([x.shape for x in dataset_piano['spectrogram']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87)]\n"
     ]
    }
   ],
   "source": [
    "dataset_guitar = pd.read_pickle(os.path.join(METADATA_DIR_PROCESSED, 'data_guitar.pkl'))\n",
    "print([x.shape for x in dataset_guitar['spectrogram']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87), (128, 87)]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_pickle(os.path.join(METADATA_DIR_RAW, 'data_piano.pkl'))\n",
    "print([np.pad(x, ((0, 0), (0, 87-x.shape[1])), 'constant').shape for x in dataset['spectrogram']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of testing samples is 100\n",
      "     file_path file_name class_name  class_ID  \\\n",
      "0   em/em8.wav   em8.wav         em         7   \n",
      "1   em/em6.wav   em6.wav         em         7   \n",
      "2   em/em7.wav   em7.wav         em         7   \n",
      "3   em/em3.wav   em3.wav         em         7   \n",
      "4   em/em5.wav   em5.wav         em         7   \n",
      "5   em/em1.wav   em1.wav         em         7   \n",
      "6   em/em9.wav   em9.wav         em         7   \n",
      "7   em/em4.wav   em4.wav         em         7   \n",
      "8  em/em10.wav  em10.wav         em         7   \n",
      "9   em/em2.wav   em2.wav         em         7   \n",
      "\n",
      "                                                   y     sr  \\\n",
      "0  [-0.0026758127, -0.0040184762, -0.004359124, -...  22050   \n",
      "1  [0.0007722303, 0.0018129349, 0.0006996244, 0.0...  22050   \n",
      "2  [-0.0026981905, -0.0034450963, -0.0021259002, ...  22050   \n",
      "3  [-0.002258081, -0.0025149286, -0.0010869578, -...  22050   \n",
      "4  [-0.005968757, -0.0077354126, -0.006970454, -0...  22050   \n",
      "5  [-0.0008049598, -0.0005307044, -0.00051933434,...  22050   \n",
      "6  [0.00010821875, 0.00067749154, 0.0008774288, 0...  22050   \n",
      "7  [0.0012531318, 0.0028354488, 0.0023814254, 0.0...  22050   \n",
      "8  [0.00095057336, 0.000635623, 0.00048708334, 6....  22050   \n",
      "9  [0.06376804, 0.08827582, 0.07017153, 0.0756941...  22050   \n",
      "\n",
      "                                         spectrogram      shape  \n",
      "0  [[0.004391378, 0.024867328, 0.053857267, 0.070...  (128, 37)  \n",
      "1  [[0.0023469902, 0.013036287, 0.026323183, 0.05...  (128, 38)  \n",
      "2  [[0.012769312, 0.02229768, 0.039185062, 0.0391...  (128, 46)  \n",
      "3  [[0.010647047, 0.006855319, 0.0065777255, 0.01...  (128, 42)  \n",
      "4  [[0.002548208, 0.004532898, 0.0061204825, 0.00...  (128, 42)  \n",
      "5  [[0.0009819805, 0.00072606135, 0.0013472042, 0...  (128, 41)  \n",
      "6  [[0.00036306537, 0.0011519301, 0.0041095056, 0...  (128, 40)  \n",
      "7  [[0.010281028, 0.007909578, 0.006278698, 0.006...  (128, 47)  \n",
      "8  [[0.0003580294, 0.0029536248, 0.012716628, 0.0...  (128, 35)  \n",
      "9  [[0.029236555, 0.0330122, 0.024281297, 0.02111...  (128, 46)  \n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_pickle(os.path.join(METADATA_DIR_RAW, 'data_piano.pkl'))\n",
    "\n",
    "test_data = dataset\n",
    "\n",
    "print(\"Number of testing samples is\", len(test_data))\n",
    "print(test_data[:10])\n",
    "\n",
    "X_test = test_data['spectrogram']\n",
    "X_test = np.array([np.pad(x, ((0, 0), (0, 87-x.shape[1])), 'constant') for x in dataset['spectrogram']])\n",
    "y_test = test_data['class_ID']\n",
    "\n",
    "X_test = np.array([x.reshape( (128, 87, 1) ) for x in X_test])\n",
    "\n",
    "y_test_values=y_test\n",
    "y_test = np.array(keras.utils.to_categorical(y_test, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    '''Calculates the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    '''\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    '''Calculates the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    '''\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "    '''Calculates the F score, the weighted harmonic mean of precision and recall.\n",
    "    This is useful for multi-label classification, where input samples can be\n",
    "    classified as sets of labels. By only using accuracy (precision) a model\n",
    "    would achieve a perfect score by simply assigning every class to every\n",
    "    input. In order to avoid this, a metric should penalize incorrect class\n",
    "    assignments as well (recall). The F-beta score (ranged from 0.0 to 1.0)\n",
    "    computes this, as a weighted mean of the proportion of correct class\n",
    "    assignments vs. the proportion of incorrect class assignments.\n",
    "    With beta = 1, this is equivalent to a F-measure. With beta < 1, assigning\n",
    "    correct classes becomes more important, and with beta > 1 the metric is\n",
    "    instead weighted towards penalizing incorrect class assignments.\n",
    "    '''\n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "        \n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score\n",
    "\n",
    "\n",
    "def fmeasure(y_true, y_pred):\n",
    "    '''Calculates the f-measure, the harmonic mean of precision and recall.\n",
    "    '''\n",
    "    return fbeta_score(y_true, y_pred, beta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 16ms/step - loss: 24.2755 - accuracy: 0.2000 - precision: 0.2219 - recall: 0.2109 - fmeasure: 0.2161\n",
      "Test loss: 24.275524139404297\n",
      "Test accuracy: 0.20000000298023224\n",
      "Test precision: 0.22194939851760864\n",
      "Test recall: 0.2109375\n",
      "Test f1-score: 0.2161121815443039\n"
     ]
    }
   ],
   "source": [
    "with open(MODEL_1_JSON, \"r\") as json_file:\n",
    "\tloaded_model_json = json_file.read()\n",
    "\n",
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights(MODEL_1_H5)\n",
    "\n",
    "model.compile(\n",
    "            optimizer=\"Adam\",\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics=['accuracy', precision, recall, fmeasure])\n",
    "\n",
    "score = model.evaluate(\n",
    "\tx=X_test,\n",
    "\ty=y_test)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test precision:', score[2])\n",
    "print('Test recall:', score[3])\n",
    "print('Test f1-score:', score[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "danigil-steganalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
