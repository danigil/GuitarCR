{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.model - INFO - Initializing CNN\n",
      "src.model - INFO - Input shape = (128, 213, 1)\n",
      "src.model - INFO - CNN Initialized\n",
      "src.model - INFO - Loading saved model\n",
      "src.model - INFO - Model loaded from /home/tzag/danigil/dl/guitarCR/models\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os, sys\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('./..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from settings import *\n",
    "from notebooks.my_train import *\n",
    "from src.model import CNN, CNN_nodropout\n",
    "import librosa\n",
    "\n",
    "most_shape = (128, 213)\n",
    "baseline = CNN(most_shape)\n",
    "baseline.load_model('baseline_latest_128_213')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 1300\n",
      "src.processing - INFO - Number of testing samples is 700\n",
      "src.processing - INFO - Train test split completed\n"
     ]
    }
   ],
   "source": [
    "from src.data.preprocessing import uniform_shape\n",
    "from src.processing import *\n",
    "\n",
    "train_datas = []\n",
    "test_datas = []\n",
    "\n",
    "instruments = ['Guitar', 'Accordion', 'Violin', 'Piano']\n",
    "datasets_raw = [pd.read_pickle(os.path.join(METADATA_DIR_PROCESSED, f'data_{instrument.lower()}.pkl')) for instrument in instruments]\n",
    "\n",
    "for i in range(len(datasets_raw)):\n",
    "    datasets_raw[i] = uniform_shape(datasets_raw[i], most_shape[1])\n",
    "\n",
    "train_data_guitar, test_data_guitar = train_test_split(datasets_raw[0], augmented=False, split_ratio=0.65)\n",
    "\n",
    "test_datas.append(test_data_guitar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 1300\n",
      "src.processing - INFO - Number of testing samples is 700\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start feature target split\n",
      "src.processing - INFO - Feature target split completed\n",
      "src.processing - INFO - Start feature target split\n",
      "src.processing - INFO - Feature target split completed\n",
      "src.processing - INFO - Features reshaped for CNN Input\n",
      "src.processing - INFO - Features reshaped for CNN Input\n",
      "src.processing - INFO - Target one hot encoded\n",
      "src.processing - INFO - Target one hot encoded\n",
      "src.model - INFO - Start training model\n",
      "src.model - INFO - Tensorboard Logging Started\n",
      "src.model - INFO - Use the following command in the terminal to view the logs during training: tensorboard --logdir logs/training\n",
      "Epoch 1/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 2.2377 - accuracy: 0.1500 - precision: 0.1639 - recall: 0.0107 - fmeasure: 0.0197src.model - INFO - {Epoch: 0} loss: 2.234499, accuracy: 0.150000, precision: 0.161538, recall: 0.010769, fmeasure: 0.019931, val_loss: 2.131870, val_accuracy: 0.251429, val_precision: 0.257143, val_recall: 0.030000, val_fmeasure: 0.052507\n",
      "65/65 [==============================] - 3s 23ms/step - loss: 2.2345 - accuracy: 0.1500 - precision: 0.1615 - recall: 0.0108 - fmeasure: 0.0199 - val_loss: 2.1319 - val_accuracy: 0.2514 - val_precision: 0.2571 - val_recall: 0.0300 - val_fmeasure: 0.0525\n",
      "Epoch 2/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 2.1086 - accuracy: 0.2008 - precision: 0.4661 - recall: 0.0426 - fmeasure: 0.0763src.model - INFO - {Epoch: 1} loss: 2.094088, accuracy: 0.206154, precision: 0.491282, recall: 0.046923, fmeasure: 0.083621, val_loss: 1.924165, val_accuracy: 0.314286, val_precision: 0.467381, val_recall: 0.087143, val_fmeasure: 0.141041\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 2.0941 - accuracy: 0.2062 - precision: 0.4913 - recall: 0.0469 - fmeasure: 0.0836 - val_loss: 1.9242 - val_accuracy: 0.3143 - val_precision: 0.4674 - val_recall: 0.0871 - val_fmeasure: 0.1410\n",
      "Epoch 3/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 1.9840 - accuracy: 0.2795 - precision: 0.5891 - recall: 0.0934 - fmeasure: 0.1573src.model - INFO - {Epoch: 2} loss: 1.981834, accuracy: 0.276923, precision: 0.597766, recall: 0.093846, fmeasure: 0.158419, val_loss: 1.788215, val_accuracy: 0.374286, val_precision: 0.575204, val_recall: 0.148571, val_fmeasure: 0.222902\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 1.9818 - accuracy: 0.2769 - precision: 0.5978 - recall: 0.0938 - fmeasure: 0.1584 - val_loss: 1.7882 - val_accuracy: 0.3743 - val_precision: 0.5752 - val_recall: 0.1486 - val_fmeasure: 0.2229\n",
      "Epoch 4/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 1.8762 - accuracy: 0.3270 - precision: 0.6997 - recall: 0.1467 - fmeasure: 0.2361src.model - INFO - {Epoch: 3} loss: 1.865156, accuracy: 0.333077, precision: 0.718187, recall: 0.150000, fmeasure: 0.241154, val_loss: 1.705597, val_accuracy: 0.431429, val_precision: 0.676336, val_recall: 0.215714, val_fmeasure: 0.314879\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 1.8652 - accuracy: 0.3331 - precision: 0.7182 - recall: 0.1500 - fmeasure: 0.2412 - val_loss: 1.7056 - val_accuracy: 0.4314 - val_precision: 0.6763 - val_recall: 0.2157 - val_fmeasure: 0.3149\n",
      "Epoch 5/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 1.7050 - accuracy: 0.4107 - precision: 0.8214 - recall: 0.2205 - fmeasure: 0.3402src.model - INFO - {Epoch: 4} loss: 1.704089, accuracy: 0.410000, precision: 0.811374, recall: 0.217692, fmeasure: 0.336048, val_loss: 1.720036, val_accuracy: 0.431429, val_precision: 0.754488, val_recall: 0.261429, val_fmeasure: 0.369354\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 1.7041 - accuracy: 0.4100 - precision: 0.8114 - recall: 0.2177 - fmeasure: 0.3360 - val_loss: 1.7200 - val_accuracy: 0.4314 - val_precision: 0.7545 - val_recall: 0.2614 - val_fmeasure: 0.3694\n",
      "Epoch 6/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 1.6340 - accuracy: 0.4451 - precision: 0.8447 - recall: 0.2713 - fmeasure: 0.4045src.model - INFO - {Epoch: 5} loss: 1.638042, accuracy: 0.442308, precision: 0.846203, recall: 0.271538, fmeasure: 0.404389, val_loss: 1.663347, val_accuracy: 0.450000, val_precision: 0.813900, val_recall: 0.290000, val_fmeasure: 0.406731\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 1.6380 - accuracy: 0.4423 - precision: 0.8462 - recall: 0.2715 - fmeasure: 0.4044 - val_loss: 1.6633 - val_accuracy: 0.4500 - val_precision: 0.8139 - val_recall: 0.2900 - val_fmeasure: 0.4067\n",
      "Epoch 7/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 1.5004 - accuracy: 0.4910 - precision: 0.8603 - recall: 0.3115 - fmeasure: 0.4493src.model - INFO - {Epoch: 6} loss: 1.489906, accuracy: 0.495385, precision: 0.867231, recall: 0.316154, fmeasure: 0.455671, val_loss: 1.365295, val_accuracy: 0.567143, val_precision: 0.912313, val_recall: 0.402857, val_fmeasure: 0.547142\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 1.4899 - accuracy: 0.4954 - precision: 0.8672 - recall: 0.3162 - fmeasure: 0.4557 - val_loss: 1.3653 - val_accuracy: 0.5671 - val_precision: 0.9123 - val_recall: 0.4029 - val_fmeasure: 0.5471\n",
      "Epoch 8/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 1.3648 - accuracy: 0.5262 - precision: 0.8901 - recall: 0.3811 - fmeasure: 0.5263src.model - INFO - {Epoch: 7} loss: 1.378747, accuracy: 0.527692, precision: 0.891512, recall: 0.383077, fmeasure: 0.528812, val_loss: 1.237512, val_accuracy: 0.584286, val_precision: 0.943889, val_recall: 0.444286, val_fmeasure: 0.595242\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 1.3787 - accuracy: 0.5277 - precision: 0.8915 - recall: 0.3831 - fmeasure: 0.5288 - val_loss: 1.2375 - val_accuracy: 0.5843 - val_precision: 0.9439 - val_recall: 0.4443 - val_fmeasure: 0.5952\n",
      "Epoch 9/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 1.4367 - accuracy: 0.5303 - precision: 0.8890 - recall: 0.3779 - fmeasure: 0.5235src.model - INFO - {Epoch: 8} loss: 1.432588, accuracy: 0.529231, precision: 0.888309, recall: 0.376154, fmeasure: 0.521989, val_loss: 1.247678, val_accuracy: 0.601429, val_precision: 0.929555, val_recall: 0.424286, val_fmeasure: 0.571466\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 1.4326 - accuracy: 0.5292 - precision: 0.8883 - recall: 0.3762 - fmeasure: 0.5220 - val_loss: 1.2477 - val_accuracy: 0.6014 - val_precision: 0.9296 - val_recall: 0.4243 - val_fmeasure: 0.5715\n",
      "Epoch 10/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 1.2453 - accuracy: 0.5697 - precision: 0.9251 - recall: 0.4180 - fmeasure: 0.5689src.model - INFO - {Epoch: 9} loss: 1.230680, accuracy: 0.574615, precision: 0.925747, recall: 0.423846, fmeasure: 0.574544, val_loss: 1.079691, val_accuracy: 0.637143, val_precision: 0.956143, val_recall: 0.478571, val_fmeasure: 0.631055\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 1.2307 - accuracy: 0.5746 - precision: 0.9257 - recall: 0.4238 - fmeasure: 0.5745 - val_loss: 1.0797 - val_accuracy: 0.6371 - val_precision: 0.9561 - val_recall: 0.4786 - val_fmeasure: 0.6311\n",
      "Epoch 11/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 1.1753 - accuracy: 0.6049 - precision: 0.9481 - recall: 0.4607 - fmeasure: 0.6134src.model - INFO - {Epoch: 10} loss: 1.174938, accuracy: 0.604615, precision: 0.946691, recall: 0.459231, fmeasure: 0.612029, val_loss: 1.104122, val_accuracy: 0.670000, val_precision: 0.926811, val_recall: 0.480000, val_fmeasure: 0.623453\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 1.1749 - accuracy: 0.6046 - precision: 0.9467 - recall: 0.4592 - fmeasure: 0.6120 - val_loss: 1.1041 - val_accuracy: 0.6700 - val_precision: 0.9268 - val_recall: 0.4800 - val_fmeasure: 0.6235\n",
      "Epoch 12/67\n",
      "65/65 [==============================] - ETA: 0s - loss: 1.1514 - accuracy: 0.6215 - precision: 0.9212 - recall: 0.4585 - fmeasure: 0.6070src.model - INFO - {Epoch: 11} loss: 1.151445, accuracy: 0.621538, precision: 0.921180, recall: 0.458462, fmeasure: 0.606994, val_loss: 0.983568, val_accuracy: 0.697143, val_precision: 0.946347, val_recall: 0.501429, val_fmeasure: 0.646159\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 1.1514 - accuracy: 0.6215 - precision: 0.9212 - recall: 0.4585 - fmeasure: 0.6070 - val_loss: 0.9836 - val_accuracy: 0.6971 - val_precision: 0.9463 - val_recall: 0.5014 - val_fmeasure: 0.6462\n",
      "Epoch 13/67\n",
      "65/65 [==============================] - ETA: 0s - loss: 1.0641 - accuracy: 0.6531 - precision: 0.9435 - recall: 0.4900 - fmeasure: 0.6395src.model - INFO - {Epoch: 12} loss: 1.064134, accuracy: 0.653077, precision: 0.943466, recall: 0.490000, fmeasure: 0.639485, val_loss: 0.959665, val_accuracy: 0.695714, val_precision: 0.946142, val_recall: 0.511429, val_fmeasure: 0.653890\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 1.0641 - accuracy: 0.6531 - precision: 0.9435 - recall: 0.4900 - fmeasure: 0.6395 - val_loss: 0.9597 - val_accuracy: 0.6957 - val_precision: 0.9461 - val_recall: 0.5114 - val_fmeasure: 0.6539\n",
      "Epoch 14/67\n",
      "63/65 [============================>.] - ETA: 0s - loss: 0.9639 - accuracy: 0.6659 - precision: 0.9459 - recall: 0.4992 - fmeasure: 0.6471src.model - INFO - {Epoch: 13} loss: 0.955133, accuracy: 0.669231, precision: 0.947521, recall: 0.503077, fmeasure: 0.650835, val_loss: 0.793734, val_accuracy: 0.744286, val_precision: 0.951040, val_recall: 0.531429, val_fmeasure: 0.673707\n",
      "65/65 [==============================] - 1s 18ms/step - loss: 0.9551 - accuracy: 0.6692 - precision: 0.9475 - recall: 0.5031 - fmeasure: 0.6508 - val_loss: 0.7937 - val_accuracy: 0.7443 - val_precision: 0.9510 - val_recall: 0.5314 - val_fmeasure: 0.6737\n",
      "Epoch 15/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.9290 - accuracy: 0.6721 - precision: 0.9148 - recall: 0.5156 - fmeasure: 0.6525src.model - INFO - {Epoch: 14} loss: 0.912391, accuracy: 0.678462, precision: 0.913691, recall: 0.520000, fmeasure: 0.655779, val_loss: 0.738814, val_accuracy: 0.727143, val_precision: 0.948118, val_recall: 0.557143, val_fmeasure: 0.692411\n",
      "65/65 [==============================] - 1s 14ms/step - loss: 0.9124 - accuracy: 0.6785 - precision: 0.9137 - recall: 0.5200 - fmeasure: 0.6558 - val_loss: 0.7388 - val_accuracy: 0.7271 - val_precision: 0.9481 - val_recall: 0.5571 - val_fmeasure: 0.6924\n",
      "Epoch 16/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.7657 - accuracy: 0.7279 - precision: 0.9302 - recall: 0.5672 - fmeasure: 0.7016src.model - INFO - {Epoch: 15} loss: 0.766494, accuracy: 0.723846, precision: 0.933050, recall: 0.564615, fmeasure: 0.700447, val_loss: 0.673138, val_accuracy: 0.761429, val_precision: 0.909512, val_recall: 0.594286, val_fmeasure: 0.707915\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.7665 - accuracy: 0.7238 - precision: 0.9330 - recall: 0.5646 - fmeasure: 0.7004 - val_loss: 0.6731 - val_accuracy: 0.7614 - val_precision: 0.9095 - val_recall: 0.5943 - val_fmeasure: 0.7079\n",
      "Epoch 17/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.9469 - accuracy: 0.7090 - precision: 0.8840 - recall: 0.5516 - fmeasure: 0.6735src.model - INFO - {Epoch: 16} loss: 0.946199, accuracy: 0.706154, precision: 0.878279, recall: 0.550000, fmeasure: 0.670589, val_loss: 0.949377, val_accuracy: 0.732857, val_precision: 0.899838, val_recall: 0.525714, val_fmeasure: 0.653324\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.9462 - accuracy: 0.7062 - precision: 0.8783 - recall: 0.5500 - fmeasure: 0.6706 - val_loss: 0.9494 - val_accuracy: 0.7329 - val_precision: 0.8998 - val_recall: 0.5257 - val_fmeasure: 0.6533\n",
      "Epoch 18/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.7508 - accuracy: 0.7197 - precision: 0.8998 - recall: 0.5730 - fmeasure: 0.6949src.model - INFO - {Epoch: 17} loss: 0.744268, accuracy: 0.722308, precision: 0.901087, recall: 0.576154, fmeasure: 0.697671, val_loss: 0.697507, val_accuracy: 0.782857, val_precision: 0.909427, val_recall: 0.595714, val_fmeasure: 0.710970\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.7443 - accuracy: 0.7223 - precision: 0.9011 - recall: 0.5762 - fmeasure: 0.6977 - val_loss: 0.6975 - val_accuracy: 0.7829 - val_precision: 0.9094 - val_recall: 0.5957 - val_fmeasure: 0.7110\n",
      "Epoch 19/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.7378 - accuracy: 0.7418 - precision: 0.9033 - recall: 0.6033 - fmeasure: 0.7177src.model - INFO - {Epoch: 18} loss: 0.730587, accuracy: 0.745385, precision: 0.904523, recall: 0.603846, fmeasure: 0.718685, val_loss: 0.765912, val_accuracy: 0.744286, val_precision: 0.881295, val_recall: 0.628572, val_fmeasure: 0.725837\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.7306 - accuracy: 0.7454 - precision: 0.9045 - recall: 0.6038 - fmeasure: 0.7187 - val_loss: 0.7659 - val_accuracy: 0.7443 - val_precision: 0.8813 - val_recall: 0.6286 - val_fmeasure: 0.7258\n",
      "Epoch 20/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.7063 - accuracy: 0.7475 - precision: 0.8845 - recall: 0.6156 - fmeasure: 0.7223src.model - INFO - {Epoch: 19} loss: 0.725894, accuracy: 0.737692, precision: 0.876589, recall: 0.609231, fmeasure: 0.715146, val_loss: 0.835207, val_accuracy: 0.811429, val_precision: 0.903918, val_recall: 0.611429, val_fmeasure: 0.719869\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.7259 - accuracy: 0.7377 - precision: 0.8766 - recall: 0.6092 - fmeasure: 0.7151 - val_loss: 0.8352 - val_accuracy: 0.8114 - val_precision: 0.9039 - val_recall: 0.6114 - val_fmeasure: 0.7199\n",
      "Epoch 21/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.8037 - accuracy: 0.7287 - precision: 0.8838 - recall: 0.6090 - fmeasure: 0.7168src.model - INFO - {Epoch: 20} loss: 0.802359, accuracy: 0.730000, precision: 0.883464, recall: 0.612308, fmeasure: 0.718857, val_loss: 0.597250, val_accuracy: 0.822857, val_precision: 0.935188, val_recall: 0.622857, val_fmeasure: 0.738847\n",
      "65/65 [==============================] - 1s 14ms/step - loss: 0.8024 - accuracy: 0.7300 - precision: 0.8835 - recall: 0.6123 - fmeasure: 0.7189 - val_loss: 0.5972 - val_accuracy: 0.8229 - val_precision: 0.9352 - val_recall: 0.6229 - val_fmeasure: 0.7388\n",
      "Epoch 22/67\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.5707 - accuracy: 0.7754 - precision: 0.8903 - recall: 0.6569 - fmeasure: 0.7523src.model - INFO - {Epoch: 21} loss: 0.570683, accuracy: 0.775385, precision: 0.890335, recall: 0.656923, fmeasure: 0.752250, val_loss: 0.531806, val_accuracy: 0.821429, val_precision: 0.916593, val_recall: 0.664286, val_fmeasure: 0.762897\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 0.5707 - accuracy: 0.7754 - precision: 0.8903 - recall: 0.6569 - fmeasure: 0.7523 - val_loss: 0.5318 - val_accuracy: 0.8214 - val_precision: 0.9166 - val_recall: 0.6643 - val_fmeasure: 0.7629\n",
      "Epoch 23/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.5632 - accuracy: 0.8033 - precision: 0.9014 - recall: 0.6934 - fmeasure: 0.7814src.model - INFO - {Epoch: 22} loss: 0.558715, accuracy: 0.804615, precision: 0.899372, recall: 0.696154, fmeasure: 0.782387, val_loss: 0.629122, val_accuracy: 0.814286, val_precision: 0.889115, val_recall: 0.684286, val_fmeasure: 0.768049\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.5587 - accuracy: 0.8046 - precision: 0.8994 - recall: 0.6962 - fmeasure: 0.7824 - val_loss: 0.6291 - val_accuracy: 0.8143 - val_precision: 0.8891 - val_recall: 0.6843 - val_fmeasure: 0.7680\n",
      "Epoch 24/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.5662 - accuracy: 0.7885 - precision: 0.8867 - recall: 0.6918 - fmeasure: 0.7741src.model - INFO - {Epoch: 23} loss: 0.559780, accuracy: 0.790769, precision: 0.886974, recall: 0.694615, fmeasure: 0.776035, val_loss: 0.518581, val_accuracy: 0.774286, val_precision: 0.829105, val_recall: 0.687143, val_fmeasure: 0.748064\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.5598 - accuracy: 0.7908 - precision: 0.8870 - recall: 0.6946 - fmeasure: 0.7760 - val_loss: 0.5186 - val_accuracy: 0.7743 - val_precision: 0.8291 - val_recall: 0.6871 - val_fmeasure: 0.7481\n",
      "Epoch 25/67\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.5188 - accuracy: 0.7953 - precision: 0.8794 - recall: 0.6914 - fmeasure: 0.7707src.model - INFO - {Epoch: 24} loss: 0.515821, accuracy: 0.796154, precision: 0.879451, recall: 0.692308, fmeasure: 0.771269, val_loss: 0.529412, val_accuracy: 0.831429, val_precision: 0.879841, val_recall: 0.752857, val_fmeasure: 0.810048\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 0.5158 - accuracy: 0.7962 - precision: 0.8795 - recall: 0.6923 - fmeasure: 0.7713 - val_loss: 0.5294 - val_accuracy: 0.8314 - val_precision: 0.8798 - val_recall: 0.7529 - val_fmeasure: 0.8100\n",
      "Epoch 26/67\n",
      "63/65 [============================>.] - ETA: 0s - loss: 0.5338 - accuracy: 0.7976 - precision: 0.8709 - recall: 0.7079 - fmeasure: 0.7782src.model - INFO - {Epoch: 25} loss: 0.528609, accuracy: 0.800769, precision: 0.873920, recall: 0.709231, fmeasure: 0.780305, val_loss: 1.084499, val_accuracy: 0.788571, val_precision: 0.847075, val_recall: 0.685714, val_fmeasure: 0.751496\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 0.5286 - accuracy: 0.8008 - precision: 0.8739 - recall: 0.7092 - fmeasure: 0.7803 - val_loss: 1.0845 - val_accuracy: 0.7886 - val_precision: 0.8471 - val_recall: 0.6857 - val_fmeasure: 0.7515\n",
      "Epoch 27/67\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.5667 - accuracy: 0.7923 - precision: 0.8712 - recall: 0.7031 - fmeasure: 0.7756src.model - INFO - {Epoch: 26} loss: 0.566743, accuracy: 0.792308, precision: 0.871212, recall: 0.703077, fmeasure: 0.775634, val_loss: 0.638903, val_accuracy: 0.820000, val_precision: 0.879915, val_recall: 0.741429, val_fmeasure: 0.802312\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 0.5667 - accuracy: 0.7923 - precision: 0.8712 - recall: 0.7031 - fmeasure: 0.7756 - val_loss: 0.6389 - val_accuracy: 0.8200 - val_precision: 0.8799 - val_recall: 0.7414 - val_fmeasure: 0.8023\n",
      "Epoch 28/67\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.4622 - accuracy: 0.8169 - precision: 0.8745 - recall: 0.7400 - fmeasure: 0.8003src.model - INFO - {Epoch: 27} loss: 0.462203, accuracy: 0.816923, precision: 0.874535, recall: 0.740000, fmeasure: 0.800272, val_loss: 0.534471, val_accuracy: 0.830000, val_precision: 0.882845, val_recall: 0.767143, val_fmeasure: 0.818832\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 0.4622 - accuracy: 0.8169 - precision: 0.8745 - recall: 0.7400 - fmeasure: 0.8003 - val_loss: 0.5345 - val_accuracy: 0.8300 - val_precision: 0.8828 - val_recall: 0.7671 - val_fmeasure: 0.8188\n",
      "Epoch 29/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.4348 - accuracy: 0.8393 - precision: 0.8979 - recall: 0.7631 - fmeasure: 0.8233src.model - INFO - {Epoch: 28} loss: 0.441278, accuracy: 0.838462, precision: 0.895093, recall: 0.765385, fmeasure: 0.823408, val_loss: 1.702501, val_accuracy: 0.804286, val_precision: 0.843594, val_recall: 0.765714, val_fmeasure: 0.801442\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 0.4413 - accuracy: 0.8385 - precision: 0.8951 - recall: 0.7654 - fmeasure: 0.8234 - val_loss: 1.7025 - val_accuracy: 0.8043 - val_precision: 0.8436 - val_recall: 0.7657 - val_fmeasure: 0.8014\n",
      "Epoch 30/67\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.5093 - accuracy: 0.8289 - precision: 0.8773 - recall: 0.7711 - fmeasure: 0.8196src.model - INFO - {Epoch: 29} loss: 0.511464, accuracy: 0.826154, precision: 0.876066, recall: 0.768461, fmeasure: 0.817582, val_loss: 0.487785, val_accuracy: 0.857143, val_precision: 0.901061, val_recall: 0.795714, val_fmeasure: 0.843094\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 0.5115 - accuracy: 0.8262 - precision: 0.8761 - recall: 0.7685 - fmeasure: 0.8176 - val_loss: 0.4878 - val_accuracy: 0.8571 - val_precision: 0.9011 - val_recall: 0.7957 - val_fmeasure: 0.8431\n",
      "Epoch 31/67\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.6401 - accuracy: 0.7954 - precision: 0.8431 - recall: 0.7023 - fmeasure: 0.7635src.model - INFO - {Epoch: 30} loss: 0.640072, accuracy: 0.795385, precision: 0.843106, recall: 0.702308, fmeasure: 0.763482, val_loss: 1.805632, val_accuracy: 0.822857, val_precision: 0.863024, val_recall: 0.764286, val_fmeasure: 0.808839\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 0.6401 - accuracy: 0.7954 - precision: 0.8431 - recall: 0.7023 - fmeasure: 0.7635 - val_loss: 1.8056 - val_accuracy: 0.8229 - val_precision: 0.8630 - val_recall: 0.7643 - val_fmeasure: 0.8088\n",
      "Epoch 32/67\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.6667 - accuracy: 0.7846 - precision: 0.8481 - recall: 0.7138 - fmeasure: 0.7730src.model - INFO - {Epoch: 31} loss: 0.666662, accuracy: 0.784615, precision: 0.848140, recall: 0.713846, fmeasure: 0.773041, val_loss: 0.433086, val_accuracy: 0.844286, val_precision: 0.887873, val_recall: 0.768571, val_fmeasure: 0.821422\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 0.6667 - accuracy: 0.7846 - precision: 0.8481 - recall: 0.7138 - fmeasure: 0.7730 - val_loss: 0.4331 - val_accuracy: 0.8443 - val_precision: 0.8879 - val_recall: 0.7686 - val_fmeasure: 0.8214\n",
      "Epoch 33/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.3893 - accuracy: 0.8533 - precision: 0.9080 - recall: 0.7918 - fmeasure: 0.8443src.model - INFO - {Epoch: 32} loss: 0.389132, accuracy: 0.851538, precision: 0.905792, recall: 0.791538, fmeasure: 0.843238, val_loss: 0.387313, val_accuracy: 0.881429, val_precision: 0.909982, val_recall: 0.830000, val_fmeasure: 0.866351\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.3891 - accuracy: 0.8515 - precision: 0.9058 - recall: 0.7915 - fmeasure: 0.8432 - val_loss: 0.3873 - val_accuracy: 0.8814 - val_precision: 0.9100 - val_recall: 0.8300 - val_fmeasure: 0.8664\n",
      "Epoch 34/67\n",
      "63/65 [============================>.] - ETA: 0s - loss: 0.3512 - accuracy: 0.8556 - precision: 0.8956 - recall: 0.8032 - fmeasure: 0.8461src.model - INFO - {Epoch: 33} loss: 0.349556, accuracy: 0.856154, precision: 0.895591, recall: 0.804615, fmeasure: 0.846847, val_loss: 0.380701, val_accuracy: 0.867143, val_precision: 0.881047, val_recall: 0.834286, val_fmeasure: 0.855906\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 0.3496 - accuracy: 0.8562 - precision: 0.8956 - recall: 0.8046 - fmeasure: 0.8468 - val_loss: 0.3807 - val_accuracy: 0.8671 - val_precision: 0.8810 - val_recall: 0.8343 - val_fmeasure: 0.8559\n",
      "Epoch 35/67\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.3258 - accuracy: 0.8615 - precision: 0.9119 - recall: 0.8200 - fmeasure: 0.8616src.model - INFO - {Epoch: 34} loss: 0.325841, accuracy: 0.861538, precision: 0.911916, recall: 0.820000, fmeasure: 0.861606, val_loss: 0.382633, val_accuracy: 0.892857, val_precision: 0.902276, val_recall: 0.854286, val_fmeasure: 0.876767\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 0.3258 - accuracy: 0.8615 - precision: 0.9119 - recall: 0.8200 - fmeasure: 0.8616 - val_loss: 0.3826 - val_accuracy: 0.8929 - val_precision: 0.9023 - val_recall: 0.8543 - val_fmeasure: 0.8768\n",
      "Epoch 36/67\n",
      "63/65 [============================>.] - ETA: 0s - loss: 0.2974 - accuracy: 0.8754 - precision: 0.9072 - recall: 0.8357 - fmeasure: 0.8690src.model - INFO - {Epoch: 35} loss: 0.295778, accuracy: 0.877692, precision: 0.908475, recall: 0.838462, fmeasure: 0.871085, val_loss: 0.394261, val_accuracy: 0.888571, val_precision: 0.902396, val_recall: 0.862857, val_fmeasure: 0.881170\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 0.2958 - accuracy: 0.8777 - precision: 0.9085 - recall: 0.8385 - fmeasure: 0.8711 - val_loss: 0.3943 - val_accuracy: 0.8886 - val_precision: 0.9024 - val_recall: 0.8629 - val_fmeasure: 0.8812\n",
      "Epoch 37/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.3104 - accuracy: 0.8738 - precision: 0.9007 - recall: 0.8320 - fmeasure: 0.8640src.model - INFO - {Epoch: 36} loss: 0.313031, accuracy: 0.873077, precision: 0.900725, recall: 0.830769, fmeasure: 0.863393, val_loss: 0.407755, val_accuracy: 0.861429, val_precision: 0.875353, val_recall: 0.840000, val_fmeasure: 0.856150\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 0.3130 - accuracy: 0.8731 - precision: 0.9007 - recall: 0.8308 - fmeasure: 0.8634 - val_loss: 0.4078 - val_accuracy: 0.8614 - val_precision: 0.8754 - val_recall: 0.8400 - val_fmeasure: 0.8562\n",
      "Epoch 38/67\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.3159 - accuracy: 0.8831 - precision: 0.9071 - recall: 0.8477 - fmeasure: 0.8754src.model - INFO - {Epoch: 37} loss: 0.315889, accuracy: 0.883077, precision: 0.907057, recall: 0.847692, fmeasure: 0.875449, val_loss: 0.370367, val_accuracy: 0.887143, val_precision: 0.902811, val_recall: 0.850000, val_fmeasure: 0.874364\n",
      "65/65 [==============================] - 1s 17ms/step - loss: 0.3159 - accuracy: 0.8831 - precision: 0.9071 - recall: 0.8477 - fmeasure: 0.8754 - val_loss: 0.3704 - val_accuracy: 0.8871 - val_precision: 0.9028 - val_recall: 0.8500 - val_fmeasure: 0.8744\n",
      "Epoch 39/67\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2929 - accuracy: 0.8823 - precision: 0.9140 - recall: 0.8423 - fmeasure: 0.8755src.model - INFO - {Epoch: 38} loss: 0.292854, accuracy: 0.882308, precision: 0.913996, recall: 0.842308, fmeasure: 0.875505, val_loss: 0.324232, val_accuracy: 0.884286, val_precision: 0.896380, val_recall: 0.864286, val_fmeasure: 0.879512\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 0.2929 - accuracy: 0.8823 - precision: 0.9140 - recall: 0.8423 - fmeasure: 0.8755 - val_loss: 0.3242 - val_accuracy: 0.8843 - val_precision: 0.8964 - val_recall: 0.8643 - val_fmeasure: 0.8795\n",
      "Epoch 40/67\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.3764 - accuracy: 0.8754 - precision: 0.9031 - recall: 0.8400 - fmeasure: 0.8695src.model - INFO - {Epoch: 39} loss: 0.376377, accuracy: 0.875385, precision: 0.903052, recall: 0.840000, fmeasure: 0.869461, val_loss: 0.651496, val_accuracy: 0.857143, val_precision: 0.867369, val_recall: 0.838571, val_fmeasure: 0.852139\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.3764 - accuracy: 0.8754 - precision: 0.9031 - recall: 0.8400 - fmeasure: 0.8695 - val_loss: 0.6515 - val_accuracy: 0.8571 - val_precision: 0.8674 - val_recall: 0.8386 - val_fmeasure: 0.8521\n",
      "Epoch 41/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.3238 - accuracy: 0.8762 - precision: 0.9005 - recall: 0.8344 - fmeasure: 0.8651src.model - INFO - {Epoch: 40} loss: 0.323698, accuracy: 0.875385, precision: 0.898834, recall: 0.831539, fmeasure: 0.862710, val_loss: 0.868342, val_accuracy: 0.894286, val_precision: 0.917031, val_recall: 0.867143, val_fmeasure: 0.890607\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 0.3237 - accuracy: 0.8754 - precision: 0.8988 - recall: 0.8315 - fmeasure: 0.8627 - val_loss: 0.8683 - val_accuracy: 0.8943 - val_precision: 0.9170 - val_recall: 0.8671 - val_fmeasure: 0.8906\n",
      "Epoch 42/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.3790 - accuracy: 0.8533 - precision: 0.8873 - recall: 0.8262 - fmeasure: 0.8545src.model - INFO - {Epoch: 41} loss: 0.393436, accuracy: 0.852308, precision: 0.885576, recall: 0.821539, fmeasure: 0.851169, val_loss: 1.054944, val_accuracy: 0.888571, val_precision: 0.913437, val_recall: 0.855714, val_fmeasure: 0.881951\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 0.3934 - accuracy: 0.8523 - precision: 0.8856 - recall: 0.8215 - fmeasure: 0.8512 - val_loss: 1.0549 - val_accuracy: 0.8886 - val_precision: 0.9134 - val_recall: 0.8557 - val_fmeasure: 0.8820\n",
      "Epoch 43/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.3390 - accuracy: 0.8656 - precision: 0.8927 - recall: 0.8320 - fmeasure: 0.8606src.model - INFO - {Epoch: 42} loss: 0.340791, accuracy: 0.866923, precision: 0.892851, recall: 0.832308, fmeasure: 0.860798, val_loss: 0.810805, val_accuracy: 0.854286, val_precision: 0.866009, val_recall: 0.835714, val_fmeasure: 0.850037\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 0.3408 - accuracy: 0.8669 - precision: 0.8929 - recall: 0.8323 - fmeasure: 0.8608 - val_loss: 0.8108 - val_accuracy: 0.8543 - val_precision: 0.8660 - val_recall: 0.8357 - val_fmeasure: 0.8500\n",
      "Epoch 44/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.4351 - accuracy: 0.8738 - precision: 0.9018 - recall: 0.8426 - fmeasure: 0.8704src.model - INFO - {Epoch: 43} loss: 0.419459, accuracy: 0.876923, precision: 0.904717, recall: 0.846154, fmeasure: 0.873686, val_loss: 0.796903, val_accuracy: 0.891429, val_precision: 0.911487, val_recall: 0.857143, val_fmeasure: 0.882362\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.4195 - accuracy: 0.8769 - precision: 0.9047 - recall: 0.8462 - fmeasure: 0.8737 - val_loss: 0.7969 - val_accuracy: 0.8914 - val_precision: 0.9115 - val_recall: 0.8571 - val_fmeasure: 0.8824\n",
      "Epoch 45/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.3331 - accuracy: 0.8795 - precision: 0.9035 - recall: 0.8385 - fmeasure: 0.8691src.model - INFO - {Epoch: 44} loss: 0.327930, accuracy: 0.883077, precision: 0.907004, recall: 0.843846, fmeasure: 0.873648, val_loss: 0.416677, val_accuracy: 0.907143, val_precision: 0.917100, val_recall: 0.892857, val_fmeasure: 0.904425\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.3279 - accuracy: 0.8831 - precision: 0.9070 - recall: 0.8438 - fmeasure: 0.8736 - val_loss: 0.4167 - val_accuracy: 0.9071 - val_precision: 0.9171 - val_recall: 0.8929 - val_fmeasure: 0.9044\n",
      "Epoch 46/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.2354 - accuracy: 0.9025 - precision: 0.9241 - recall: 0.8820 - fmeasure: 0.9022src.model - INFO - {Epoch: 45} loss: 0.234661, accuracy: 0.903846, precision: 0.924008, recall: 0.882308, fmeasure: 0.902322, val_loss: 0.344421, val_accuracy: 0.927143, val_precision: 0.933325, val_recall: 0.905714, val_fmeasure: 0.918782\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.2347 - accuracy: 0.9038 - precision: 0.9240 - recall: 0.8823 - fmeasure: 0.9023 - val_loss: 0.3444 - val_accuracy: 0.9271 - val_precision: 0.9333 - val_recall: 0.9057 - val_fmeasure: 0.9188\n",
      "Epoch 47/67\n",
      "62/65 [===========================>..] - ETA: 0s - loss: 0.2313 - accuracy: 0.9016 - precision: 0.9159 - recall: 0.8750 - fmeasure: 0.8944src.model - INFO - {Epoch: 46} loss: 0.228730, accuracy: 0.903846, precision: 0.918980, recall: 0.876923, fmeasure: 0.896905, val_loss: 0.363891, val_accuracy: 0.911429, val_precision: 0.912389, val_recall: 0.894286, val_fmeasure: 0.902994\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.2287 - accuracy: 0.9038 - precision: 0.9190 - recall: 0.8769 - fmeasure: 0.8969 - val_loss: 0.3639 - val_accuracy: 0.9114 - val_precision: 0.9124 - val_recall: 0.8943 - val_fmeasure: 0.9030\n",
      "Epoch 48/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.2437 - accuracy: 0.8984 - precision: 0.9182 - recall: 0.8746 - fmeasure: 0.8953src.model - INFO - {Epoch: 47} loss: 0.241881, accuracy: 0.900000, precision: 0.920198, recall: 0.877692, fmeasure: 0.897894, val_loss: 0.463224, val_accuracy: 0.917143, val_precision: 0.924412, val_recall: 0.904286, val_fmeasure: 0.913783\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.2419 - accuracy: 0.9000 - precision: 0.9202 - recall: 0.8777 - fmeasure: 0.8979 - val_loss: 0.4632 - val_accuracy: 0.9171 - val_precision: 0.9244 - val_recall: 0.9043 - val_fmeasure: 0.9138\n",
      "Epoch 49/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.2598 - accuracy: 0.8959 - precision: 0.9132 - recall: 0.8746 - fmeasure: 0.8930src.model - INFO - {Epoch: 48} loss: 0.252649, accuracy: 0.900000, precision: 0.916191, recall: 0.878462, fmeasure: 0.896507, val_loss: 0.349250, val_accuracy: 0.910000, val_precision: 0.920532, val_recall: 0.897143, val_fmeasure: 0.907980\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.2526 - accuracy: 0.9000 - precision: 0.9162 - recall: 0.8785 - fmeasure: 0.8965 - val_loss: 0.3492 - val_accuracy: 0.9100 - val_precision: 0.9205 - val_recall: 0.8971 - val_fmeasure: 0.9080\n",
      "Epoch 50/67\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2263 - accuracy: 0.9102 - precision: 0.9333 - recall: 0.8836 - fmeasure: 0.9070src.model - INFO - {Epoch: 49} loss: 0.227527, accuracy: 0.910000, precision: 0.932710, recall: 0.883077, fmeasure: 0.906459, val_loss: 0.405253, val_accuracy: 0.930000, val_precision: 0.932030, val_recall: 0.920000, val_fmeasure: 0.925822\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 0.2275 - accuracy: 0.9100 - precision: 0.9327 - recall: 0.8831 - fmeasure: 0.9065 - val_loss: 0.4053 - val_accuracy: 0.9300 - val_precision: 0.9320 - val_recall: 0.9200 - val_fmeasure: 0.9258\n",
      "Epoch 51/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.3286 - accuracy: 0.9082 - precision: 0.9309 - recall: 0.8852 - fmeasure: 0.9069src.model - INFO - {Epoch: 50} loss: 0.332714, accuracy: 0.901538, precision: 0.924347, recall: 0.878462, fmeasure: 0.900219, val_loss: 0.703236, val_accuracy: 0.914286, val_precision: 0.926767, val_recall: 0.900000, val_fmeasure: 0.912069\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.3327 - accuracy: 0.9015 - precision: 0.9243 - recall: 0.8785 - fmeasure: 0.9002 - val_loss: 0.7032 - val_accuracy: 0.9143 - val_precision: 0.9268 - val_recall: 0.9000 - val_fmeasure: 0.9121\n",
      "Epoch 52/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.3673 - accuracy: 0.8902 - precision: 0.9095 - recall: 0.8598 - fmeasure: 0.8834src.model - INFO - {Epoch: 51} loss: 0.364586, accuracy: 0.889231, precision: 0.908098, recall: 0.860000, fmeasure: 0.882820, val_loss: 0.655347, val_accuracy: 0.908571, val_precision: 0.920122, val_recall: 0.891429, val_fmeasure: 0.905120\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.3646 - accuracy: 0.8892 - precision: 0.9081 - recall: 0.8600 - fmeasure: 0.8828 - val_loss: 0.6553 - val_accuracy: 0.9086 - val_precision: 0.9201 - val_recall: 0.8914 - val_fmeasure: 0.9051\n",
      "Epoch 53/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.2043 - accuracy: 0.9148 - precision: 0.9370 - recall: 0.8984 - fmeasure: 0.9168src.model - INFO - {Epoch: 52} loss: 0.202857, accuracy: 0.916154, precision: 0.938472, recall: 0.899231, fmeasure: 0.917966, val_loss: 0.518612, val_accuracy: 0.928571, val_precision: 0.941496, val_recall: 0.915714, val_fmeasure: 0.927592\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.2029 - accuracy: 0.9162 - precision: 0.9385 - recall: 0.8992 - fmeasure: 0.9180 - val_loss: 0.5186 - val_accuracy: 0.9286 - val_precision: 0.9415 - val_recall: 0.9157 - val_fmeasure: 0.9276\n",
      "Epoch 54/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.1846 - accuracy: 0.9262 - precision: 0.9375 - recall: 0.9115 - fmeasure: 0.9239src.model - INFO - {Epoch: 53} loss: 0.191384, accuracy: 0.920769, precision: 0.934016, recall: 0.906154, fmeasure: 0.919473, val_loss: 0.509423, val_accuracy: 0.947143, val_precision: 0.955021, val_recall: 0.935714, val_fmeasure: 0.944629\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.1914 - accuracy: 0.9208 - precision: 0.9340 - recall: 0.9062 - fmeasure: 0.9195 - val_loss: 0.5094 - val_accuracy: 0.9471 - val_precision: 0.9550 - val_recall: 0.9357 - val_fmeasure: 0.9446\n",
      "Epoch 55/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.2013 - accuracy: 0.9189 - precision: 0.9286 - recall: 0.9066 - fmeasure: 0.9171src.model - INFO - {Epoch: 54} loss: 0.200211, accuracy: 0.920000, precision: 0.929883, recall: 0.908462, fmeasure: 0.918760, val_loss: 0.478818, val_accuracy: 0.931429, val_precision: 0.939014, val_recall: 0.925714, val_fmeasure: 0.932119\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.2002 - accuracy: 0.9200 - precision: 0.9299 - recall: 0.9085 - fmeasure: 0.9188 - val_loss: 0.4788 - val_accuracy: 0.9314 - val_precision: 0.9390 - val_recall: 0.9257 - val_fmeasure: 0.9321\n",
      "Epoch 56/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.1773 - accuracy: 0.9279 - precision: 0.9379 - recall: 0.9049 - fmeasure: 0.9208src.model - INFO - {Epoch: 55} loss: 0.177063, accuracy: 0.929231, precision: 0.938569, recall: 0.906923, fmeasure: 0.922166, val_loss: 0.573496, val_accuracy: 0.937143, val_precision: 0.943835, val_recall: 0.935714, val_fmeasure: 0.939670\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.1771 - accuracy: 0.9292 - precision: 0.9386 - recall: 0.9069 - fmeasure: 0.9222 - val_loss: 0.5735 - val_accuracy: 0.9371 - val_precision: 0.9438 - val_recall: 0.9357 - val_fmeasure: 0.9397\n",
      "Epoch 57/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.1835 - accuracy: 0.9238 - precision: 0.9319 - recall: 0.9066 - fmeasure: 0.9187src.model - INFO - {Epoch: 56} loss: 0.182514, accuracy: 0.923846, precision: 0.933728, recall: 0.907692, fmeasure: 0.920196, val_loss: 0.354773, val_accuracy: 0.942857, val_precision: 0.946617, val_recall: 0.935714, val_fmeasure: 0.940987\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.1825 - accuracy: 0.9238 - precision: 0.9337 - recall: 0.9077 - fmeasure: 0.9202 - val_loss: 0.3548 - val_accuracy: 0.9429 - val_precision: 0.9466 - val_recall: 0.9357 - val_fmeasure: 0.9410\n",
      "Epoch 58/67\n",
      "63/65 [============================>.] - ETA: 0s - loss: 0.3577 - accuracy: 0.9302 - precision: 0.9380 - recall: 0.9135 - fmeasure: 0.9253src.model - INFO - {Epoch: 57} loss: 0.359253, accuracy: 0.926923, precision: 0.935005, recall: 0.910000, fmeasure: 0.922029, val_loss: 0.604628, val_accuracy: 0.918571, val_precision: 0.931637, val_recall: 0.912857, val_fmeasure: 0.921857\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.3593 - accuracy: 0.9269 - precision: 0.9350 - recall: 0.9100 - fmeasure: 0.9220 - val_loss: 0.6046 - val_accuracy: 0.9186 - val_precision: 0.9316 - val_recall: 0.9129 - val_fmeasure: 0.9219\n",
      "Epoch 59/67\n",
      "60/65 [==========================>...] - ETA: 0s - loss: 0.2736 - accuracy: 0.9058 - precision: 0.9207 - recall: 0.8950 - fmeasure: 0.9074src.model - INFO - {Epoch: 58} loss: 0.268283, accuracy: 0.907692, precision: 0.922054, recall: 0.896923, fmeasure: 0.909012, val_loss: 0.541051, val_accuracy: 0.938571, val_precision: 0.945614, val_recall: 0.925714, val_fmeasure: 0.935300\n",
      "65/65 [==============================] - 1s 14ms/step - loss: 0.2683 - accuracy: 0.9077 - precision: 0.9221 - recall: 0.8969 - fmeasure: 0.9090 - val_loss: 0.5411 - val_accuracy: 0.9386 - val_precision: 0.9456 - val_recall: 0.9257 - val_fmeasure: 0.9353\n",
      "Epoch 60/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.5689 - accuracy: 0.9107 - precision: 0.9205 - recall: 0.8959 - fmeasure: 0.9077src.model - INFO - {Epoch: 59} loss: 0.557608, accuracy: 0.908462, precision: 0.919111, recall: 0.894615, fmeasure: 0.906338, val_loss: 0.718268, val_accuracy: 0.884286, val_precision: 0.900975, val_recall: 0.867143, val_fmeasure: 0.883109\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 0.5576 - accuracy: 0.9085 - precision: 0.9191 - recall: 0.8946 - fmeasure: 0.9063 - val_loss: 0.7183 - val_accuracy: 0.8843 - val_precision: 0.9010 - val_recall: 0.8671 - val_fmeasure: 0.8831\n",
      "Epoch 61/67\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.4109 - accuracy: 0.8891 - precision: 0.9089 - recall: 0.8648 - fmeasure: 0.8858src.model - INFO - {Epoch: 60} loss: 0.408959, accuracy: 0.890000, precision: 0.909438, recall: 0.864615, fmeasure: 0.885890, val_loss: 0.408076, val_accuracy: 0.911429, val_precision: 0.914662, val_recall: 0.905714, val_fmeasure: 0.910073\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 0.4090 - accuracy: 0.8900 - precision: 0.9094 - recall: 0.8646 - fmeasure: 0.8859 - val_loss: 0.4081 - val_accuracy: 0.9114 - val_precision: 0.9147 - val_recall: 0.9057 - val_fmeasure: 0.9101\n",
      "Epoch 62/67\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.3965 - accuracy: 0.8838 - precision: 0.9044 - recall: 0.8654 - fmeasure: 0.8838src.model - INFO - {Epoch: 61} loss: 0.396488, accuracy: 0.883846, precision: 0.904351, recall: 0.865385, fmeasure: 0.883847, val_loss: 0.620114, val_accuracy: 0.901429, val_precision: 0.904202, val_recall: 0.888572, val_fmeasure: 0.896150\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.3965 - accuracy: 0.8838 - precision: 0.9044 - recall: 0.8654 - fmeasure: 0.8838 - val_loss: 0.6201 - val_accuracy: 0.9014 - val_precision: 0.9042 - val_recall: 0.8886 - val_fmeasure: 0.8962\n",
      "Epoch 63/67\n",
      "62/65 [===========================>..] - ETA: 0s - loss: 0.2708 - accuracy: 0.9169 - precision: 0.9322 - recall: 0.8984 - fmeasure: 0.9146src.model - INFO - {Epoch: 62} loss: 0.275844, accuracy: 0.917692, precision: 0.932900, recall: 0.899231, fmeasure: 0.915375, val_loss: 0.696904, val_accuracy: 0.928571, val_precision: 0.941030, val_recall: 0.914286, val_fmeasure: 0.926814\n",
      "65/65 [==============================] - 1s 14ms/step - loss: 0.2758 - accuracy: 0.9177 - precision: 0.9329 - recall: 0.8992 - fmeasure: 0.9154 - val_loss: 0.6969 - val_accuracy: 0.9286 - val_precision: 0.9410 - val_recall: 0.9143 - val_fmeasure: 0.9268\n",
      "Epoch 64/67\n",
      "62/65 [===========================>..] - ETA: 0s - loss: 0.2060 - accuracy: 0.9274 - precision: 0.9360 - recall: 0.9161 - fmeasure: 0.9257src.model - INFO - {Epoch: 63} loss: 0.206761, accuracy: 0.926154, precision: 0.934966, recall: 0.913846, fmeasure: 0.923971, val_loss: 0.373426, val_accuracy: 0.934286, val_precision: 0.939624, val_recall: 0.934286, val_fmeasure: 0.936887\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.2068 - accuracy: 0.9262 - precision: 0.9350 - recall: 0.9138 - fmeasure: 0.9240 - val_loss: 0.3734 - val_accuracy: 0.9343 - val_precision: 0.9396 - val_recall: 0.9343 - val_fmeasure: 0.9369\n",
      "Epoch 65/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.1656 - accuracy: 0.9336 - precision: 0.9402 - recall: 0.9197 - fmeasure: 0.9295src.model - INFO - {Epoch: 64} loss: 0.167072, accuracy: 0.933846, precision: 0.940679, recall: 0.920769, fmeasure: 0.930335, val_loss: 0.390174, val_accuracy: 0.938571, val_precision: 0.948741, val_recall: 0.932857, val_fmeasure: 0.940366\n",
      "65/65 [==============================] - 1s 16ms/step - loss: 0.1671 - accuracy: 0.9338 - precision: 0.9407 - recall: 0.9208 - fmeasure: 0.9303 - val_loss: 0.3902 - val_accuracy: 0.9386 - val_precision: 0.9487 - val_recall: 0.9329 - val_fmeasure: 0.9404\n",
      "Epoch 66/67\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.1326 - accuracy: 0.9475 - precision: 0.9541 - recall: 0.9361 - fmeasure: 0.9448src.model - INFO - {Epoch: 65} loss: 0.133183, accuracy: 0.947692, precision: 0.953779, recall: 0.936154, fmeasure: 0.944664, val_loss: 0.416804, val_accuracy: 0.945714, val_precision: 0.948120, val_recall: 0.940000, val_fmeasure: 0.943918\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.1332 - accuracy: 0.9477 - precision: 0.9538 - recall: 0.9362 - fmeasure: 0.9447 - val_loss: 0.4168 - val_accuracy: 0.9457 - val_precision: 0.9481 - val_recall: 0.9400 - val_fmeasure: 0.9439\n",
      "Epoch 67/67\n",
      "63/65 [============================>.] - ETA: 0s - loss: 0.1860 - accuracy: 0.9437 - precision: 0.9493 - recall: 0.9325 - fmeasure: 0.9406src.model - INFO - {Epoch: 66} loss: 0.183896, accuracy: 0.943846, precision: 0.949348, recall: 0.933077, fmeasure: 0.940899, val_loss: 0.428588, val_accuracy: 0.944286, val_precision: 0.948346, val_recall: 0.942857, val_fmeasure: 0.945531\n",
      "65/65 [==============================] - 1s 15ms/step - loss: 0.1839 - accuracy: 0.9438 - precision: 0.9493 - recall: 0.9331 - fmeasure: 0.9409 - val_loss: 0.4286 - val_accuracy: 0.9443 - val_precision: 0.9483 - val_recall: 0.9429 - val_fmeasure: 0.9455\n",
      "src.model - INFO - Training completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test, y_test = features_target_split(test_data_guitar)\n",
    "X_train, y_train = features_target_split(train_data_guitar)\n",
    "\n",
    "\n",
    "X_train, X_test = reshape_feature_CNN(X_train, size=most_shape[1]), reshape_feature_CNN(X_test, size=most_shape[1])\n",
    "\n",
    "y_test_values = y_test.copy()\n",
    "\n",
    "y_train, y_test = one_hot_encode(y_train), one_hot_encode(y_test)\n",
    "baseline.train(X_train, y_train, X_test, y_test, epochs=67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.model - INFO - Saving model\n",
      "src.model - INFO - Saved model to /home/tzag/danigil/dl/guitarCR/models\n"
     ]
    }
   ],
   "source": [
    "baseline.save_model('baseline_latest_128_213')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 1300\n",
      "src.processing - INFO - Number of testing samples is 700\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0\n",
      "src.processing - INFO - Number of training samples is 0\n",
      "src.processing - INFO - Number of testing samples is 100\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0\n",
      "src.processing - INFO - Number of training samples is 0\n",
      "src.processing - INFO - Number of testing samples is 100\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0\n",
      "src.processing - INFO - Number of training samples is 0\n",
      "src.processing - INFO - Number of testing samples is 100\n",
      "src.processing - INFO - Train test split completed\n"
     ]
    }
   ],
   "source": [
    "train_data_guitar, test_data_guitar = train_test_split(datasets_raw[0], augmented=False, split_ratio=0.65)\n",
    "test_datas = []\n",
    "test_datas.append(test_data_guitar)\n",
    "\n",
    "for i, dataset in enumerate(datasets_raw):\n",
    "    if i == 0:\n",
    "        continue\n",
    "\n",
    "    _, test_data = train_test_split(dataset, augmented=False, split_ratio=0)\n",
    "    test_datas.append(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 8ms/step - loss: 0.4286 - accuracy: 0.9443 - precision: 0.9481 - recall: 0.9428 - fmeasure: 0.9454\n",
      "Test score for instrument: Guitar\n",
      "\tTest loss: 0.42860978841781616\n",
      "\tTest accuracy: 0.9442856907844543\n",
      "\tTest precision: 0.9481370449066162\n",
      "\tTest recall: 0.9427759647369385\n",
      "\tTest f1-score: 0.9454139471054077\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 265.3678 - accuracy: 0.4300 - precision: 0.3924 - recall: 0.3906 - fmeasure: 0.3915\n",
      "Test score for instrument: Accordion\n",
      "\tTest loss: 265.3677978515625\n",
      "\tTest accuracy: 0.4300000071525574\n",
      "\tTest precision: 0.39238911867141724\n",
      "\tTest recall: 0.390625\n",
      "\tTest f1-score: 0.391493022441864\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 71.8601 - accuracy: 0.3500 - precision: 0.2734 - recall: 0.2734 - fmeasure: 0.2734\n",
      "Test score for instrument: Violin\n",
      "\tTest loss: 71.860107421875\n",
      "\tTest accuracy: 0.3499999940395355\n",
      "\tTest precision: 0.2734375\n",
      "\tTest recall: 0.2734375\n",
      "\tTest f1-score: 0.2734374701976776\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9.5194 - accuracy: 0.3200 - precision: 0.2549 - recall: 0.2344 - fmeasure: 0.2440\n",
      "Test score for instrument: Piano\n",
      "\tTest loss: 9.519414901733398\n",
      "\tTest accuracy: 0.3199999928474426\n",
      "\tTest precision: 0.25489628314971924\n",
      "\tTest recall: 0.234375\n",
      "\tTest f1-score: 0.24404756724834442\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test_instruments = instruments\n",
    "for test_data, instrument in zip(test_datas, test_instruments):\n",
    "    X_test = test_data['spectrogram']\n",
    "    X_test = np.array([x.reshape( (128, most_shape[1], 1) ) for x in X_test])\n",
    "    y_test = test_data['class_ID']\n",
    "\n",
    "    y_test_values=y_test\n",
    "    y_test = np.array(keras.utils.to_categorical(y_test, 10))\n",
    "\n",
    "    score = baseline.model.evaluate(X_test,y_test)\n",
    "    print(f'Test score for instrument: {instrument}')\n",
    "    print('\\tTest loss:', score[0])\n",
    "    print('\\tTest accuracy:', score[1])\n",
    "    print('\\tTest precision:', score[2])\n",
    "    print('\\tTest recall:', score[3])\n",
    "    print('\\tTest f1-score:', score[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 17ms/step - loss: 62.1479 - accuracy: 0.3600 - precision: 0.4453 - recall: 0.4453 - fmeasure: 0.4453\n",
      "Piano Test accuracy: 0.36000001430511475\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 17.3487 - accuracy: 0.4667 - precision: 0.4710 - recall: 0.4710 - fmeasure: 0.4710\n",
      "Guitar Test accuracy: 0.46666666865348816\n"
     ]
    }
   ],
   "source": [
    "dataset_piano = pd.read_pickle(os.path.join(METADATA_DIR_RAW_OOD, 'data_piano.pkl'))\n",
    "dataset_guitar = pd.read_pickle(os.path.join(METADATA_DIR_RAW_OOD, 'data_guitar.pkl'))\n",
    "size=213\n",
    "dataset_piano['spectrogram'] = dataset_piano['spectrogram'].apply(lambda x: np.pad(x, ((0, 0), (0, size-x.shape[1])), 'constant'))\n",
    "dataset_guitar['spectrogram'] = dataset_guitar['spectrogram'].apply(lambda x: np.pad(x, ((0, 0), (0, size-x.shape[1])), 'constant'))\n",
    "\n",
    "test_data = dataset_piano\n",
    "\n",
    "X_test = test_data['spectrogram']\n",
    "X_test = np.array([np.pad(x, ((0, 0), (0, size-x.shape[1])), 'constant') for x in dataset_piano['spectrogram']])\n",
    "y_test = test_data['class_ID']\n",
    "\n",
    "X_test = np.array([x.reshape( (128, size, 1) ) for x in X_test])\n",
    "\n",
    "y_test_values=y_test\n",
    "y_test = np.array(keras.utils.to_categorical(y_test, 10))\n",
    "\n",
    "score = baseline.model.evaluate(\n",
    "\tx=X_test,\n",
    "\ty=y_test)\n",
    "\n",
    "print('Piano Test accuracy:', score[1])\n",
    "\n",
    "test_data = dataset_guitar\n",
    "\n",
    "X_test = test_data['spectrogram']\n",
    "X_test = np.array([np.pad(x, ((0, 0), (0, size-x.shape[1])), 'constant') for x in dataset_guitar['spectrogram']])\n",
    "y_test = test_data['class_ID']\n",
    "\n",
    "X_test = np.array([x.reshape( (128, size, 1) ) for x in X_test])\n",
    "\n",
    "y_test_values=y_test\n",
    "y_test = np.array(keras.utils.to_categorical(y_test, 10))\n",
    "\n",
    "score = baseline.model.evaluate(\n",
    "\tx=X_test,\n",
    "\ty=y_test)\n",
    "\n",
    "print('Guitar Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~xylophone~~~~~~~~~~~~~~~~~~~\n",
      "#EXP | ACCURACY | RECALL | PRECISION | F1-SCORE\n",
      "BASELINE | 0.000000 | 0.0000 | 0.0000000 | 0.000000\n",
      "~~~~~~~~~~~~~~~~~~~clarinet~~~~~~~~~~~~~~~~~~~\n",
      "#EXP | ACCURACY | RECALL | PRECISION | F1-SCORE\n",
      "BASELINE | 0.100000 | 0.1000 | 0.0333333 | 0.050000\n",
      "~~~~~~~~~~~~~~~~~~~~trumpet~~~~~~~~~~~~~~~~~~~~\n",
      "#EXP | ACCURACY | RECALL | PRECISION | F1-SCORE\n",
      "BASELINE | 0.200000 | 0.2000 | 0.0750000 | 0.106667\n",
      "~~~~~~~~~~~~~~~~~~~~~oboe~~~~~~~~~~~~~~~~~~~~~\n",
      "#EXP | ACCURACY | RECALL | PRECISION | F1-SCORE\n",
      "BASELINE | 0.300000 | 0.3000 | 0.1666667 | 0.195238\n",
      "~~~~~~~~~~~~~~~~~~~~~harp~~~~~~~~~~~~~~~~~~~~~\n",
      "#EXP | ACCURACY | RECALL | PRECISION | F1-SCORE\n",
      "BASELINE | 0.100000 | 0.1000 | 0.0200000 | 0.033333\n",
      "~~~~~~~~~~~~~~~~~tubular_bells~~~~~~~~~~~~~~~~~\n",
      "#EXP | ACCURACY | RECALL | PRECISION | F1-SCORE\n",
      "BASELINE | 0.000000 | 0.0000 | 0.0000000 | 0.000000\n",
      "~~~~~~~~~~~~~~~~~~~~~horn~~~~~~~~~~~~~~~~~~~~~\n",
      "#EXP | ACCURACY | RECALL | PRECISION | F1-SCORE\n",
      "BASELINE | 0.200000 | 0.2000 | 0.0583333 | 0.090000\n",
      "~~~~~~~~~~~~~~~~~~~~~flute~~~~~~~~~~~~~~~~~~~~~\n",
      "#EXP | ACCURACY | RECALL | PRECISION | F1-SCORE\n",
      "BASELINE | 0.000000 | 0.0000 | 0.0000000 | 0.000000\n"
     ]
    }
   ],
   "source": [
    "y_pred = {}\n",
    "y_true = {}\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ood2_path = './../data/audio/myood2/splits'\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for instrument in os.listdir(ood2_path):\n",
    "    y_pred[instrument] = []\n",
    "    # y_pred_3[instrument] = []\n",
    "    y_true[instrument] = []\n",
    "\n",
    "    for chord in os.listdir(os.path.join(ood2_path, instrument)):\n",
    "\n",
    "        #true = file.split('-')[-1][:1]\n",
    "        true = chord.replace('.wav','')\n",
    "        assert true in CLASSES\n",
    "        y_true[instrument].append(true)\n",
    "\n",
    "        curr_path = os.path.join(ood2_path, instrument, chord)\n",
    "        y, sr = librosa.load(curr_path, sr=44100, duration=2)\n",
    "\n",
    "        spectrogram = librosa.feature.melspectrogram(y=y,sr=sr, n_mels=128)\n",
    "        #spectrogram = librosa.util.normalize(np.log(librosa.feature.melspectrogram(y=y,sr=sr, n_mels=128) + 1e-9))\n",
    "        spectrogram = np.pad(spectrogram, ((0, 0), (0, most_shape[1]-spectrogram.shape[1])), 'constant')\n",
    "        spectrogram = spectrogram.reshape((1,)+most_shape+(1,))\n",
    "\n",
    "        predict_x=baseline.model.predict(spectrogram, batch_size=1, verbose=0)\n",
    "        predictions = np.argmax(predict_x,axis=1)\n",
    "        pred = CLASSES[predictions[0]]\n",
    "        y_pred[instrument].append(pred)\n",
    "        \n",
    "        # predict_x_3=experiment3.model.predict(spectrogram, batch_size=1, verbose=0)\n",
    "        # predictions_3 = np.argmax(predict_x_3,axis=1)\n",
    "        # pred_3 = CLASSES[predictions_3[0]]\n",
    "        # y_pred_3[instrument].append(pred_3)\n",
    "\n",
    "    slen = int((len('#EXP | ACCURACY | RECALL | PRECISION | F1-SCORE') - len(instrument))/2)\n",
    "    print(f\"{'~'*slen}{instrument}{'~'*slen}\")\n",
    "    print(f'#EXP | ACCURACY | RECALL | PRECISION | F1-SCORE')\n",
    "    print(f\"\"\"BASELINE | {'{:.6f}'.format(accuracy_score(y_true[instrument], y_pred[instrument]))} | {'{:.4f}'.format(recall_score(y_true[instrument], y_pred[instrument], average='macro'))} | {'{:.7f}'.format(precision_score(y_true[instrument], y_pred[instrument], average='macro'))} | {'{:.6f}'.format(f1_score(y_true[instrument], y_pred[instrument], average='macro'))}\"\"\")\n",
    "    # print(f\"\"\"EXP3 | {'{:.6f}'.format(accuracy_score(y_true[instrument], y_pred_3[instrument]))} | {'{:.4f}'.format(recall_score(y_true[instrument], y_pred_3[instrument], average='macro'))} | {'{:.7f}'.format(precision_score(y_true[instrument], y_pred_3[instrument], average='macro'))} | {'{:.6f}'.format(f1_score(y_true[instrument], y_pred_3[instrument], average='macro'))}\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "danigil-steganalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
