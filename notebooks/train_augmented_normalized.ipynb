{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import pandas as pd\n",
    "from src.metrics import *\n",
    "from settings import *\n",
    "from src.data import generate\n",
    "\n",
    "instruments = ['Guitar']\n",
    "instruments_aug = ['Accordion', 'Violin', 'Piano']\n",
    "\n",
    "# from setup_logging import setup_logging\n",
    "# setup_logging()\n",
    "\n",
    "#generate.my_run(instruments)\n",
    "datasets_raw = [pd.read_pickle(os.path.join(METADATA_DIR_PROCESSED_NORMALIZED, f'data_{instrument.lower()}.pkl')) for instrument in instruments]\n",
    "datasets_augmented = [pd.read_pickle(os.path.join(METADATA_DIR_AUGMENTED_RAW_NORMALIZED, f'data_{instrument.lower()}.pkl')) for instrument in instruments_aug]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(128, 64), (128, 70), (128, 79), (128, 81), (128, 66), (128, 77), (128, 74), (128, 63), (128, 55), (128, 69), (128, 58), (128, 77), (128, 87), (128, 66), (128, 70), (128, 37), (128, 70), (128, 87), (128, 22), (128, 78), (128, 72), (128, 29), (128, 87), (128, 79), (128, 84), (128, 51), (128, 87), (128, 87), (128, 87), (128, 87), (128, 59), (128, 49), (128, 71), (128, 78), (128, 57), (128, 84), (128, 73), (128, 65), (128, 72), (128, 63), (128, 87), (128, 84), (128, 69), (128, 80), (128, 87), (128, 87), (128, 87), (128, 42), (128, 75), (128, 87), (128, 87), (128, 87), (128, 51), (128, 87), (128, 73), (128, 87), (128, 87), (128, 87), (128, 49), (128, 43), (128, 87), (128, 81), (128, 79), (128, 66), (128, 48), (128, 87), (128, 87), (128, 78), (128, 87), (128, 87), (128, 27), (128, 77), (128, 55), (128, 87), (128, 87), (128, 87), (128, 71), (128, 70), (128, 56), (128, 66), (128, 87), (128, 78), (128, 87), (128, 61), (128, 70), (128, 76), (128, 82), (128, 28), (128, 60), (128, 87), (128, 53), (128, 49), (128, 51), (128, 49), (128, 52), (128, 62), (128, 52), (128, 50), (128, 80), (128, 42), (128, 64), (128, 70), (128, 79), (128, 81), (128, 66), (128, 77), (128, 74), (128, 63), (128, 55), (128, 69), (128, 58), (128, 77), (128, 87), (128, 66), (128, 70), (128, 37), (128, 70), (128, 87), (128, 22), (128, 78), (128, 72), (128, 29), (128, 87), (128, 79), (128, 84), (128, 51), (128, 87), (128, 87), (128, 87), (128, 87), (128, 59), (128, 49), (128, 71), (128, 78), (128, 57), (128, 84), (128, 73), (128, 65), (128, 72), (128, 63), (128, 87), (128, 84), (128, 69), (128, 80), (128, 87), (128, 87), (128, 87), (128, 42), (128, 75), (128, 87), (128, 87), (128, 87), (128, 51), (128, 87), (128, 73), (128, 87), (128, 87), (128, 87), (128, 49), (128, 43), (128, 87), (128, 81), (128, 79), (128, 66), (128, 48), (128, 87), (128, 87), (128, 78), (128, 87), (128, 87), (128, 27), (128, 77), (128, 55), (128, 87), (128, 87), (128, 87), (128, 71), (128, 70), (128, 56), (128, 66), (128, 87), (128, 78), (128, 87), (128, 61), (128, 70), (128, 76), (128, 82), (128, 28), (128, 60), (128, 87), (128, 53), (128, 49), (128, 51), (128, 49), (128, 52), (128, 62), (128, 52), (128, 50), (128, 80), (128, 42), (128, 60), (128, 65), (128, 73), (128, 76), (128, 61), (128, 72), (128, 69), (128, 58), (128, 51), (128, 65), (128, 54), (128, 72), (128, 81), (128, 61), (128, 65), (128, 35), (128, 65), (128, 81), (128, 21), (128, 73), (128, 67), (128, 27), (128, 81), (128, 74), (128, 78), (128, 47), (128, 81), (128, 81), (128, 81), (128, 81), (128, 55), (128, 46), (128, 66), (128, 73), (128, 53), (128, 78), (128, 68), (128, 60), (128, 67), (128, 59), (128, 81), (128, 79), (128, 64), (128, 75), (128, 81), (128, 81), (128, 81), (128, 39), (128, 70), (128, 81), (128, 81), (128, 81), (128, 47), (128, 81), (128, 68), (128, 81), (128, 81), (128, 81), (128, 46), (128, 40), (128, 81), (128, 75), (128, 73), (128, 61), (128, 44), (128, 81), (128, 81), (128, 73), (128, 81), (128, 81), (128, 25), (128, 72), (128, 51), (128, 81), (128, 81), (128, 81), (128, 66), (128, 65), (128, 52), (128, 62), (128, 81), (128, 72), (128, 81), (128, 57), (128, 65), (128, 71), (128, 76), (128, 26), (128, 56), (128, 81), (128, 50), (128, 46), (128, 47), (128, 45), (128, 48), (128, 58), (128, 48), (128, 46), (128, 74), (128, 39), (128, 79), (128, 86), (128, 97), (128, 100), (128, 81), (128, 95), (128, 91), (128, 77), (128, 67), (128, 85), (128, 71), (128, 95), (128, 107), (128, 81), (128, 86), (128, 46), (128, 86), (128, 107), (128, 27), (128, 96), (128, 89), (128, 35), (128, 107), (128, 98), (128, 103), (128, 62), (128, 107), (128, 107), (128, 107), (128, 107), (128, 72), (128, 60), (128, 88), (128, 96), (128, 70), (128, 103), (128, 90), (128, 80), (128, 89), (128, 78), (128, 107), (128, 104), (128, 84), (128, 99), (128, 107), (128, 107), (128, 107), (128, 52), (128, 92), (128, 107), (128, 107), (128, 107), (128, 62), (128, 107), (128, 90), (128, 107), (128, 107), (128, 107), (128, 60), (128, 53), (128, 107), (128, 99), (128, 97), (128, 81), (128, 59), (128, 107), (128, 107), (128, 96), (128, 107), (128, 107), (128, 33), (128, 95), (128, 67), (128, 107), (128, 107), (128, 107), (128, 88), (128, 86), (128, 68), (128, 81), (128, 107), (128, 96), (128, 107), (128, 75), (128, 86), (128, 93), (128, 101), (128, 34), (128, 73), (128, 107), (128, 65), (128, 60), (128, 62), (128, 60), (128, 63), (128, 76), (128, 63), (128, 61), (128, 98), (128, 52), (128, 64), (128, 70), (128, 79), (128, 81), (128, 66), (128, 77), (128, 74), (128, 63), (128, 55), (128, 69), (128, 58), (128, 77), (128, 87), (128, 66), (128, 70), (128, 37), (128, 70), (128, 87), (128, 22), (128, 78), (128, 72), (128, 29), (128, 87), (128, 79), (128, 84), (128, 51), (128, 87), (128, 87), (128, 87), (128, 87), (128, 59), (128, 49), (128, 71), (128, 78), (128, 57), (128, 84), (128, 73), (128, 65), (128, 72), (128, 63), (128, 87), (128, 84), (128, 69), (128, 80), (128, 87), (128, 87), (128, 87), (128, 42), (128, 75), (128, 87), (128, 87), (128, 87), (128, 51), (128, 87), (128, 73), (128, 87), (128, 87), (128, 87), (128, 49), (128, 43), (128, 87), (128, 81), (128, 79), (128, 66), (128, 48), (128, 87), (128, 87), (128, 78), (128, 87), (128, 87), (128, 27), (128, 77), (128, 55), (128, 87), (128, 87), (128, 87), (128, 71), (128, 70), (128, 56), (128, 66), (128, 87), (128, 78), (128, 87), (128, 61), (128, 70), (128, 76), (128, 82), (128, 28), (128, 60), (128, 87), (128, 53), (128, 49), (128, 51), (128, 49), (128, 52), (128, 62), (128, 52), (128, 50), (128, 80), (128, 42), (128, 64), (128, 70), (128, 79), (128, 81), (128, 66), (128, 77), (128, 74), (128, 63), (128, 55), (128, 69), (128, 58), (128, 77), (128, 87), (128, 66), (128, 70), (128, 37), (128, 70), (128, 87), (128, 22), (128, 78), (128, 72), (128, 29), (128, 87), (128, 79), (128, 84), (128, 51), (128, 87), (128, 87), (128, 87), (128, 87), (128, 59), (128, 49), (128, 71), (128, 78), (128, 57), (128, 84), (128, 73), (128, 65), (128, 72), (128, 63), (128, 87), (128, 84), (128, 69), (128, 80), (128, 87), (128, 87), (128, 87), (128, 42), (128, 75), (128, 87), (128, 87), (128, 87), (128, 51), (128, 87), (128, 73), (128, 87), (128, 87), (128, 87), (128, 49), (128, 43), (128, 87), (128, 81), (128, 79), (128, 66), (128, 48), (128, 87), (128, 87), (128, 78), (128, 87), (128, 87), (128, 27), (128, 77), (128, 55), (128, 87), (128, 87), (128, 87), (128, 71), (128, 70), (128, 56), (128, 66), (128, 87), (128, 78), (128, 87), (128, 61), (128, 70), (128, 76), (128, 82), (128, 28), (128, 60), (128, 87), (128, 53), (128, 49), (128, 51), (128, 49), (128, 52), (128, 62), (128, 52), (128, 50), (128, 80), (128, 42), (128, 64), (128, 70), (128, 79), (128, 81), (128, 66), (128, 77), (128, 74), (128, 63), (128, 55), (128, 69), (128, 58), (128, 77), (128, 87), (128, 66), (128, 70), (128, 37), (128, 70), (128, 87), (128, 22), (128, 78), (128, 72), (128, 29), (128, 87), (128, 79), (128, 84), (128, 51), (128, 87), (128, 87), (128, 87), (128, 87), (128, 59), (128, 49), (128, 71), (128, 78), (128, 57), (128, 84), (128, 73), (128, 65), (128, 72), (128, 63), (128, 87), (128, 84), (128, 69), (128, 80), (128, 87), (128, 87), (128, 87), (128, 42), (128, 75), (128, 87), (128, 87), (128, 87), (128, 51), (128, 87), (128, 73), (128, 87), (128, 87), (128, 87), (128, 49), (128, 43), (128, 87), (128, 81), (128, 79), (128, 66), (128, 48), (128, 87), (128, 87), (128, 78), (128, 87), (128, 87), (128, 27), (128, 77), (128, 55), (128, 87), (128, 87), (128, 87), (128, 71), (128, 70), (128, 56), (128, 66), (128, 87), (128, 78), (128, 87), (128, 61), (128, 70), (128, 76), (128, 82), (128, 28), (128, 60), (128, 87), (128, 53), (128, 49), (128, 51), (128, 49), (128, 52), (128, 62), (128, 52), (128, 50), (128, 80), (128, 42), (128, 64), (128, 70), (128, 79), (128, 81), (128, 66), (128, 77), (128, 74), (128, 63), (128, 55), (128, 69), (128, 58), (128, 77), (128, 87), (128, 66), (128, 70), (128, 37), (128, 70), (128, 87), (128, 22), (128, 78), (128, 72), (128, 29), (128, 87), (128, 79), (128, 84), (128, 51), (128, 87), (128, 87), (128, 87), (128, 87), (128, 59), (128, 49), (128, 71), (128, 78), (128, 57), (128, 84), (128, 73), (128, 65), (128, 72), (128, 63), (128, 87), (128, 84), (128, 69), (128, 80), (128, 87), (128, 87), (128, 87), (128, 42), (128, 75), (128, 87), (128, 87), (128, 87), (128, 51), (128, 87), (128, 73), (128, 87), (128, 87), (128, 87), (128, 49), (128, 43), (128, 87), (128, 81), (128, 79), (128, 66), (128, 48), (128, 87), (128, 87), (128, 78), (128, 87), (128, 87), (128, 27), (128, 77), (128, 55), (128, 87), (128, 87), (128, 87), (128, 71), (128, 70), (128, 56), (128, 66), (128, 87), (128, 78), (128, 87), (128, 61), (128, 70), (128, 76), (128, 82), (128, 28), (128, 60), (128, 87), (128, 53), (128, 49), (128, 51), (128, 49), (128, 52), (128, 62), (128, 52), (128, 50), (128, 80), (128, 42), (128, 64), (128, 70), (128, 79), (128, 81), (128, 66), (128, 77), (128, 74), (128, 63), (128, 55), (128, 69), (128, 58), (128, 77), (128, 87), (128, 66), (128, 70), (128, 37), (128, 70), (128, 87), (128, 22), (128, 78), (128, 72), (128, 29), (128, 87), (128, 79), (128, 84), (128, 51), (128, 87), (128, 87), (128, 87), (128, 87), (128, 59), (128, 49), (128, 71), (128, 78), (128, 57), (128, 84), (128, 73), (128, 65), (128, 72), (128, 63), (128, 87), (128, 84), (128, 69), (128, 80), (128, 87), (128, 87), (128, 87), (128, 42), (128, 75), (128, 87), (128, 87), (128, 87), (128, 51), (128, 87), (128, 73), (128, 87), (128, 87), (128, 87), (128, 49), (128, 43), (128, 87), (128, 81), (128, 79), (128, 66), (128, 48), (128, 87), (128, 87), (128, 78), (128, 87), (128, 87), (128, 27), (128, 77), (128, 55), (128, 87), (128, 87), (128, 87), (128, 71), (128, 70), (128, 56), (128, 66), (128, 87), (128, 78), (128, 87), (128, 61), (128, 70), (128, 76), (128, 82), (128, 28), (128, 60), (128, 87), (128, 53), (128, 49), (128, 51), (128, 49), (128, 52), (128, 62), (128, 52), (128, 50), (128, 80), (128, 42)]\n"
     ]
    }
   ],
   "source": [
    "print([x.shape for x in datasets_augmented[0]['spectrogram']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data.preprocessing import get_max_shape\n",
    "max_spectrogram_size = max(map(lambda df: get_max_shape(df), datasets_raw+datasets_augmented))\n",
    "max_spectrogram_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.preprocessing import uniform_shape\n",
    "uniform = lambda df: uniform_shape(df, max_spectrogram_size)\n",
    "\n",
    "datasets_raw = list(map(uniform,datasets_raw))\n",
    "\n",
    "datasets_augmented = list(map(uniform,datasets_augmented))\n",
    "datasets_augmented = list(map(lambda df: df[['spectrogram','class_ID', 'class_name','augmentation']],datasets_augmented))\n",
    "datasets_augmented = list(map(lambda df: df.reset_index(drop=True), datasets_augmented))\n",
    "datasets_augmented = list(map(lambda df: df[~df['augmentation'].isin(['pitch_250', 'pitch_200'])].reset_index(drop=True),datasets_augmented))\n",
    "\n",
    "#datasets_augmented = list(map(lambda df: df[['spectrogram','class_ID', 'class_name','augmentation']],map(uniform,datasets_augmented)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 107)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data.preprocessing import all_equal\n",
    "#equal_shape = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 1300\n",
      "src.processing - INFO - Number of testing samples is 700\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 455\n",
      "src.processing - INFO - Number of testing samples is 245\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 455\n",
      "src.processing - INFO - Number of testing samples is 245\n",
      "src.processing - INFO - Train test split completed\n",
      "src.processing - INFO - Start train test split with split ratio: 0.65\n",
      "src.processing - INFO - Number of training samples is 455\n",
      "src.processing - INFO - Number of testing samples is 245\n",
      "src.processing - INFO - Train test split completed\n",
      "The most frequent shape is (128, 213)\n",
      "src.train - INFO - Number of train samples: 2665\n",
      "src.train - INFO - Number of test samples: 1435\n",
      "src.processing - INFO - Start feature target split\n",
      "src.processing - INFO - Feature target split completed\n",
      "src.processing - INFO - Start feature target split\n",
      "src.processing - INFO - Feature target split completed\n",
      "src.processing - INFO - Features reshaped for CNN Input\n",
      "src.processing - INFO - Features reshaped for CNN Input\n",
      "src.processing - INFO - Target one hot encoded\n",
      "src.processing - INFO - Target one hot encoded\n",
      "src.model - INFO - Initializing CNN\n",
      "src.model - INFO - Input shape = (128, 213, 1)\n",
      "src.model - INFO - CNN Initialized\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 124, 209, 24)      624       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 31, 104, 24)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 31, 104, 24)       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 27, 100, 48)       28848     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 50, 48)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 6, 50, 48)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 2, 46, 48)         57648     \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 2, 46, 48)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 4416)              0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4416)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                282688    \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 370,458\n",
      "Trainable params: 370,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "src.train - INFO - None\n",
      "src.model - INFO - Start training model\n",
      "src.model - INFO - Tensorboard Logging Started\n",
      "src.model - INFO - Use the following command in the terminal to view the logs during training: tensorboard --logdir logs/training\n",
      "Epoch 1/15\n",
      "130/134 [============================>.] - ETA: 0s - loss: 2.3009 - accuracy: 0.1104 - precision: 0.0000e+00 - recall: 0.0000e+00 - fmeasure: 0.0000e+00src.model - INFO - {Epoch: 0} loss: 2.300553, accuracy: 0.110319, precision: 0.000000, recall: 0.000000, fmeasure: 0.000000, val_loss: 2.300432, val_accuracy: 0.088502, val_precision: 0.000000, val_recall: 0.000000, val_fmeasure: 0.000000\n",
      "134/134 [==============================] - 4s 18ms/step - loss: 2.3006 - accuracy: 0.1103 - precision: 0.0000e+00 - recall: 0.0000e+00 - fmeasure: 0.0000e+00 - val_loss: 2.3004 - val_accuracy: 0.0885 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fmeasure: 0.0000e+00\n",
      "Epoch 2/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 2.2840 - accuracy: 0.1363 - precision: 0.0000e+00 - recall: 0.0000e+00 - fmeasure: 0.0000e+00src.model - INFO - {Epoch: 1} loss: 2.281610, accuracy: 0.138086, precision: 0.000000, recall: 0.000000, fmeasure: 0.000000, val_loss: 2.225840, val_accuracy: 0.181185, val_precision: 0.000000, val_recall: 0.000000, val_fmeasure: 0.000000\n",
      "134/134 [==============================] - 2s 15ms/step - loss: 2.2816 - accuracy: 0.1381 - precision: 0.0000e+00 - recall: 0.0000e+00 - fmeasure: 0.0000e+00 - val_loss: 2.2258 - val_accuracy: 0.1812 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_fmeasure: 0.0000e+00\n",
      "Epoch 3/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 1.8375 - accuracy: 0.3370 - precision: 0.6147 - recall: 0.1252 - fmeasure: 0.1961src.model - INFO - {Epoch: 2} loss: 1.829428, accuracy: 0.339962, precision: 0.620489, recall: 0.130224, fmeasure: 0.202910, val_loss: 1.131247, val_accuracy: 0.616725, val_precision: 0.862976, val_recall: 0.359259, val_fmeasure: 0.500532\n",
      "134/134 [==============================] - 2s 15ms/step - loss: 1.8294 - accuracy: 0.3400 - precision: 0.6205 - recall: 0.1302 - fmeasure: 0.2029 - val_loss: 1.1312 - val_accuracy: 0.6167 - val_precision: 0.8630 - val_recall: 0.3593 - val_fmeasure: 0.5005\n",
      "Epoch 4/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.9704 - accuracy: 0.6645 - precision: 0.8541 - recall: 0.5206 - fmeasure: 0.6391src.model - INFO - {Epoch: 3} loss: 0.963960, accuracy: 0.667167, precision: 0.856050, recall: 0.524627, fmeasure: 0.642660, val_loss: 0.499185, val_accuracy: 0.852265, val_precision: 0.945381, val_recall: 0.756019, val_fmeasure: 0.837884\n",
      "134/134 [==============================] - 2s 15ms/step - loss: 0.9640 - accuracy: 0.6672 - precision: 0.8561 - recall: 0.5246 - fmeasure: 0.6427 - val_loss: 0.4992 - val_accuracy: 0.8523 - val_precision: 0.9454 - val_recall: 0.7560 - val_fmeasure: 0.8379\n",
      "Epoch 5/15\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.5743 - accuracy: 0.8092 - precision: 0.8982 - recall: 0.7227 - fmeasure: 0.7978src.model - INFO - {Epoch: 4} loss: 0.575167, accuracy: 0.809756, precision: 0.895795, recall: 0.720895, fmeasure: 0.795810, val_loss: 0.396799, val_accuracy: 0.878049, val_precision: 0.944122, val_recall: 0.822454, val_fmeasure: 0.877633\n",
      "134/134 [==============================] - 2s 15ms/step - loss: 0.5752 - accuracy: 0.8098 - precision: 0.8958 - recall: 0.7209 - fmeasure: 0.7958 - val_loss: 0.3968 - val_accuracy: 0.8780 - val_precision: 0.9441 - val_recall: 0.8225 - val_fmeasure: 0.8776\n",
      "Epoch 6/15\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4119 - accuracy: 0.8662 - precision: 0.9268 - recall: 0.8162 - fmeasure: 0.8665src.model - INFO - {Epoch: 5} loss: 0.411348, accuracy: 0.866417, precision: 0.927368, recall: 0.817537, fmeasure: 0.867501, val_loss: 0.215810, val_accuracy: 0.938676, val_precision: 0.975166, val_recall: 0.902315, val_fmeasure: 0.936627\n",
      "134/134 [==============================] - 2s 16ms/step - loss: 0.4113 - accuracy: 0.8664 - precision: 0.9274 - recall: 0.8175 - fmeasure: 0.8675 - val_loss: 0.2158 - val_accuracy: 0.9387 - val_precision: 0.9752 - val_recall: 0.9023 - val_fmeasure: 0.9366\n",
      "Epoch 7/15\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3062 - accuracy: 0.9058 - precision: 0.9462 - recall: 0.8701 - fmeasure: 0.9054src.model - INFO - {Epoch: 6} loss: 0.306224, accuracy: 0.905816, precision: 0.946207, recall: 0.870149, fmeasure: 0.905411, val_loss: 0.197933, val_accuracy: 0.935889, val_precision: 0.961807, val_recall: 0.912037, val_fmeasure: 0.935765\n",
      "134/134 [==============================] - 2s 15ms/step - loss: 0.3062 - accuracy: 0.9058 - precision: 0.9462 - recall: 0.8701 - fmeasure: 0.9054 - val_loss: 0.1979 - val_accuracy: 0.9359 - val_precision: 0.9618 - val_recall: 0.9120 - val_fmeasure: 0.9358\n",
      "Epoch 8/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.2721 - accuracy: 0.9195 - precision: 0.9474 - recall: 0.8882 - fmeasure: 0.9161src.model - INFO - {Epoch: 7} loss: 0.272391, accuracy: 0.920075, precision: 0.948205, recall: 0.885074, fmeasure: 0.914523, val_loss: 0.241546, val_accuracy: 0.915679, val_precision: 0.948228, val_recall: 0.893287, val_fmeasure: 0.919259\n",
      "134/134 [==============================] - 2s 16ms/step - loss: 0.2724 - accuracy: 0.9201 - precision: 0.9482 - recall: 0.8851 - fmeasure: 0.9145 - val_loss: 0.2415 - val_accuracy: 0.9157 - val_precision: 0.9482 - val_recall: 0.8933 - val_fmeasure: 0.9193\n",
      "Epoch 9/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.2136 - accuracy: 0.9298 - precision: 0.9581 - recall: 0.9015 - fmeasure: 0.9281src.model - INFO - {Epoch: 8} loss: 0.211917, accuracy: 0.930582, precision: 0.958641, recall: 0.902985, fmeasure: 0.929167, val_loss: 0.176669, val_accuracy: 0.944948, val_precision: 0.961446, val_recall: 0.927315, val_fmeasure: 0.943757\n",
      "134/134 [==============================] - 2s 15ms/step - loss: 0.2119 - accuracy: 0.9306 - precision: 0.9586 - recall: 0.9030 - fmeasure: 0.9292 - val_loss: 0.1767 - val_accuracy: 0.9449 - val_precision: 0.9614 - val_recall: 0.9273 - val_fmeasure: 0.9438\n",
      "Epoch 10/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.1594 - accuracy: 0.9511 - precision: 0.9668 - recall: 0.9302 - fmeasure: 0.9477src.model - INFO - {Epoch: 9} loss: 0.160462, accuracy: 0.950844, precision: 0.966470, recall: 0.929104, fmeasure: 0.946947, val_loss: 0.226615, val_accuracy: 0.933798, val_precision: 0.950535, val_recall: 0.919908, val_fmeasure: 0.934553\n",
      "134/134 [==============================] - 2s 15ms/step - loss: 0.1605 - accuracy: 0.9508 - precision: 0.9665 - recall: 0.9291 - fmeasure: 0.9469 - val_loss: 0.2266 - val_accuracy: 0.9338 - val_precision: 0.9505 - val_recall: 0.9199 - val_fmeasure: 0.9346\n",
      "Epoch 11/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.1679 - accuracy: 0.9473 - precision: 0.9644 - recall: 0.9336 - fmeasure: 0.9483src.model - INFO - {Epoch: 10} loss: 0.166081, accuracy: 0.947842, precision: 0.964780, recall: 0.934701, fmeasure: 0.949063, val_loss: 0.130406, val_accuracy: 0.957491, val_precision: 0.972397, val_recall: 0.944213, val_fmeasure: 0.957810\n",
      "134/134 [==============================] - 2s 16ms/step - loss: 0.1661 - accuracy: 0.9478 - precision: 0.9648 - recall: 0.9347 - fmeasure: 0.9491 - val_loss: 0.1304 - val_accuracy: 0.9575 - val_precision: 0.9724 - val_recall: 0.9442 - val_fmeasure: 0.9578\n",
      "Epoch 12/15\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.1138 - accuracy: 0.9665 - precision: 0.9764 - recall: 0.9545 - fmeasure: 0.9651src.model - INFO - {Epoch: 11} loss: 0.113704, accuracy: 0.966604, precision: 0.976592, recall: 0.954850, fmeasure: 0.965325, val_loss: 0.153718, val_accuracy: 0.955401, val_precision: 0.963913, val_recall: 0.946297, val_fmeasure: 0.954760\n",
      "134/134 [==============================] - 2s 16ms/step - loss: 0.1137 - accuracy: 0.9666 - precision: 0.9766 - recall: 0.9549 - fmeasure: 0.9653 - val_loss: 0.1537 - val_accuracy: 0.9554 - val_precision: 0.9639 - val_recall: 0.9463 - val_fmeasure: 0.9548\n",
      "Epoch 13/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.1191 - accuracy: 0.9626 - precision: 0.9739 - recall: 0.9531 - fmeasure: 0.9631src.model - INFO - {Epoch: 12} loss: 0.118623, accuracy: 0.962477, precision: 0.974088, recall: 0.952985, fmeasure: 0.963166, val_loss: 0.105018, val_accuracy: 0.968641, val_precision: 0.976397, val_recall: 0.958796, val_fmeasure: 0.967242\n",
      "134/134 [==============================] - 2s 15ms/step - loss: 0.1186 - accuracy: 0.9625 - precision: 0.9741 - recall: 0.9530 - fmeasure: 0.9632 - val_loss: 0.1050 - val_accuracy: 0.9686 - val_precision: 0.9764 - val_recall: 0.9588 - val_fmeasure: 0.9672\n",
      "Epoch 14/15\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.0824 - accuracy: 0.9737 - precision: 0.9810 - recall: 0.9656 - fmeasure: 0.9731src.model - INFO - {Epoch: 13} loss: 0.082229, accuracy: 0.973734, precision: 0.981083, recall: 0.965671, fmeasure: 0.973120, val_loss: 0.094459, val_accuracy: 0.974216, val_precision: 0.981031, val_recall: 0.966435, val_fmeasure: 0.973446\n",
      "134/134 [==============================] - 2s 16ms/step - loss: 0.0822 - accuracy: 0.9737 - precision: 0.9811 - recall: 0.9657 - fmeasure: 0.9731 - val_loss: 0.0945 - val_accuracy: 0.9742 - val_precision: 0.9810 - val_recall: 0.9664 - val_fmeasure: 0.9734\n",
      "Epoch 15/15\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.1033 - accuracy: 0.9662 - precision: 0.9765 - recall: 0.9592 - fmeasure: 0.9675src.model - INFO - {Epoch: 14} loss: 0.105134, accuracy: 0.965478, precision: 0.974932, recall: 0.957089, fmeasure: 0.965671, val_loss: 0.129795, val_accuracy: 0.961672, val_precision: 0.968421, val_recall: 0.955093, val_fmeasure: 0.961544\n",
      "134/134 [==============================] - 2s 15ms/step - loss: 0.1051 - accuracy: 0.9655 - precision: 0.9749 - recall: 0.9571 - fmeasure: 0.9657 - val_loss: 0.1298 - val_accuracy: 0.9617 - val_precision: 0.9684 - val_recall: 0.9551 - val_fmeasure: 0.9615\n",
      "src.model - INFO - Training completed\n",
      "src.model - INFO - Evaluating model\n",
      "45/45 [==============================] - 0s 9ms/step - loss: 0.1298 - accuracy: 0.9617 - precision: 0.9684 - recall: 0.9553 - fmeasure: 0.9617\n",
      "84/84 [==============================] - 1s 8ms/step - loss: 0.0318 - accuracy: 0.9906 - precision: 0.9918 - recall: 0.9877 - fmeasure: 0.9897\n",
      "src.model - INFO - Train loss: 0.031830690801143646\n",
      "src.model - INFO - Train precision: 0.9917555451393127\n",
      "src.model - INFO - Train recall: 0.9877232313156128\n",
      "src.model - INFO - Train f1-score: 0.9897072315216064\n",
      "src.model - INFO - Test loss: 0.12979449331760406\n",
      "src.model - INFO - Test precision: 0.968385636806488\n",
      "src.model - INFO - Test recall: 0.9552983641624451\n",
      "src.model - INFO - Test f1-score: 0.9616868495941162\n",
      "45/45 [==============================] - 0s 5ms/step\n",
      "src.train - INFO - Confusion Matrix for classes ['a', 'am', 'bm', 'c', 'd', 'dm', 'e', 'em', 'f', 'g']:\n",
      "[[136   3   0   0   1   0   0   0   0   0]\n",
      " [  0 126   0   1   0   1   0   0   1   0]\n",
      " [  0   0 123   0   1   0   0   0   0   0]\n",
      " [  0   0   0 165   0   0   0   0   0   1]\n",
      " [  0   0   0   0 140   6   0   0   0   1]\n",
      " [  0   0   0   0   3 146   0   0   0   4]\n",
      " [  0   1   3   0   0   1 132   0   1   0]\n",
      " [  0   1   0   1   0   2   4 128   1   2]\n",
      " [  0   4   0   1   0   4   0   0 125   0]\n",
      " [  0   0   1   0   2   2   1   0   0 159]]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import keras\n",
    "import os, glob\n",
    "import logging\n",
    "import librosa, librosa.display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import model_from_json\n",
    "from keras import backend as K\n",
    "\n",
    "from src.metrics import *\n",
    "from settings import *\n",
    "from src.data import generate\n",
    "from src.processing import *\n",
    "from src.model import CNN\n",
    "from src.data.preprocessing import get_most_shape\n",
    "from setup_logging import setup_logging\n",
    "\n",
    "setup_logging()\n",
    "logger = logging.getLogger('src.train')\n",
    "\n",
    "train_datas = []\n",
    "test_datas = []\n",
    "\n",
    "for dataset in datasets_raw:\n",
    "    train_data, test_data = train_test_split(dataset, augmented=False, split_ratio=0.65)\n",
    "    train_datas.append(train_data)\n",
    "    test_datas.append(test_data)\n",
    "\n",
    "for dataset in datasets_augmented:\n",
    "    train_data, test_data = train_test_split(dataset, augmented=True, split_ratio=0.65)\n",
    "    train_datas.append(train_data)\n",
    "    test_datas.append(test_data)\n",
    "\n",
    "train_data = pd.concat(train_datas)\n",
    "test_data = pd.concat(test_datas)\n",
    "\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
    "test_data = test_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "most_shape = get_most_shape(train_data)\n",
    "\n",
    "logger.info(f\"Number of train samples: {len(train_data)}\")\n",
    "logger.info(f\"Number of test samples: {len(test_data)}\")\n",
    "# most_shape = get_most_shape(dataset)\n",
    "#train_data, test_data = train_test_split(dataset, augmented=augmented, split_ratio=0.65)\n",
    "\n",
    "X_train, y_train = features_target_split(train_data)\n",
    "X_test, y_test = features_target_split(test_data)\n",
    "\n",
    "# Reshape for CNN input\n",
    "X_train, X_test = reshape_feature_CNN(X_train, size=max_spectrogram_size), reshape_feature_CNN(X_test, size=max_spectrogram_size)\n",
    "\n",
    "# Preserve y_test values\n",
    "y_test_values = y_test.copy()\n",
    "\n",
    "# One-Hot encoding for classes\n",
    "y_train, y_test = one_hot_encode(y_train), one_hot_encode(y_test)\n",
    "\n",
    "# Instance of CNN model\n",
    "cnn = CNN(most_shape)\n",
    "logger.info(str(cnn))\n",
    "\n",
    "cnn.train(X_train, y_train, X_test, y_test, epochs=15)\n",
    "cnn.evaluate(X_train, y_train, X_test, y_test)\n",
    "\n",
    "if tf.__version__ != '1.8.0':\n",
    "    predict_x=cnn.model.predict(X_test)\n",
    "    predictions = np.argmax(predict_x,axis=1)\n",
    "else:    \n",
    "    predictions = cnn.model.predict_classes(X_test)\n",
    "conf_matrix=confusion_matrix(y_test_values, predictions, labels=range(10))\n",
    "logger.info('Confusion Matrix for classes {}:\\n{}'.format(CLASSES, conf_matrix))\n",
    "#cnn.save_model(name=\"model_all_data_augment_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1590 - accuracy: 0.9586 - precision: 0.9599 - recall: 0.9531 - fmeasure: 0.9564\n",
      "Test score for instrument: Guitar\n",
      "\tTest loss: 0.15901747345924377\n",
      "\tTest accuracy: 0.9585714340209961\n",
      "\tTest precision: 0.9598607420921326\n",
      "\tTest recall: 0.953125\n",
      "\tTest f1-score: 0.9564393758773804\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0129 - accuracy: 0.9959 - precision: 0.9961 - recall: 0.9961 - fmeasure: 0.9961\n",
      "Test score for instrument: Accordion\n",
      "\tTest loss: 0.012882090173661709\n",
      "\tTest accuracy: 0.9959183931350708\n",
      "\tTest precision: 0.99609375\n",
      "\tTest recall: 0.99609375\n",
      "\tTest f1-score: 0.99609375\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0030 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - fmeasure: 1.0000\n",
      "Test score for instrument: Violin\n",
      "\tTest loss: 0.00295547628775239\n",
      "\tTest accuracy: 1.0\n",
      "\tTest precision: 1.0\n",
      "\tTest recall: 1.0\n",
      "\tTest f1-score: 1.0\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2901 - accuracy: 0.8980 - precision: 0.9305 - recall: 0.8808 - fmeasure: 0.9044\n",
      "Test score for instrument: Piano\n",
      "\tTest loss: 0.29005154967308044\n",
      "\tTest accuracy: 0.8979591727256775\n",
      "\tTest precision: 0.930514395236969\n",
      "\tTest recall: 0.8807663917541504\n",
      "\tTest f1-score: 0.9044294357299805\n"
     ]
    }
   ],
   "source": [
    "test_instruments = instruments + instruments_aug\n",
    "for test_data, instrument in zip(test_datas, test_instruments):\n",
    "    X_test = test_data['spectrogram']\n",
    "    X_test = np.array([x.reshape( (128, max_spectrogram_size, 1) ) for x in X_test])\n",
    "    y_test = test_data['class_ID']\n",
    "\n",
    "    y_test_values=y_test\n",
    "    y_test = np.array(keras.utils.to_categorical(y_test, 10))\n",
    "\n",
    "    score = cnn.model.evaluate(X_test,y_test)\n",
    "    print(f'Test score for instrument: {instrument}')\n",
    "    print('\\tTest loss:', score[0])\n",
    "    print('\\tTest accuracy:', score[1])\n",
    "    print('\\tTest precision:', score[2])\n",
    "    print('\\tTest recall:', score[3])\n",
    "    print('\\tTest f1-score:', score[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src.model - INFO - Saving model\n",
      "src.model - INFO - Saved model to /home/tzag/danigil/dl/guitarCR/models\n"
     ]
    }
   ],
   "source": [
    "cnn.save_model(name=\"model_alldata_augment_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/tzag/miniconda3/envs/danigil-steganalysis/lib/python3.8/site-packages/keras/engine/training.py\", line 1820, in test_function  *\n        return step_function(self, iterator)\n    File \"/home/tzag/miniconda3/envs/danigil-steganalysis/lib/python3.8/site-packages/keras/engine/training.py\", line 1804, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/tzag/miniconda3/envs/danigil-steganalysis/lib/python3.8/site-packages/keras/engine/training.py\", line 1792, in run_step  **\n        outputs = model.test_step(data)\n    File \"/home/tzag/miniconda3/envs/danigil-steganalysis/lib/python3.8/site-packages/keras/engine/training.py\", line 1756, in test_step\n        y_pred = self(x, training=False)\n    File \"/home/tzag/miniconda3/envs/danigil-steganalysis/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/tzag/miniconda3/envs/danigil-steganalysis/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 128, 87, 1), found shape=(None, 128, 107, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m y_test_values\u001b[39m=\u001b[39my_test\n\u001b[1;32m     18\u001b[0m y_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(keras\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mto_categorical(y_test, \u001b[39m10\u001b[39m))\n\u001b[0;32m---> 20\u001b[0m score \u001b[39m=\u001b[39m baseline_model\u001b[39m.\u001b[39;49mevaluate(X_test,y_test)\n\u001b[1;32m     21\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTest score for instrument: \u001b[39m\u001b[39m{\u001b[39;00minstrument\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[39m# print('\\tTest loss:', score[0])\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39m# print('\\tTest accuracy:', score[1])\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39m# print('\\tTest precision:', score[2])\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39m# print('\\tTest recall:', score[3])\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/danigil-steganalysis/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filekcblrgyb.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/tzag/miniconda3/envs/danigil-steganalysis/lib/python3.8/site-packages/keras/engine/training.py\", line 1820, in test_function  *\n        return step_function(self, iterator)\n    File \"/home/tzag/miniconda3/envs/danigil-steganalysis/lib/python3.8/site-packages/keras/engine/training.py\", line 1804, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/tzag/miniconda3/envs/danigil-steganalysis/lib/python3.8/site-packages/keras/engine/training.py\", line 1792, in run_step  **\n        outputs = model.test_step(data)\n    File \"/home/tzag/miniconda3/envs/danigil-steganalysis/lib/python3.8/site-packages/keras/engine/training.py\", line 1756, in test_step\n        y_pred = self(x, training=False)\n    File \"/home/tzag/miniconda3/envs/danigil-steganalysis/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/tzag/miniconda3/envs/danigil-steganalysis/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 128, 87, 1), found shape=(None, 128, 107, 1)\n"
     ]
    }
   ],
   "source": [
    "with open(MODEL_1_JSON, \"r\") as json_file:\n",
    "\tloaded_model_json = json_file.read()\n",
    "\n",
    "baseline_model = model_from_json(loaded_model_json)\n",
    "baseline_model.load_weights(MODEL_1_H5)\n",
    "\n",
    "baseline_model.compile(\n",
    "            optimizer=\"Adam\",\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics=['accuracy', precision, recall, fmeasure])\n",
    "\n",
    "for test_data, instrument in zip(test_datas, test_instruments):\n",
    "    X_test = test_data['spectrogram']\n",
    "    X_test = np.array([x.reshape( (128, max_spectrogram_size, 1) ) for x in X_test])\n",
    "    y_test = test_data['class_ID']\n",
    "\n",
    "    y_test_values=y_test\n",
    "    y_test = np.array(keras.utils.to_categorical(y_test, 10))\n",
    "\n",
    "    score = baseline_model.evaluate(X_test,y_test)\n",
    "    print(f'Test score for instrument: {instrument}')\n",
    "    # print('\\tTest loss:', score[0])\n",
    "    # print('\\tTest accuracy:', score[1])\n",
    "    # print('\\tTest precision:', score[2])\n",
    "    # print('\\tTest recall:', score[3])\n",
    "    print('\\tf1-score:', score[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "danigil-steganalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
